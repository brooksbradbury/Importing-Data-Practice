{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "nGcQ-p1il_kr",
        "outputId": "9eb9bd5b-9186-4e7d-88e9-47fdfbbd7947",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
            "0               7.4             0.700         0.00             1.9      0.076   \n",
            "1               7.8             0.880         0.00             2.6      0.098   \n",
            "2               7.8             0.760         0.04             2.3      0.092   \n",
            "3              11.2             0.280         0.56             1.9      0.075   \n",
            "4               7.4             0.700         0.00             1.9      0.076   \n",
            "...             ...               ...          ...             ...        ...   \n",
            "1594            6.2             0.600         0.08             2.0      0.090   \n",
            "1595            5.9             0.550         0.10             2.2      0.062   \n",
            "1596            6.3             0.510         0.13             2.3      0.076   \n",
            "1597            5.9             0.645         0.12             2.0      0.075   \n",
            "1598            6.0             0.310         0.47             3.6      0.067   \n",
            "\n",
            "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
            "0                    11.0                  34.0  0.99780  3.51       0.56   \n",
            "1                    25.0                  67.0  0.99680  3.20       0.68   \n",
            "2                    15.0                  54.0  0.99700  3.26       0.65   \n",
            "3                    17.0                  60.0  0.99800  3.16       0.58   \n",
            "4                    11.0                  34.0  0.99780  3.51       0.56   \n",
            "...                   ...                   ...      ...   ...        ...   \n",
            "1594                 32.0                  44.0  0.99490  3.45       0.58   \n",
            "1595                 39.0                  51.0  0.99512  3.52       0.76   \n",
            "1596                 29.0                  40.0  0.99574  3.42       0.75   \n",
            "1597                 32.0                  44.0  0.99547  3.57       0.71   \n",
            "1598                 18.0                  42.0  0.99549  3.39       0.66   \n",
            "\n",
            "      alcohol  quality  \n",
            "0         9.4        5  \n",
            "1         9.8        5  \n",
            "2         9.8        5  \n",
            "3         9.8        6  \n",
            "4         9.4        5  \n",
            "...       ...      ...  \n",
            "1594     10.5        5  \n",
            "1595     11.2        6  \n",
            "1596     11.0        6  \n",
            "1597     10.2        5  \n",
            "1598     11.0        6  \n",
            "\n",
            "[1599 rows x 12 columns]\n"
          ]
        }
      ],
      "source": [
        "# Importing CSVs from Web\n",
        "\n",
        "# Import package\n",
        "from urllib.request import urlretrieve\n",
        "\n",
        "# Import pandas\n",
        "import pandas as pd\n",
        "\n",
        "# Import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assign url of file: url\n",
        "url = 'https://assets.datacamp.com/production/course_1606/datasets/winequality-red.csv'\n",
        "\n",
        "# Save file locally\n",
        "urlretrieve(url,'winequality-red.csv')\n",
        "\n",
        "# Read file into a DataFrame and print its head\n",
        "df = pd.read_csv('winequality-red.csv', sep=';')\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot first column of df\n",
        "df.iloc[:, 0].hist()\n",
        "plt.xlabel('fixed acidity (g(tartaric acid)/dm$^3$)')\n",
        "plt.ylabel('count')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "id": "zlfKeo23nsGk",
        "outputId": "2c451395-d5b0-440c-8ec9-b332a940580d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing xls file from web\n",
        "\n",
        "# Assign url of file: url\n",
        "url = 'https://assets.datacamp.com/course/importing_data_into_r/latitude.xls'\n",
        "\n",
        "# Read in all sheets of Excel file: xls\n",
        "xls = pd.read_excel(url, sheet_name = None)\n",
        "\n",
        "# Print the sheetnames to the shell\n",
        "print(xls.keys())\n",
        "\n",
        "# Print the head of the first sheet (using its name, NOT its index)\n",
        "print(xls['1700'].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LsDRT4_aDhaA",
        "outputId": "5e419985-fb36-412a-c0f7-90c5d9643cd3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['1700', '1900'])\n",
            "                 country       1700\n",
            "0            Afghanistan  34.565000\n",
            "1  Akrotiri and Dhekelia  34.616667\n",
            "2                Albania  41.312000\n",
            "3                Algeria  36.720000\n",
            "4         American Samoa -14.307000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# HTTP requests in Python\n",
        "\n",
        "# Import packages\n",
        "from urllib.request import urlopen\n",
        "from urllib.request import Request\n",
        "import requests\n",
        "\n",
        "# Specify the url\n",
        "url = \"https://campus.datacamp.com/courses/1606/4135?ex=2\"\n",
        "\n",
        "# This packages the request: request\n",
        "request = Request(url)\n",
        "\n",
        "# Sends the request and catches the response: response\n",
        "response = urlopen(request)\n",
        "\n",
        "# Print the datatype of response\n",
        "print(type(response))\n",
        "\n",
        "# Extract the response: html\n",
        "html = response.read()\n",
        "\n",
        "# Print the html\n",
        "print(html)\n",
        "\n",
        "# Be polite and close the response!\n",
        "response.close()\n",
        "\n",
        "# Packages the request, send the request and catch the response: r\n",
        "r = requests.get(url)\n",
        "\n",
        "# Extract the response: text\n",
        "text = r.text\n",
        "\n",
        "# Print the html\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wO67iMIhEzhi",
        "outputId": "6cb2b3bb-296c-4e31-92a3-ba8ffad22f4c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'http.client.HTTPResponse'>\n",
            "b'<!doctype html><html lang=\"en\"><head><meta charset=\"UTF-8\"><link rel=\"apple-touch-icon-precomposed\" sizes=\"57x57\" href=\"/campus/apple-touch-icon-57x57.png\"><link rel=\"apple-touch-icon-precomposed\" sizes=\"114x114\" href=\"/campus/apple-touch-icon-114x114.png\"><link rel=\"apple-touch-icon-precomposed\" sizes=\"72x72\" href=\"/campus/apple-touch-icon-72x72.png\"><link rel=\"apple-touch-icon-precomposed\" sizes=\"144x144\" href=\"/campus/apple-touch-icon-144x144.png\"><link rel=\"apple-touch-icon-precomposed\" sizes=\"60x60\" href=\"/campus/apple-touch-icon-60x60.png\"><link rel=\"apple-touch-icon-precomposed\" sizes=\"120x120\" href=\"/campus/apple-touch-icon-120x120.png\"><link rel=\"apple-touch-icon-precomposed\" sizes=\"76x76\" href=\"/campus/apple-touch-icon-76x76.png\"><link rel=\"apple-touch-icon-precomposed\" sizes=\"152x152\" href=\"/campus/apple-touch-icon-152x152.png\"><link rel=\"icon\" type=\"image/png\" href=\"/campus/favicon.ico\"><link rel=\"icon\" type=\"image/png\" href=\"/campus/favicon-196x196.png\" sizes=\"196x196\"><link rel=\"icon\" type=\"image/png\" href=\"/campus/favicon-96x96.png\" sizes=\"96x96\"><link rel=\"icon\" type=\"image/png\" href=\"/campus/favicon-32x32.png\" sizes=\"32x32\"><link rel=\"icon\" type=\"image/png\" href=\"/campus/favicon-16x16.png\" sizes=\"16x16\"><link rel=\"icon\" type=\"image/png\" href=\"/campus/favicon-128.png\" sizes=\"128x128\"><meta name=\"application-name\" content=\"DataCamp\"><meta name=\"msapplication-TileColor\" content=\"#FFFFFF\"><meta name=\"msapplication-TileImage\" content=\"/campus/mstile-144x144.png\"><meta name=\"msapplication-square70x70logo\" content=\"/campus/mstile-70x70.png\"><meta name=\"msapplication-square150x150logo\" content=\"/campus/mstile-150x150.png\"><meta name=\"msapplication-wide310x150logo\" content=\"/campus/mstile-310x150.png\"><meta name=\"msapplication-square310x310logo\" content=\"/campus/mstile-310x310.png\"><script>!function(n,t,e,r){function a(){return t&&t.now?t.now():null}e.version||(e._events=[],e._errors=[],e._metadata={},e._urlGroup=null,window.RM=e,e.install=function(t){e._options=t;var r=n.createElement(\"script\");r.async=!0,r.crossOrigin=\"anonymous\",r.src=\"https://cdn.requestmetrics.com/agent/current/rm.js\";var a=n.getElementsByTagName(\"script\")[0];a.parentNode.insertBefore(r,a)},e.identify=function(n,t){e._userId=n,e._identifyOptions=t},e.sendEvent=function(n,t){e._events.push({eventName:n,metadata:t,time:a()})},e.setUrlGroup=function(n){e._urlGroup=n},e.track=function(n,t){e._errors.push({error:n,metadata:t,time:a()})},e.addMetadata=function(n){e._metadata=Object.assign(e._metadata,n)})}(document,window.performance,window.RM||{}),window.RM.install({token:\"h4zx2kc:w3sn5gv\"})</script><link href=\"/campus/static/css/vendors~main~977b87ed.cf4b5fcf.chunk.css\" rel=\"stylesheet\"><link href=\"/campus/static/css/vendors~main~1f20a385.ead2d232.chunk.css\" rel=\"stylesheet\"><link href=\"/campus/static/css/vendors~main~678f84af.9b5ca43c.chunk.css\" rel=\"stylesheet\"><link href=\"/campus/static/css/main~c714bc7b.473de2c9.chunk.css\" rel=\"stylesheet\"><title data-react-helmet=\"true\">Importing flat files from the web: your turn! | Python</title><link data-react-helmet=\"true\" rel=\"canonical\" href=\"https://campus.datacamp.com/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1?ex=2\"><link data-react-helmet=\"true\" rel=\"preload\" href=\"https://dcmfe.datacamp.com/assets/fonts/StudioFeixenSansRegular-english-v2.woff2\" as=\"font\" crossorigin=\"anonymous\"><link data-react-helmet=\"true\" rel=\"preload\" href=\"https://dcmfe.datacamp.com/assets/fonts/StudioFeixenSans-Semibold-english.woff2\" as=\"font\" crossorigin=\"anonymous\"><link data-react-helmet=\"true\" rel=\"preload\" href=\"https://dcmfe.datacamp.com/assets/fonts/StudioFeixenSansRegular-latin-v2.woff2\" as=\"font\" crossorigin=\"anonymous\"><link data-react-helmet=\"true\" rel=\"preload\" href=\"https://dcmfe.datacamp.com/assets/fonts/JetBrainsMono-english.woff2\" as=\"font\" crossorigin=\"anonymous\"><link data-react-helmet=\"true\" rel=\"preload\" href=\"https://dcmfe.datacamp.com/assets/fonts/JetBrainsMono-rest.woff2\" as=\"font\" crossorigin=\"anonymous\"><link data-react-helmet=\"true\" rel=\"preconnect\" href=\"https://campus-api.datacamp.com\"><link data-react-helmet=\"true\" rel=\"dns-prefetch\" href=\"https://campus-api.datacamp.com\"><link data-react-helmet=\"true\" rel=\"preconnect\" href=\"https://projector.datacamp.com\"><link data-react-helmet=\"true\" rel=\"dns-prefetch\" href=\"https://projector.datacamp.com\"><link data-react-helmet=\"true\" rel=\"preconnect\" href=\"https://assets.datacamp.com\"><link data-react-helmet=\"true\" rel=\"dns-prefetch\" href=\"https://assets.datacamp.com\"><meta data-react-helmet=\"true\" http-equiv=\"X-UA-Compatible\" content=\"IE=edge,chrome=1\"><meta data-react-helmet=\"true\" name=\"viewport\" content=\"width=device-width, initial-scale=1, maximum-scale=1\"><meta data-react-helmet=\"true\" name=\"fragment\" content=\"!\"><meta data-react-helmet=\"true\" name=\"keywords\" content=\"R, Python, Data analysis, interactive, learning\"><meta data-react-helmet=\"true\" name=\"description\" content=\"Here is an example of Importing flat files from the web: your turn!: You are about to import your first file from the web! The flat file you will import will be &apos;winequality-red.\"><meta data-react-helmet=\"true\" name=\"twitter:card\" content=\"summary\"><meta data-react-helmet=\"true\" name=\"twitter:site\" content=\"@DataCamp\"><meta data-react-helmet=\"true\" name=\"twitter:title\" content=\"Importing flat files from the web: your turn! | Python\"><meta data-react-helmet=\"true\" name=\"twitter:description\" content=\"Here is an example of Importing flat files from the web: your turn!: You are about to import your first file from the web! The flat file you will import will be &apos;winequality-red.\"><meta data-react-helmet=\"true\" name=\"twitter:creator\" content=\"@DataCamp\"><meta data-react-helmet=\"true\" name=\"twitter:image:src\" content=\"/public/assets/images/var/twitter_share.png\"><meta data-react-helmet=\"true\" name=\"twitter:domain\" content=\"www.datacamp.com\"><meta data-react-helmet=\"true\" property=\"og:title\" content=\"Importing flat files from the web: your turn! | Python\"><meta data-react-helmet=\"true\" property=\"og:image\" content=\"/public/assets/images/var/linkedin_share.png\"><meta data-react-helmet=\"true\" name=\"google-signin-clientid\" content=\"892114885437-01a7plbsu1b2vobuhvnckmmanhb58h3a.apps.googleusercontent.com\"><meta data-react-helmet=\"true\" name=\"google-signin-scope\" content=\"email profile\"><meta data-react-helmet=\"true\" name=\"google-signin-cookiepolicy\" content=\"single_host_origin\"><meta content=\"en\" http-equiv=\"content-language\"><link href=\"https://campus.datacamp.com/courses/1606/4135?ex=2\" hreflang=\"x-default\" rel=\"alternate\"><link href=\"https://campus.datacamp.com/courses/1606/4135?ex=2\" hreflang=\"en\" rel=\"alternate\"><link href=\"https://campus.datacamp.com/es/courses/1606/4135?ex=2\" hreflang=\"es\" rel=\"alternate\"><link href=\"https://campus.datacamp.com/pt/courses/1606/4135?ex=2\" hreflang=\"pt\" rel=\"alternate\"><link href=\"https://campus.datacamp.com/de/courses/1606/4135?ex=2\" hreflang=\"de\" rel=\"alternate\"></head><body><script>window.PRELOADED_STATE = \"[&quot;~#iR&quot;,[&quot;^ &quot;,&quot;n&quot;,&quot;StateRecord&quot;,&quot;v&quot;,[&quot;^ &quot;,&quot;backendSession&quot;,[&quot;^ &quot;,&quot;status&quot;,[&quot;^ &quot;,&quot;code&quot;,&quot;none&quot;,&quot;text&quot;,&quot;&quot;],&quot;lastSubmittedCode&quot;,null,&quot;lastSubmittedCommand&quot;,null,&quot;isInitSession&quot;,false,&quot;message&quot;,null,&quot;sessionId&quot;,null],&quot;backendSessionJsonRpc&quot;,[&quot;^ &quot;,&quot;^2&quot;,&quot;initial&quot;],&quot;boot&quot;,[&quot;^0&quot;,[&quot;^ &quot;,&quot;n&quot;,&quot;BootStateRecord&quot;,&quot;v&quot;,[&quot;^ &quot;,&quot;bootState&quot;,&quot;PRE_BOOTED&quot;,&quot;error&quot;,null]]],&quot;chapter&quot;,[&quot;~#iOM&quot;,[&quot;current&quot;,[&quot;^?&quot;,[&quot;badge_uncompleted_url&quot;,&quot;https://assets.datacamp.com/production/default/badges/missing_unc.png&quot;,&quot;number&quot;,1,&quot;number_of_videos&quot;,3,&quot;slug&quot;,&quot;importing-data-from-the-internet-1&quot;,&quot;last_updated_on&quot;,&quot;26/09/2024&quot;,&quot;title_meta&quot;,null,&quot;nb_exercises&quot;,12,&quot;free_preview&quot;,true,&quot;slides_link&quot;,&quot;https://projector-video-pdf-converter.datacamp.com/1606/chapter1.pdf&quot;,&quot;title&quot;,&quot;Importing data from the Internet&quot;,&quot;xp&quot;,1050,&quot;id&quot;,4135,&quot;exercises&quot;,[&quot;~#iL&quot;,[[&quot;^?&quot;,[&quot;type&quot;,&quot;VideoExercise&quot;,&quot;title&quot;,&quot;Importing flat files from the web&quot;,&quot;aggregate_xp&quot;,50,&quot;number&quot;,1,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1?ex=1&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;NormalExercise&quot;,&quot;title&quot;,&quot;Importing flat files from the web: your turn!&quot;,&quot;aggregate_xp&quot;,100,&quot;number&quot;,2,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1?ex=2&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;NormalExercise&quot;,&quot;title&quot;,&quot;Opening and reading flat files from the web&quot;,&quot;aggregate_xp&quot;,100,&quot;number&quot;,3,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1?ex=3&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;NormalExercise&quot;,&quot;title&quot;,&quot;Importing non-flat files from the web&quot;,&quot;aggregate_xp&quot;,100,&quot;number&quot;,4,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1?ex=4&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;VideoExercise&quot;,&quot;title&quot;,&quot;HTTP requests to import files from the web&quot;,&quot;aggregate_xp&quot;,50,&quot;number&quot;,5,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1?ex=5&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;NormalExercise&quot;,&quot;title&quot;,&quot;Performing HTTP requests in Python using urllib&quot;,&quot;aggregate_xp&quot;,100,&quot;number&quot;,6,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1?ex=6&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;NormalExercise&quot;,&quot;title&quot;,&quot;Printing HTTP request results in Python using urllib&quot;,&quot;aggregate_xp&quot;,100,&quot;number&quot;,7,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1?ex=7&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;NormalExercise&quot;,&quot;title&quot;,&quot;Performing HTTP requests in Python using requests&quot;,&quot;aggregate_xp&quot;,100,&quot;number&quot;,8,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1?ex=8&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;VideoExercise&quot;,&quot;title&quot;,&quot;Scraping the web in Python&quot;,&quot;aggregate_xp&quot;,50,&quot;number&quot;,9,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1?ex=9&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;NormalExercise&quot;,&quot;title&quot;,&quot;Parsing HTML with BeautifulSoup&quot;,&quot;aggregate_xp&quot;,100,&quot;number&quot;,10,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1?ex=10&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;NormalExercise&quot;,&quot;title&quot;,&quot;Turning a webpage into data using BeautifulSoup: getting the text&quot;,&quot;aggregate_xp&quot;,100,&quot;number&quot;,11,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1?ex=11&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;NormalExercise&quot;,&quot;title&quot;,&quot;Turning a webpage into data using BeautifulSoup: getting the hyperlinks&quot;,&quot;aggregate_xp&quot;,100,&quot;number&quot;,12,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1?ex=12&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]]]],&quot;description&quot;,&quot;The web is a rich source of data from which you can extract various types of insights and findings. In this chapter, you will learn how to get data from the web, whether it is stored in files or in HTML. You&#39;ll also learn the basics of scraping and parsing web data.&quot;,&quot;badge_completed_url&quot;,&quot;https://assets.datacamp.com/production/default/badges/missing.png&quot;]]]],&quot;codeExplanation&quot;,[&quot;^ &quot;,&quot;^A&quot;,[&quot;^ &quot;,&quot;type&quot;,&quot;initial&quot;]],&quot;contentAuthorization&quot;,[&quot;^ &quot;],&quot;datawarehouseSession&quot;,[&quot;^ &quot;,&quot;^2&quot;,&quot;initial&quot;],&quot;course&quot;,[&quot;^?&quot;,[&quot;difficulty_level&quot;,2,&quot;private_access&quot;,[&quot;^?&quot;,[]],&quot;reduced_outline&quot;,null,&quot;course_resources&quot;,[&quot;^@&quot;,[]],&quot;marketing_video&quot;,&quot;&quot;,&quot;tier&quot;,null,&quot;private&quot;,false,&quot;mobile_enabled&quot;,true,&quot;author_field&quot;,null,&quot;chapters&quot;,[&quot;^@&quot;,[[&quot;^?&quot;,[&quot;badge_uncompleted_url&quot;,&quot;https://assets.datacamp.com/production/default/badges/missing_unc.png&quot;,&quot;number&quot;,1,&quot;number_of_videos&quot;,3,&quot;slug&quot;,&quot;importing-data-from-the-internet-1&quot;,&quot;last_updated_on&quot;,&quot;26/09/2024&quot;,&quot;title_meta&quot;,null,&quot;nb_exercises&quot;,12,&quot;free_preview&quot;,true,&quot;slides_link&quot;,&quot;https://projector-video-pdf-converter.datacamp.com/1606/chapter1.pdf&quot;,&quot;title&quot;,&quot;Importing data from the Internet&quot;,&quot;xp&quot;,1050,&quot;id&quot;,4135,&quot;exercises&quot;,[&quot;^@&quot;,[[&quot;^?&quot;,[&quot;type&quot;,&quot;VideoExercise&quot;,&quot;title&quot;,&quot;Importing flat files from the web&quot;,&quot;aggregate_xp&quot;,50,&quot;number&quot;,1,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1?ex=1&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;NormalExercise&quot;,&quot;title&quot;,&quot;Importing flat files from the web: your turn!&quot;,&quot;aggregate_xp&quot;,100,&quot;number&quot;,2,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1?ex=2&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;NormalExercise&quot;,&quot;title&quot;,&quot;Opening and reading flat files from the web&quot;,&quot;aggregate_xp&quot;,100,&quot;number&quot;,3,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1?ex=3&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;NormalExercise&quot;,&quot;title&quot;,&quot;Importing non-flat files from the web&quot;,&quot;aggregate_xp&quot;,100,&quot;number&quot;,4,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1?ex=4&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;VideoExercise&quot;,&quot;title&quot;,&quot;HTTP requests to import files from the web&quot;,&quot;aggregate_xp&quot;,50,&quot;number&quot;,5,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1?ex=5&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;NormalExercise&quot;,&quot;title&quot;,&quot;Performing HTTP requests in Python using urllib&quot;,&quot;aggregate_xp&quot;,100,&quot;number&quot;,6,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1?ex=6&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;NormalExercise&quot;,&quot;title&quot;,&quot;Printing HTTP request results in Python using urllib&quot;,&quot;aggregate_xp&quot;,100,&quot;number&quot;,7,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1?ex=7&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;NormalExercise&quot;,&quot;title&quot;,&quot;Performing HTTP requests in Python using requests&quot;,&quot;aggregate_xp&quot;,100,&quot;number&quot;,8,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1?ex=8&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;VideoExercise&quot;,&quot;title&quot;,&quot;Scraping the web in Python&quot;,&quot;aggregate_xp&quot;,50,&quot;number&quot;,9,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1?ex=9&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;NormalExercise&quot;,&quot;title&quot;,&quot;Parsing HTML with BeautifulSoup&quot;,&quot;aggregate_xp&quot;,100,&quot;number&quot;,10,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1?ex=10&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;NormalExercise&quot;,&quot;title&quot;,&quot;Turning a webpage into data using BeautifulSoup: getting the text&quot;,&quot;aggregate_xp&quot;,100,&quot;number&quot;,11,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1?ex=11&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;NormalExercise&quot;,&quot;title&quot;,&quot;Turning a webpage into data using BeautifulSoup: getting the hyperlinks&quot;,&quot;aggregate_xp&quot;,100,&quot;number&quot;,12,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1?ex=12&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]]]],&quot;description&quot;,&quot;The web is a rich source of data from which you can extract various types of insights and findings. In this chapter, you will learn how to get data from the web, whether it is stored in files or in HTML. You&#39;ll also learn the basics of scraping and parsing web data.&quot;,&quot;badge_completed_url&quot;,&quot;https://assets.datacamp.com/production/default/badges/missing.png&quot;]],[&quot;^?&quot;,[&quot;badge_uncompleted_url&quot;,&quot;https://assets.datacamp.com/production/default/badges/missing_unc.png&quot;,&quot;number&quot;,2,&quot;number_of_videos&quot;,2,&quot;slug&quot;,&quot;interacting-with-apis-to-import-data-from-the-web-2&quot;,&quot;last_updated_on&quot;,&quot;26/09/2024&quot;,&quot;title_meta&quot;,null,&quot;nb_exercises&quot;,9,&quot;free_preview&quot;,null,&quot;slides_link&quot;,&quot;https://projector-video-pdf-converter.datacamp.com/1606/chapter2.pdf&quot;,&quot;title&quot;,&quot;Interacting with APIs to import data from the web&quot;,&quot;xp&quot;,650,&quot;id&quot;,4136,&quot;exercises&quot;,[&quot;^@&quot;,[[&quot;^?&quot;,[&quot;type&quot;,&quot;VideoExercise&quot;,&quot;title&quot;,&quot;Introduction to APIs and JSONs&quot;,&quot;aggregate_xp&quot;,50,&quot;number&quot;,1,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/interacting-with-apis-to-import-data-from-the-web-2?ex=1&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;PureMultipleChoiceExercise&quot;,&quot;title&quot;,&quot;Pop quiz: What exactly is a JSON?&quot;,&quot;aggregate_xp&quot;,50,&quot;number&quot;,2,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/interacting-with-apis-to-import-data-from-the-web-2?ex=2&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;NormalExercise&quot;,&quot;title&quot;,&quot;Loading and exploring a JSON&quot;,&quot;aggregate_xp&quot;,100,&quot;number&quot;,3,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/interacting-with-apis-to-import-data-from-the-web-2?ex=3&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;MultipleChoiceExercise&quot;,&quot;title&quot;,&quot;Pop quiz: Exploring your JSON&quot;,&quot;aggregate_xp&quot;,50,&quot;number&quot;,4,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/interacting-with-apis-to-import-data-from-the-web-2?ex=4&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;VideoExercise&quot;,&quot;title&quot;,&quot;APIs and interacting with the world wide web&quot;,&quot;aggregate_xp&quot;,50,&quot;number&quot;,5,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/interacting-with-apis-to-import-data-from-the-web-2?ex=5&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;PureMultipleChoiceExercise&quot;,&quot;title&quot;,&quot;Pop quiz: What&#39;s an API?&quot;,&quot;aggregate_xp&quot;,50,&quot;number&quot;,6,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/interacting-with-apis-to-import-data-from-the-web-2?ex=6&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;NormalExercise&quot;,&quot;title&quot;,&quot;API requests&quot;,&quot;aggregate_xp&quot;,100,&quot;number&quot;,7,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/interacting-with-apis-to-import-data-from-the-web-2?ex=7&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;NormalExercise&quot;,&quot;title&quot;,&quot;JSON\\xe2\\x80\\x93from the web to Python&quot;,&quot;aggregate_xp&quot;,100,&quot;number&quot;,8,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/interacting-with-apis-to-import-data-from-the-web-2?ex=8&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;NormalExercise&quot;,&quot;title&quot;,&quot;Checking out the Wikipedia API&quot;,&quot;aggregate_xp&quot;,100,&quot;number&quot;,9,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/interacting-with-apis-to-import-data-from-the-web-2?ex=9&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]]]],&quot;description&quot;,&quot;In this chapter, you will gain a deeper understanding of how to import data from the web. You will learn the basics of extracting data from APIs, gain insight on the importance of APIs, and practice extracting data by diving into the OMDB and Library of Congress APIs.&quot;,&quot;badge_completed_url&quot;,&quot;https://assets.datacamp.com/production/default/badges/missing.png&quot;]],[&quot;^?&quot;,[&quot;badge_uncompleted_url&quot;,&quot;https://assets.datacamp.com/production/default/badges/missing_unc.png&quot;,&quot;number&quot;,3,&quot;number_of_videos&quot;,2,&quot;slug&quot;,&quot;diving-deep-into-the-twitter-api&quot;,&quot;last_updated_on&quot;,&quot;26/09/2024&quot;,&quot;title_meta&quot;,null,&quot;nb_exercises&quot;,7,&quot;free_preview&quot;,null,&quot;slides_link&quot;,&quot;https://projector-video-pdf-converter.datacamp.com/1606/chapter3.pdf&quot;,&quot;title&quot;,&quot;Diving  deep into the Twitter API&quot;,&quot;xp&quot;,600,&quot;id&quot;,4140,&quot;exercises&quot;,[&quot;^@&quot;,[[&quot;^?&quot;,[&quot;type&quot;,&quot;VideoExercise&quot;,&quot;title&quot;,&quot;The Twitter API and Authentication&quot;,&quot;aggregate_xp&quot;,50,&quot;number&quot;,1,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/diving-deep-into-the-twitter-api?ex=1&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;NormalExercise&quot;,&quot;title&quot;,&quot;Streaming tweets&quot;,&quot;aggregate_xp&quot;,100,&quot;number&quot;,2,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/diving-deep-into-the-twitter-api?ex=2&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;NormalExercise&quot;,&quot;title&quot;,&quot;Load and explore your Twitter data&quot;,&quot;aggregate_xp&quot;,100,&quot;number&quot;,3,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/diving-deep-into-the-twitter-api?ex=3&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;NormalExercise&quot;,&quot;title&quot;,&quot;Twitter data to DataFrame&quot;,&quot;aggregate_xp&quot;,100,&quot;number&quot;,4,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/diving-deep-into-the-twitter-api?ex=4&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;NormalExercise&quot;,&quot;title&quot;,&quot;A little bit of Twitter text analysis&quot;,&quot;aggregate_xp&quot;,100,&quot;number&quot;,5,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/diving-deep-into-the-twitter-api?ex=5&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;NormalExercise&quot;,&quot;title&quot;,&quot;Plotting your Twitter data&quot;,&quot;aggregate_xp&quot;,100,&quot;number&quot;,6,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/diving-deep-into-the-twitter-api?ex=6&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;VideoExercise&quot;,&quot;title&quot;,&quot;Final Thoughts&quot;,&quot;aggregate_xp&quot;,50,&quot;number&quot;,7,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/diving-deep-into-the-twitter-api?ex=7&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]]]],&quot;description&quot;,&quot;In this chapter, you will consolidate your knowledge of interacting with APIs in a deep dive into the Twitter streaming API. You&#39;ll learn how to stream real-time Twitter data, and how to analyze and visualize it.&quot;,&quot;badge_completed_url&quot;,&quot;https://assets.datacamp.com/production/default/badges/missing.png&quot;]]]],&quot;time_needed&quot;,null,&quot;author_image&quot;,&quot;https://assets.datacamp.com/production/course_1606/author_images/author_image_course_1606_20200310-1-lgdj4c?1583853939&quot;,&quot;tracks&quot;,[&quot;^@&quot;,[[&quot;^?&quot;,[&quot;path&quot;,&quot;/tracks/data-engineer-in-python&quot;,&quot;title_with_subtitle&quot;,&quot;Data Engineer in Python&quot;]],[&quot;^?&quot;,[&quot;path&quot;,&quot;/tracks/data-scientist-in-python&quot;,&quot;title_with_subtitle&quot;,&quot;Data Scientist in Python&quot;]],[&quot;^?&quot;,[&quot;path&quot;,&quot;/tracks/importing-cleaning-data-with-python&quot;,&quot;title_with_subtitle&quot;,&quot;Importing &amp; Cleaning Data  in Python&quot;]]]],&quot;runtime_config&quot;,null,&quot;lti_only&quot;,false,&quot;image_url&quot;,&quot;https://assets.datacamp.com/production/course_1606/shields/thumb/shield_image_course_1606_20200310-1-17hkmhz?1583853940&quot;,&quot;topic_id&quot;,18,&quot;slug&quot;,&quot;intermediate-importing-data-in-python&quot;,&quot;last_updated_on&quot;,&quot;11/10/2024&quot;,&quot;audio_recorders&quot;,[&quot;^@&quot;,[]],&quot;paid&quot;,true,&quot;collaborators&quot;,[&quot;^@&quot;,[[&quot;^?&quot;,[&quot;avatar_url&quot;,&quot;https://assets.datacamp.com/authors/avatars/000/000/058/square/francis-photo.jpg?1705506690&quot;,&quot;full_name&quot;,&quot;Francisco Castro&quot;]]]],&quot;difficulty_level_hardcoded&quot;,null,&quot;time_needed_in_hours&quot;,2,&quot;technology_id&quot;,2,&quot;university&quot;,null,&quot;archived_at&quot;,null,&quot;state&quot;,&quot;live&quot;,&quot;content_area&quot;,&quot;Data Science and Analytics&quot;,&quot;author_bio&quot;,null,&quot;is_labeled_as_new&quot;,null,&quot;should_cache&quot;,true,&quot;sharing_links&quot;,[&quot;^?&quot;,[&quot;twitter&quot;,&quot;http://bit.ly/1eWTMJh&quot;,&quot;facebook&quot;,&quot;http://bit.ly/1iS42Do&quot;]],&quot;instructors&quot;,[&quot;^@&quot;,[[&quot;^?&quot;,[&quot;id&quot;,301837,&quot;marketing_biography&quot;,&quot;Data Scientist&quot;,&quot;biography&quot;,&quot;Hugo is a data scientist, educator, writer and podcaster formerly at DataCamp. His main interests are promoting data &amp; AI literacy, helping to spread data skills through organizations and society and doing amateur stand up comedy in NYC. If you want to know what he likes to talk about, definitely check out &lt;a href=\\\\\\\\&quot;https://www.datacamp.com/community/podcast\\\\\\\\&quot;&gt;DataFramed&lt;/a&gt;, the DataCamp podcast, which he hosted and produced.&quot;,&quot;avatar_url&quot;,&quot;https://assets.datacamp.com/authors/avatars/000/000/006/square/hugoaboutpic.jpg?1705506415&quot;,&quot;full_name&quot;,&quot;Hugo Bowne-Anderson&quot;,&quot;instructor_path&quot;,&quot;/instructors/hugobowne&quot;]]]],&quot;translated_course_id&quot;,1606,&quot;seo_title&quot;,&quot;Intermediate Importing Data in Python&quot;,&quot;industry_ids&quot;,[&quot;^@&quot;,[]],&quot;title&quot;,&quot;Intermediate Importing Data in Python&quot;,&quot;xp&quot;,2300,&quot;image_thumbnail_url&quot;,&quot;https://assets.datacamp.com/production/course_1606/shields/thumb_home/shield_image_course_1606_20200310-1-17hkmhz?1583853940&quot;,&quot;short_description&quot;,&quot;Improve your Python data importing skills and learn to work with web and API data.&quot;,&quot;nb_of_subscriptions&quot;,179489,&quot;long_description&quot;,null,&quot;seo_description&quot;,&quot;Learn how to import data into Python from sources like the web and by pulling data from APIs, such as the Twitter streaming API to stream real-time tweets.&quot;,&quot;type&quot;,&quot;datacamp&quot;,&quot;link&quot;,&quot;https://www.datacamp.com/courses/intermediate-importing-data-in-python&quot;,&quot;case_study&quot;,null,&quot;id&quot;,1606,&quot;datasets&quot;,[&quot;^@&quot;,[[&quot;^?&quot;,[&quot;asset_url&quot;,&quot;https://assets.datacamp.com/production/repositories/488/datasets/b422ace2fceada7b569e0ba3e8d833fddc684c4d/latitude.xls&quot;,&quot;name&quot;,&quot;Latitudes (XLS)&quot;]],[&quot;^?&quot;,[&quot;asset_url&quot;,&quot;https://assets.datacamp.com/production/repositories/488/datasets/3ef452f83a91556ea4284624b969392c0506fb33/tweets3.txt&quot;,&quot;name&quot;,&quot;Tweets&quot;]],[&quot;^?&quot;,[&quot;asset_url&quot;,&quot;https://assets.datacamp.com/production/repositories/488/datasets/013936d2700e2d00207ec42100d448c23692eb6f/winequality-red.csv&quot;,&quot;name&quot;,&quot;Red wine quality&quot;]]]],&quot;description&quot;,&quot;As a data scientist, you will need to clean data, wrangle and munge it, visualize it, build predictive models and interpret these models. Before you can do so, however, you will need to know how to get data into Python. In the prequel to this course, you learned many ways to import data into Python: from flat files such as .txt and .csv; from files native to other software such as Excel spreadsheets, Stata, SAS, and MATLAB files; and from relational databases such as SQLite and PostgreSQL. In this course, you&#39;ll extend this knowledge base by learning to import data from the web and by pulling data from Application Programming Interfaces\\xe2\\x80\\x94 APIs\\xe2\\x80\\x94such as the Twitter streaming API, which allows us to stream real-time tweets.&quot;,&quot;prerequisites&quot;,[&quot;^@&quot;,[[&quot;^?&quot;,[&quot;path&quot;,&quot;/courses/introduction-to-importing-data-in-python&quot;,&quot;title&quot;,&quot;Introduction to Importing Data in Python&quot;]]]],&quot;original_image_url&quot;,&quot;https://assets.datacamp.com/production/course_1606/shields/original/shield_image_course_1606_20200310-1-17hkmhz?1583853940&quot;,&quot;programming_language&quot;,&quot;python&quot;,&quot;external_slug&quot;,&quot;intermediate-importing-data-in-python&quot;]],&quot;exercises&quot;,[&quot;^?&quot;,[&quot;current&quot;,1,&quot;all&quot;,[&quot;^@&quot;,[[&quot;^?&quot;,[&quot;sample_code&quot;,&quot;&quot;,&quot;sct&quot;,&quot;&quot;,&quot;aspect_ratio&quot;,56.25,&quot;instructions&quot;,null,&quot;externalId&quot;,990668,&quot;question&quot;,&quot;&quot;,&quot;hint&quot;,null,&quot;possible_answers&quot;,[&quot;^@&quot;,[]],&quot;runtime_config&quot;,null,&quot;number&quot;,1,&quot;video_hls&quot;,null,&quot;randomNumber&quot;,0.8364573381546423,&quot;chapter_id&quot;,4135,&quot;assignment&quot;,null,&quot;feedbacks&quot;,[&quot;^@&quot;,[]],&quot;attachments&quot;,null,&quot;exercise_image&quot;,null,&quot;version&quot;,&quot;v0&quot;,&quot;title&quot;,&quot;Importing flat files from the web&quot;,&quot;xp&quot;,50,&quot;language&quot;,&quot;python&quot;,&quot;pre_exercise_code&quot;,&quot;&quot;,&quot;solution&quot;,&quot;&quot;,&quot;type&quot;,&quot;VideoExercise&quot;,&quot;id&quot;,990668,&quot;projector_key&quot;,&quot;course_1606_59604c018a6e132016cd26144a12fee0&quot;,&quot;video_link&quot;,null,&quot;programming_language&quot;,null,&quot;key&quot;,&quot;e36457c7ed&quot;,&quot;course_id&quot;,1606]],[&quot;^?&quot;,[&quot;sample_code&quot;,&quot;# Import package\\\\\\\\nfrom ____ import ____\\\\\\\\n\\\\\\\\n# Import pandas\\\\\\\\nimport pandas as pd\\\\\\\\n\\\\\\\\n# Assign url of file: url\\\\\\\\n\\\\\\\\n\\\\\\\\n# Save file locally\\\\\\\\n\\\\\\\\n\\\\\\\\n# Read file into a DataFrame and print its head\\\\\\\\ndf = pd.read_csv(&#39;winequality-red.csv&#39;, sep=&#39;;&#39;)\\\\\\\\nprint(df.head())&quot;,&quot;sct&quot;,&quot;Ex().has_import(\\\\\\\\&quot;urllib.request.urlretrieve\\\\\\\\&quot;)\\\\\\\\nEx().has_import(\\\\\\\\&quot;pandas\\\\\\\\&quot;)\\\\\\\\nEx().check_object(\\\\\\\\&quot;url\\\\\\\\&quot;).has_equal_value()\\\\\\\\nEx().check_function(\\\\\\\\&quot;urllib.request.urlretrieve\\\\\\\\&quot;).multi(\\\\\\\\n  check_args(0).has_equal_value(),\\\\\\\\n  check_args(1).has_equal_value()\\\\\\\\n)\\\\\\\\nEx().check_correct(\\\\\\\\n  check_object(\\\\\\\\&quot;df\\\\\\\\&quot;).has_equal_value(),\\\\\\\\n  check_function(\\\\\\\\&quot;pandas.read_csv\\\\\\\\&quot;).multi(\\\\\\\\n    check_args(0).has_equal_value(),\\\\\\\\n    check_args(1).has_equal_value()\\\\\\\\n  )\\\\\\\\n)\\\\\\\\nEx().has_printout(0)\\\\\\\\nsuccess_msg(\\\\\\\\&quot;Awesome!\\\\\\\\&quot;)\\\\\\\\n&quot;,&quot;instructions&quot;,&quot;&lt;ul&gt;\\\\\\\\n&lt;li&gt;Import the function &lt;code&gt;urlretrieve&lt;/code&gt; from the subpackage &lt;code&gt;urllib.request&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;li&gt;Assign the URL of the file to the variable &lt;code&gt;url&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;li&gt;Use the function &lt;code&gt;urlretrieve()&lt;/code&gt; to save the file locally as &lt;code&gt;&#39;winequality-red.csv&#39;&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;li&gt;Execute the remaining code to load &lt;code&gt;&#39;winequality-red.csv&#39;&lt;/code&gt; in a pandas DataFrame and to print its head to the shell.&lt;/li&gt;\\\\\\\\n&lt;/ul&gt;&quot;,&quot;externalId&quot;,42707,&quot;question&quot;,&quot;&quot;,&quot;hint&quot;,&quot;&lt;ul&gt;\\\\\\\\n&lt;li&gt;To import a function &lt;code&gt;y&lt;/code&gt; from a subpackage &lt;code&gt;x&lt;/code&gt;, execute &lt;code&gt;from x import y&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;li&gt;This one&#39;s a long URL. Make sure you typed it in correctly!&lt;/li&gt;\\\\\\\\n&lt;li&gt;Pass the &lt;em&gt;url&lt;/em&gt; to import (in the &lt;code&gt;url&lt;/code&gt; object you defined) as the first argument and the &lt;em&gt;filename&lt;/em&gt; for saving the file locally as the second argument to &lt;code&gt;urlretrieve()&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;li&gt;You don&#39;t have to change the code for loading &lt;code&gt;&#39;winequality-red.csv&#39;&lt;/code&gt; and printing its head.&lt;/li&gt;\\\\\\\\n&lt;/ul&gt;&quot;,&quot;possible_answers&quot;,[&quot;^@&quot;,[]],&quot;runtime_config&quot;,null,&quot;number&quot;,2,&quot;user&quot;,[&quot;^?&quot;,[&quot;isHintShown&quot;,false,&quot;usedAiFeatures&quot;,[&quot;^?&quot;,[&quot;aiIncorrectSubmissions&quot;,false,&quot;aiErrorExplanations&quot;,false]],&quot;lastRunCode&quot;,null,&quot;editorTabs&quot;,[&quot;^?&quot;,[&quot;files/script.py&quot;,[&quot;^?&quot;,[&quot;title&quot;,&quot;script.py&quot;,&quot;isSolution&quot;,false,&quot;props&quot;,[&quot;^?&quot;,[&quot;active&quot;,true,&quot;isClosable&quot;,false,&quot;code&quot;,null,&quot;extra&quot;,[&quot;^?&quot;,[]]]]]]]],&quot;outputMarkdownTabs&quot;,[&quot;^?&quot;,[]],&quot;markdown&quot;,[&quot;^?&quot;,[&quot;titles&quot;,[&quot;^@&quot;,[&quot;Knit PDF&quot;,&quot;Knit HTML&quot;]],&quot;activeTitle&quot;,&quot;Knit HTML&quot;]],&quot;currentXp&quot;,100,&quot;graphicalTabs&quot;,[&quot;^?&quot;,[&quot;plot&quot;,[&quot;^?&quot;,[&quot;extraClass&quot;,&quot;animation--flash&quot;,&quot;title&quot;,&quot;Plots&quot;,&quot;props&quot;,[&quot;^?&quot;,[&quot;sources&quot;,[&quot;^@&quot;,[]],&quot;currentIndex&quot;,0]],&quot;dimension&quot;,[&quot;^?&quot;,[&quot;isRealSize&quot;,false,&quot;width&quot;,1,&quot;height&quot;,1]]]],&quot;html&quot;,[&quot;^?&quot;,[&quot;extraClass&quot;,&quot;animation--flash&quot;,&quot;title&quot;,&quot;HTML Viewer&quot;,&quot;props&quot;,[&quot;^?&quot;,[&quot;sources&quot;,[&quot;^@&quot;,[]],&quot;currentIndex&quot;,0]]]]]],&quot;feedbackMessages&quot;,[&quot;^@&quot;,[]],&quot;lastSubmittedCode&quot;,null,&quot;ltiStatus&quot;,[&quot;^?&quot;,[]],&quot;lastSubmitActiveEditorTab&quot;,null,&quot;consoleSqlTabs&quot;,[&quot;^?&quot;,[&quot;query_result&quot;,[&quot;^?&quot;,[&quot;extraClass&quot;,&quot;&quot;,&quot;title&quot;,&quot;query result&quot;,&quot;props&quot;,[&quot;^?&quot;,[&quot;active&quot;,true,&quot;isNotView&quot;,true,&quot;message&quot;,&quot;No query executed yet...&quot;]]]]]],&quot;consoleTabs&quot;,[&quot;^?&quot;,[&quot;console&quot;,[&quot;^?&quot;,[&quot;title&quot;,&quot;IPython Shell&quot;,&quot;props&quot;,[&quot;^?&quot;,[&quot;active&quot;,true]],&quot;dimension&quot;,[&quot;^?&quot;,[&quot;cols&quot;,400]]]],&quot;slides&quot;,[&quot;^?&quot;,[&quot;title&quot;,&quot;Slides&quot;,&quot;props&quot;,[&quot;^?&quot;,[&quot;active&quot;,false]]]]]],&quot;inputMarkdownTabs&quot;,[&quot;^?&quot;,[]],&quot;consoleObjectViewTabs&quot;,[&quot;^?&quot;,[]]]],&quot;randomNumber&quot;,0.13306885324133644,&quot;assignment&quot;,&quot;&lt;p&gt;You are about to import your first file from the web! The flat file you will import will be &lt;code&gt;&#39;winequality-red.csv&#39;&lt;/code&gt; from the University of California, Irvine&#39;s &lt;a href=\\\\\\\\&quot;https://archive.ics.uci.edu/ml/index.php\\\\\\\\&quot;&gt;Machine Learning repository&lt;/a&gt;. The flat file contains tabular data of physiochemical properties of red wine, such as pH, alcohol content and citric acid content, along with wine quality rating.&lt;/p&gt;\\\\\\\\n&lt;p&gt;The URL of the file is&lt;/p&gt;\\\\\\\\n&lt;pre&gt;&lt;code&gt;&#39;https://assets.datacamp.com/production/course_1606/datasets/winequality-red.csv&#39;\\\\\\\\n&lt;/code&gt;&lt;/pre&gt;\\\\\\\\n&lt;p&gt;After you import it, you&#39;ll check your working directory to confirm that it is there and then you&#39;ll load it into a &lt;code&gt;pandas&lt;/code&gt; DataFrame.&lt;/p&gt;&quot;,&quot;feedbacks&quot;,[&quot;^@&quot;,[]],&quot;attachments&quot;,null,&quot;exercise_image&quot;,null,&quot;title&quot;,&quot;Importing flat files from the web: your turn!&quot;,&quot;xp&quot;,100,&quot;language&quot;,&quot;python&quot;,&quot;pre_exercise_code&quot;,&quot;&quot;,&quot;solution&quot;,&quot;# Import package\\\\\\\\nfrom urllib.request import urlretrieve\\\\\\\\n\\\\\\\\n# Import pandas\\\\\\\\nimport pandas as pd\\\\\\\\n\\\\\\\\n# Assign url of file: url\\\\\\\\nurl = &#39;https://assets.datacamp.com/production/course_1606/datasets/winequality-red.csv&#39;\\\\\\\\n\\\\\\\\n# Save file locally\\\\\\\\nurlretrieve(url, &#39;winequality-red.csv&#39;)\\\\\\\\n\\\\\\\\n# Read file into a DataFrame and print its head\\\\\\\\ndf = pd.read_csv(&#39;winequality-red.csv&#39;, sep=&#39;;&#39;)\\\\\\\\nprint(df.head())&quot;,&quot;type&quot;,&quot;NormalExercise&quot;,&quot;id&quot;,42707,&quot;programming_language&quot;,null]],[&quot;^?&quot;,[&quot;sample_code&quot;,&quot;# Import packages\\\\\\\\nimport matplotlib.pyplot as plt\\\\\\\\nimport pandas as pd\\\\\\\\n\\\\\\\\n# Assign url of file: url\\\\\\\\n\\\\\\\\n\\\\\\\\n# Read file into a DataFrame: df\\\\\\\\n\\\\\\\\n\\\\\\\\n# Print the head of the DataFrame\\\\\\\\nprint(____)\\\\\\\\n\\\\\\\\n# Plot first column of df\\\\\\\\ndf.iloc[:, 0].hist()\\\\\\\\nplt.xlabel(&#39;fixed acidity (g(tartaric acid)/dm$^3$)&#39;)\\\\\\\\nplt.ylabel(&#39;count&#39;)\\\\\\\\nplt.show()\\\\\\\\n&quot;,&quot;sct&quot;,&quot;Ex().has_import(\\\\\\\\&quot;matplotlib.pyplot\\\\\\\\&quot;)\\\\\\\\nEx().has_import(\\\\\\\\&quot;pandas\\\\\\\\&quot;)\\\\\\\\nEx().check_object(\\\\\\\\&quot;url\\\\\\\\&quot;).has_equal_value()\\\\\\\\nEx().check_correct(\\\\\\\\n  check_object(\\\\\\\\&quot;df\\\\\\\\&quot;).has_equal_value(),\\\\\\\\n  check_function(\\\\\\\\&quot;pandas.read_csv\\\\\\\\&quot;).multi(\\\\\\\\n    check_args(0).has_equal_value(),\\\\\\\\n    check_args(1).has_equal_value()\\\\\\\\n  )\\\\\\\\n)\\\\\\\\nEx().has_printout(0)\\\\\\\\nEx().has_equal_ast(code=\\\\\\\\&quot;df.iloc[:, 0].hist\\\\\\\\&quot;, incorrect_msg=\\\\\\\\&quot;Please do not change the code to plot the histogram.\\\\\\\\&quot;)\\\\\\\\nEx().check_function(\\\\\\\\&quot;matplotlib.pyplot.show\\\\\\\\&quot;)\\\\\\\\n\\\\\\\\nsuccess_msg(\\\\\\\\&quot;Awesome!\\\\\\\\&quot;)\\\\\\\\n&quot;,&quot;instructions&quot;,&quot;&lt;ul&gt;\\\\\\\\n&lt;li&gt;Assign the URL of the file to the variable &lt;code&gt;url&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;li&gt;Read file into a DataFrame &lt;code&gt;df&lt;/code&gt; using &lt;code&gt;pd.read_csv()&lt;/code&gt;, recalling that the separator in the file is &lt;code&gt;&#39;;&#39;&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;li&gt;Print the head of the DataFrame &lt;code&gt;df&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;li&gt;Execute the rest of the code to plot histogram of the first feature in the DataFrame &lt;code&gt;df&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;/ul&gt;&quot;,&quot;externalId&quot;,42708,&quot;question&quot;,&quot;&quot;,&quot;hint&quot;,&quot;&lt;ul&gt;\\\\\\\\n&lt;li&gt;Make sure you typed the URL correctly!&lt;/li&gt;\\\\\\\\n&lt;li&gt;Pass the &lt;em&gt;url&lt;/em&gt; (the &lt;code&gt;url&lt;/code&gt; object you defined) as the first argument and the &lt;em&gt;separator&lt;/em&gt; as the second argument to &lt;code&gt;pd.read_csv()&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;li&gt;The &lt;em&gt;head&lt;/em&gt; of a DataFrame can be accessed by using &lt;code&gt;head()&lt;/code&gt; on the DataFrame.&lt;/li&gt;\\\\\\\\n&lt;li&gt;You don&#39;t have to change any of the code for plotting the histograms.&lt;/li&gt;\\\\\\\\n&lt;/ul&gt;&quot;,&quot;possible_answers&quot;,[&quot;^@&quot;,[]],&quot;runtime_config&quot;,null,&quot;number&quot;,3,&quot;randomNumber&quot;,0.7785533906387767,&quot;assignment&quot;,&quot;&lt;p&gt;You have just imported a file from the web, saved it locally and loaded it into a DataFrame. If you just wanted to load a file from the web into a DataFrame without first saving it locally, you can do that easily using &lt;code&gt;pandas&lt;/code&gt;. In particular, you can use the function &lt;code&gt;pd.read_csv()&lt;/code&gt; with the URL as the first argument and the separator &lt;code&gt;sep&lt;/code&gt; as the second argument.&lt;/p&gt;\\\\\\\\n&lt;p&gt;The URL of the file, once again, is&lt;/p&gt;\\\\\\\\n&lt;pre&gt;&lt;code&gt;&#39;https://assets.datacamp.com/production/course_1606/datasets/winequality-red.csv&#39;\\\\\\\\n&lt;/code&gt;&lt;/pre&gt;&quot;,&quot;feedbacks&quot;,[&quot;^@&quot;,[]],&quot;attachments&quot;,null,&quot;exercise_image&quot;,null,&quot;title&quot;,&quot;Opening and reading flat files from the web&quot;,&quot;xp&quot;,100,&quot;language&quot;,&quot;python&quot;,&quot;pre_exercise_code&quot;,&quot;&quot;,&quot;solution&quot;,&quot;# Import packages\\\\\\\\nimport matplotlib.pyplot as plt\\\\\\\\nimport pandas as pd\\\\\\\\n\\\\\\\\n# Assign url of file: url\\\\\\\\nurl = &#39;https://assets.datacamp.com/production/course_1606/datasets/winequality-red.csv&#39;\\\\\\\\n\\\\\\\\n# Read file into a DataFrame: df\\\\\\\\ndf = pd.read_csv(url, sep=&#39;;&#39;)\\\\\\\\n\\\\\\\\n# Print the head of the DataFrame\\\\\\\\nprint(df.head())\\\\\\\\n\\\\\\\\n# Plot first column of df\\\\\\\\ndf.iloc[:, 0].hist()\\\\\\\\nplt.xlabel(&#39;fixed acidity (g(tartaric acid)/dm$^3$)&#39;)\\\\\\\\nplt.ylabel(&#39;count&#39;)\\\\\\\\nplt.show()\\\\\\\\n&quot;,&quot;type&quot;,&quot;NormalExercise&quot;,&quot;id&quot;,42708,&quot;programming_language&quot;,null]],[&quot;^?&quot;,[&quot;sample_code&quot;,&quot;# Import package\\\\\\\\nimport pandas as pd\\\\\\\\n\\\\\\\\n# Assign url of file: url\\\\\\\\n\\\\\\\\n\\\\\\\\n# Read in all sheets of Excel file: xls\\\\\\\\n\\\\\\\\n\\\\\\\\n# Print the sheetnames to the shell\\\\\\\\n\\\\\\\\n\\\\\\\\n# Print the head of the first sheet (using its name, NOT its index)\\\\\\\\n\\\\\\\\n&quot;,&quot;sct&quot;,&quot;Ex().has_import(&#39;pandas&#39;)\\\\\\\\nEx().check_correct(\\\\\\\\n    has_printout(0),\\\\\\\\n    multi(\\\\\\\\n        check_correct(\\\\\\\\n            check_object(&#39;xls&#39;).is_instance(dict),\\\\\\\\n            check_correct(\\\\\\\\n                check_function(&#39;pandas.read_excel&#39;).multi(\\\\\\\\n                    check_args(0).has_equal_value(),\\\\\\\\n                    check_args(&#39;sheet_name&#39;).has_equal_value()\\\\\\\\n                ),\\\\\\\\n                check_object(&#39;url&#39;).has_equal_value()\\\\\\\\n            )\\\\\\\\n        )\\\\\\\\n    )\\\\\\\\n)\\\\\\\\nEx().has_printout(1)\\\\\\\\nsuccess_msg(\\\\\\\\&quot;Awesome!\\\\\\\\&quot;)&quot;,&quot;instructions&quot;,&quot;&lt;ul&gt;\\\\\\\\n&lt;li&gt;Assign the URL of the file to the variable &lt;code&gt;url&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;li&gt;Read the file in &lt;code&gt;url&lt;/code&gt; into a dictionary &lt;code&gt;xls&lt;/code&gt; using &lt;code&gt;pd.read_excel()&lt;/code&gt; recalling that, in order to import all sheets you need to pass &lt;code&gt;None&lt;/code&gt; to the argument &lt;code&gt;sheet_name&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;li&gt;Print the names of the sheets in the Excel spreadsheet; these will be the keys of the dictionary &lt;code&gt;xls&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;li&gt;Print the head of the first sheet &lt;em&gt;using the sheet name, not the index of the sheet&lt;/em&gt;! The sheet name is &lt;code&gt;&#39;1700&#39;&lt;/code&gt;&lt;/li&gt;\\\\\\\\n&lt;/ul&gt;&quot;,&quot;externalId&quot;,42709,&quot;question&quot;,&quot;&quot;,&quot;hint&quot;,&quot;&lt;ul&gt;\\\\\\\\n&lt;li&gt;Make sure you typed in the URL correctly!&lt;/li&gt;\\\\\\\\n&lt;li&gt;Pass the &lt;em&gt;url&lt;/em&gt; (the &lt;code&gt;url&lt;/code&gt; object you defined) as the first argument and &lt;code&gt;sheet_name&lt;/code&gt; with its corresponding value as the second argument to &lt;code&gt;pd.read_excel()&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;li&gt;The &lt;em&gt;keys&lt;/em&gt; of a dictionary can be accessed by using &lt;code&gt;keys()&lt;/code&gt; on the dictionary.&lt;/li&gt;\\\\\\\\n&lt;li&gt;You can access a sheet using the format: &lt;em&gt;dictionary&lt;/em&gt;&lt;strong&gt;[&lt;/strong&gt;&lt;em&gt;sheet name or index&lt;/em&gt;&lt;strong&gt;]&lt;/strong&gt;.&lt;/li&gt;\\\\\\\\n&lt;/ul&gt;&quot;,&quot;possible_answers&quot;,[&quot;^@&quot;,[]],&quot;runtime_config&quot;,null,&quot;number&quot;,4,&quot;randomNumber&quot;,0.29677029636305896,&quot;assignment&quot;,&quot;&lt;p&gt;Congrats! You&#39;ve just loaded a flat file from the web into a DataFrame without first saving it locally using the &lt;code&gt;pandas&lt;/code&gt; function &lt;code&gt;pd.read_csv()&lt;/code&gt;. This function is super cool because it has close relatives that allow you to load all types of files, not only flat ones. In this interactive exercise, you&#39;ll use &lt;code&gt;pd.read_excel()&lt;/code&gt; to import an Excel spreadsheet.&lt;/p&gt;\\\\\\\\n&lt;p&gt;The URL of the spreadsheet is&lt;/p&gt;\\\\\\\\n&lt;pre&gt;&lt;code&gt;&#39;https://assets.datacamp.com/course/importing_data_into_r/latitude.xls&#39;\\\\\\\\n&lt;/code&gt;&lt;/pre&gt;\\\\\\\\n&lt;p&gt;Your job is to use &lt;code&gt;pd.read_excel()&lt;/code&gt; to read in all of its sheets, print the sheet names and then print the head of the first sheet &lt;em&gt;using its name, not its index&lt;/em&gt;.&lt;/p&gt;\\\\\\\\n&lt;p&gt;Note that the output of &lt;code&gt;pd.read_excel()&lt;/code&gt; is a Python dictionary with sheet names as keys and corresponding DataFrames as corresponding values.&lt;/p&gt;&quot;,&quot;feedbacks&quot;,[&quot;^@&quot;,[]],&quot;attachments&quot;,null,&quot;exercise_image&quot;,null,&quot;title&quot;,&quot;Importing non-flat files from the web&quot;,&quot;xp&quot;,100,&quot;language&quot;,&quot;python&quot;,&quot;pre_exercise_code&quot;,&quot;&quot;,&quot;solution&quot;,&quot;# Import package\\\\\\\\nimport pandas as pd\\\\\\\\n\\\\\\\\n# Assign url of file: url\\\\\\\\nurl = &#39;https://assets.datacamp.com/course/importing_data_into_r/latitude.xls&#39;\\\\\\\\n\\\\\\\\n# Read in all sheets of Excel file: xls\\\\\\\\nxls = pd.read_excel(url, sheet_name=None)\\\\\\\\n\\\\\\\\n# Print the sheetnames to the shell\\\\\\\\nprint(xls.keys())\\\\\\\\n\\\\\\\\n# Print the head of the first sheet (using its name, NOT its index)\\\\\\\\nprint(xls[&#39;1700&#39;].head())&quot;,&quot;type&quot;,&quot;NormalExercise&quot;,&quot;id&quot;,42709,&quot;programming_language&quot;,null]],[&quot;^?&quot;,[&quot;sample_code&quot;,&quot;&quot;,&quot;sct&quot;,&quot;&quot;,&quot;aspect_ratio&quot;,56.25,&quot;instructions&quot;,null,&quot;externalId&quot;,990669,&quot;question&quot;,&quot;&quot;,&quot;hint&quot;,null,&quot;possible_answers&quot;,[&quot;^@&quot;,[]],&quot;runtime_config&quot;,null,&quot;number&quot;,5,&quot;video_hls&quot;,null,&quot;randomNumber&quot;,0.08513839239732768,&quot;chapter_id&quot;,4135,&quot;assignment&quot;,null,&quot;feedbacks&quot;,[&quot;^@&quot;,[]],&quot;attachments&quot;,null,&quot;exercise_image&quot;,null,&quot;version&quot;,&quot;v0&quot;,&quot;title&quot;,&quot;HTTP requests to import files from the web&quot;,&quot;xp&quot;,50,&quot;language&quot;,&quot;python&quot;,&quot;pre_exercise_code&quot;,&quot;&quot;,&quot;solution&quot;,&quot;&quot;,&quot;type&quot;,&quot;VideoExercise&quot;,&quot;id&quot;,990669,&quot;projector_key&quot;,&quot;course_1606_9d15ae176be1800b996f7869a82b8087&quot;,&quot;video_link&quot;,null,&quot;programming_language&quot;,null,&quot;key&quot;,&quot;e480d1fdcf&quot;,&quot;course_id&quot;,1606]],[&quot;^?&quot;,[&quot;sample_code&quot;,&quot;# Import packages\\\\\\\\n\\\\\\\\n\\\\\\\\n# Specify the url\\\\\\\\nurl = \\\\\\\\&quot;https://campus.datacamp.com/courses/1606/4135?ex=2\\\\\\\\&quot;\\\\\\\\n\\\\\\\\n# This packages the request: request\\\\\\\\n\\\\\\\\n\\\\\\\\n# Sends the request and catches the response: response\\\\\\\\n\\\\\\\\n\\\\\\\\n# Print the datatype of response\\\\\\\\nprint(type(response))\\\\\\\\n\\\\\\\\n# Be polite and close the response!\\\\\\\\nresponse.close()\\\\\\\\n&quot;,&quot;sct&quot;,&quot;\\\\\\\\n# Test: import urlopen, Request\\\\\\\\nimport_msg = \\\\\\\\&quot;Did you correctly import the required packages?\\\\\\\\&quot;\\\\\\\\nEx().has_import(\\\\\\\\n    \\\\\\\\&quot;urllib.request.urlopen\\\\\\\\&quot;,\\\\\\\\n    not_imported_msg=import_msg\\\\\\\\n)\\\\\\\\nEx().has_import(\\\\\\\\n    \\\\\\\\&quot;urllib.request.Request\\\\\\\\&quot;,\\\\\\\\n    not_imported_msg=import_msg\\\\\\\\n)\\\\\\\\n\\\\\\\\n# Test: Predefined code\\\\\\\\npredef_msg = \\\\\\\\&quot;You don&#39;t have to change any of the predefined code.\\\\\\\\&quot;\\\\\\\\nEx().check_object(\\\\\\\\&quot;url\\\\\\\\&quot;, missing_msg=predef_msg).has_equal_value(incorrect_msg = predef_msg)\\\\\\\\n\\\\\\\\n# Test: call to Request() and &#39;request&#39; variable\\\\\\\\nEx().check_function(\\\\\\\\&quot;urllib.request.Request\\\\\\\\&quot;).check_args(0).has_equal_value()\\\\\\\\nEx().check_object(\\\\\\\\&quot;request\\\\\\\\&quot;)\\\\\\\\n  \\\\\\\\n# Test: call to urlopen() and &#39;response&#39; variable\\\\\\\\nEx().check_function(\\\\\\\\&quot;urllib.request.urlopen\\\\\\\\&quot;).check_args(0).has_equal_ast()\\\\\\\\nEx().check_object(\\\\\\\\&quot;response\\\\\\\\&quot;),\\\\\\\\n\\\\\\\\n# Test: Predefined code\\\\\\\\nEx().has_printout(0)\\\\\\\\nEx().check_function(\\\\\\\\&quot;response.close\\\\\\\\&quot;)\\\\\\\\n\\\\\\\\nsuccess_msg(\\\\\\\\&quot;Awesome!\\\\\\\\&quot;)\\\\\\\\n&quot;,&quot;instructions&quot;,&quot;&lt;ul&gt;\\\\\\\\n&lt;li&gt;Import the functions &lt;code&gt;urlopen&lt;/code&gt; and &lt;code&gt;Request&lt;/code&gt; from the subpackage &lt;code&gt;urllib.request&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;li&gt;Package the request to the url &lt;code&gt;\\\\\\\\&quot;https://campus.datacamp.com/courses/1606/4135?ex=2\\\\\\\\&quot;&lt;/code&gt; using the function &lt;code&gt;Request()&lt;/code&gt; and assign it to &lt;code&gt;request&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;li&gt;Send the request and catch the response in the variable &lt;code&gt;response&lt;/code&gt; with  the function &lt;code&gt;urlopen()&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;li&gt;Run the rest of the code to see the datatype of &lt;code&gt;response&lt;/code&gt; and to close the connection!&lt;/li&gt;\\\\\\\\n&lt;/ul&gt;&quot;,&quot;externalId&quot;,42711,&quot;question&quot;,&quot;&quot;,&quot;hint&quot;,&quot;&lt;ul&gt;\\\\\\\\n&lt;li&gt;To import two functions in one line, import the first function as usual and add a comma &lt;code&gt;,&lt;/code&gt; followed by the second function.&lt;/li&gt;\\\\\\\\n&lt;li&gt;Pass the &lt;em&gt;url&lt;/em&gt; (already in the &lt;code&gt;url&lt;/code&gt; object defined) as an argument to &lt;code&gt;Request()&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;li&gt;Pass &lt;code&gt;request&lt;/code&gt; as an argument to &lt;code&gt;urlopen()&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;li&gt;You don&#39;t have to modify the code for printing the datatype of &lt;code&gt;response&lt;/code&gt; and closing the connection.&lt;/li&gt;\\\\\\\\n&lt;/ul&gt;&quot;,&quot;possible_answers&quot;,[&quot;^@&quot;,[]],&quot;runtime_config&quot;,null,&quot;number&quot;,6,&quot;randomNumber&quot;,0.025167267893165146,&quot;assignment&quot;,&quot;&lt;p&gt;Now that you know the basics behind HTTP GET requests, it&#39;s time to perform some of your own. In this interactive exercise, you will ping our very own DataCamp servers to perform a GET request to extract information from the first coding exercise of this course, &lt;code&gt;\\\\\\\\&quot;https://campus.datacamp.com/courses/1606/4135?ex=2\\\\\\\\&quot;&lt;/code&gt;.&lt;/p&gt;\\\\\\\\n&lt;p&gt;In the next exercise, you&#39;ll extract the HTML itself. Right now, however, you are going to package and send the request and then catch the response.&lt;/p&gt;&quot;,&quot;feedbacks&quot;,[&quot;^@&quot;,[]],&quot;attachments&quot;,null,&quot;exercise_image&quot;,null,&quot;title&quot;,&quot;Performing HTTP requests in Python using urllib&quot;,&quot;xp&quot;,100,&quot;language&quot;,&quot;python&quot;,&quot;pre_exercise_code&quot;,&quot;&quot;,&quot;solution&quot;,&quot;# Import packages\\\\\\\\nfrom urllib.request import urlopen, Request\\\\\\\\n\\\\\\\\n# Specify the url\\\\\\\\nurl = \\\\\\\\&quot;https://campus.datacamp.com/courses/1606/4135?ex=2\\\\\\\\&quot;\\\\\\\\n\\\\\\\\n# This packages the request: request\\\\\\\\nrequest = Request(url)\\\\\\\\n\\\\\\\\n# Sends the request and catches the response: response\\\\\\\\nresponse = urlopen(request)\\\\\\\\n\\\\\\\\n# Print the datatype of response\\\\\\\\nprint(type(response))\\\\\\\\n\\\\\\\\n# Be polite and close the response!\\\\\\\\nresponse.close()\\\\\\\\n&quot;,&quot;type&quot;,&quot;NormalExercise&quot;,&quot;id&quot;,42711,&quot;programming_language&quot;,null]],[&quot;^?&quot;,[&quot;sample_code&quot;,&quot;# Import packages\\\\\\\\nfrom urllib.request import urlopen, Request\\\\\\\\n\\\\\\\\n# Specify the url\\\\\\\\nurl = \\\\\\\\&quot;https://campus.datacamp.com/courses/1606/4135?ex=2\\\\\\\\&quot;\\\\\\\\n\\\\\\\\n# This packages the request\\\\\\\\nrequest = Request(url)\\\\\\\\n\\\\\\\\n# Sends the request and catches the response: response\\\\\\\\n\\\\\\\\n\\\\\\\\n# Extract the response: html\\\\\\\\n\\\\\\\\n\\\\\\\\n# Print the html\\\\\\\\n\\\\\\\\n\\\\\\\\n# Be polite and close the response!\\\\\\\\nresponse.close()&quot;,&quot;sct&quot;,&quot;\\\\\\\\n# Test: Predefined code\\\\\\\\npredef_msg = \\\\\\\\&quot;You don&#39;t have to change any of the predefined code.\\\\\\\\&quot;\\\\\\\\nEx().has_import(\\\\\\\\n    \\\\\\\\&quot;urllib.request.urlopen\\\\\\\\&quot;,\\\\\\\\n    not_imported_msg=predef_msg\\\\\\\\n)\\\\\\\\n\\\\\\\\nEx().has_import(\\\\\\\\n    \\\\\\\\&quot;urllib.request.Request\\\\\\\\&quot;,\\\\\\\\n    not_imported_msg=predef_msg\\\\\\\\n)\\\\\\\\n\\\\\\\\nEx().check_object(\\\\\\\\&quot;url\\\\\\\\&quot;).has_equal_value()\\\\\\\\n\\\\\\\\n# Test: call to Request() and &#39;request&#39; variable\\\\\\\\nEx().check_function(\\\\\\\\&quot;urllib.request.Request\\\\\\\\&quot;).check_args(0).has_equal_value()\\\\\\\\nEx().check_object(\\\\\\\\&quot;request\\\\\\\\&quot;)\\\\\\\\n\\\\\\\\n# Test: call to urlopen() and &#39;response&#39; variable\\\\\\\\nEx().check_function(\\\\\\\\&quot;urllib.request.urlopen\\\\\\\\&quot;).check_args(0).has_equal_ast()\\\\\\\\nEx().check_object(\\\\\\\\&quot;response\\\\\\\\&quot;)\\\\\\\\n\\\\\\\\n# Test: call to urlopen() and &#39;response&#39; variable\\\\\\\\nEx().check_function(\\\\\\\\&quot;response.read\\\\\\\\&quot;)\\\\\\\\nEx().check_object(\\\\\\\\&quot;html\\\\\\\\&quot;)\\\\\\\\n\\\\\\\\n# Test: call to print()\\\\\\\\nEx().check_function(&#39;print&#39;).check_args(0).has_equal_ast()\\\\\\\\n\\\\\\\\n# Test: Predefined code\\\\\\\\nEx().check_function(\\\\\\\\&quot;response.close\\\\\\\\&quot;)\\\\\\\\n\\\\\\\\nsuccess_msg(\\\\\\\\&quot;Awesome!\\\\\\\\&quot;)\\\\\\\\n&quot;,&quot;instructions&quot;,&quot;&lt;ul&gt;\\\\\\\\n&lt;li&gt;Send the request and catch the response in the variable &lt;code&gt;response&lt;/code&gt; with the function &lt;code&gt;urlopen()&lt;/code&gt;, as in the previous exercise.&lt;/li&gt;\\\\\\\\n&lt;li&gt;Extract the response using the &lt;code&gt;read()&lt;/code&gt; method and store the result in the variable &lt;code&gt;html&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;li&gt;Print the string &lt;code&gt;html&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;li&gt;Hit submit to perform all of the above and to close the response: be tidy!&lt;/li&gt;\\\\\\\\n&lt;/ul&gt;&quot;,&quot;externalId&quot;,42712,&quot;question&quot;,&quot;&quot;,&quot;hint&quot;,&quot;&lt;ul&gt;\\\\\\\\n&lt;li&gt;Pass &lt;code&gt;request&lt;/code&gt; as an argument to &lt;code&gt;urlopen()&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;li&gt;Apply the method &lt;code&gt;read()&lt;/code&gt; to the response object &lt;code&gt;response&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;li&gt;Simply pass &lt;code&gt;html&lt;/code&gt; to the &lt;code&gt;print()&lt;/code&gt; function.&lt;/li&gt;\\\\\\\\n&lt;li&gt;You don&#39;t have to modify the code for closing the response.&lt;/li&gt;\\\\\\\\n&lt;/ul&gt;&quot;,&quot;possible_answers&quot;,[&quot;^@&quot;,[]],&quot;runtime_config&quot;,null,&quot;number&quot;,7,&quot;randomNumber&quot;,0.8963620619853123,&quot;assignment&quot;,&quot;&lt;p&gt;You have just packaged and sent a GET request to &lt;code&gt;\\\\\\\\&quot;https://campus.datacamp.com/courses/1606/4135?ex=2\\\\\\\\&quot;&lt;/code&gt; and then caught the response. You saw that such a response is a &lt;code&gt;http.client.HTTPResponse&lt;/code&gt; object. The question remains: what can you do with this response?&lt;/p&gt;\\\\\\\\n&lt;p&gt;Well, as it came from an HTML page, you could &lt;em&gt;read&lt;/em&gt; it to extract the HTML and, in fact, such a &lt;code&gt;http.client.HTTPResponse&lt;/code&gt; object has an associated &lt;code&gt;read()&lt;/code&gt; method. In this exercise, you&#39;ll build on your previous great work to extract the response and print the HTML.&lt;/p&gt;&quot;,&quot;feedbacks&quot;,[&quot;^@&quot;,[]],&quot;attachments&quot;,null,&quot;exercise_image&quot;,null,&quot;title&quot;,&quot;Printing HTTP request results in Python using urllib&quot;,&quot;xp&quot;,100,&quot;language&quot;,&quot;python&quot;,&quot;pre_exercise_code&quot;,&quot;&quot;,&quot;solution&quot;,&quot;# Import packages\\\\\\\\nfrom urllib.request import urlopen, Request\\\\\\\\n\\\\\\\\n# Specify the url\\\\\\\\nurl = \\\\\\\\&quot;https://campus.datacamp.com/courses/1606/4135?ex=2\\\\\\\\&quot;\\\\\\\\n\\\\\\\\n# This packages the request\\\\\\\\nrequest = Request(url)\\\\\\\\n\\\\\\\\n# Sends the request and catches the response: response\\\\\\\\nresponse = urlopen(request)\\\\\\\\n\\\\\\\\n# Extract the response: html\\\\\\\\nhtml = response.read()\\\\\\\\n\\\\\\\\n# Print the html\\\\\\\\nprint(html)\\\\\\\\n\\\\\\\\n# Be polite and close the response!\\\\\\\\nresponse.close()&quot;,&quot;type&quot;,&quot;NormalExercise&quot;,&quot;id&quot;,42712,&quot;programming_language&quot;,null]],[&quot;^?&quot;,[&quot;sample_code&quot;,&quot;# Import package\\\\\\\\n\\\\\\\\n\\\\\\\\n# Specify the url: url\\\\\\\\n\\\\\\\\n\\\\\\\\n# Packages the request, send the request and catch the response: r\\\\\\\\n\\\\\\\\n\\\\\\\\n# Extract the response: text\\\\\\\\n\\\\\\\\n\\\\\\\\n# Print the html\\\\\\\\nprint(text)&quot;,&quot;sct&quot;,&quot;\\\\\\\\n# Test: import requests\\\\\\\\nEx().has_import(\\\\\\\\&quot;requests\\\\\\\\&quot;)\\\\\\\\n\\\\\\\\n# Test: &#39;url&#39; variable\\\\\\\\nEx().check_object(\\\\\\\\&quot;url\\\\\\\\&quot;).has_equal_value()\\\\\\\\n\\\\\\\\n# Test: call to requests.get() and &#39;r&#39; variable\\\\\\\\nEx().check_function(\\\\\\\\&quot;requests.get\\\\\\\\&quot;).check_args(0).has_equal_value()\\\\\\\\nEx().check_object(\\\\\\\\&quot;r\\\\\\\\&quot;)\\\\\\\\n\\\\\\\\n# Test: &#39;text&#39; variable\\\\\\\\nEx().has_code(\\\\\\\\&quot;r.text\\\\\\\\&quot;, pattern = False, not_typed_msg=\\\\\\\\&quot;Have you used `r.text` to create `text`?\\\\\\\\&quot;)\\\\\\\\nEx().check_object(\\\\\\\\&quot;text\\\\\\\\&quot;)\\\\\\\\n\\\\\\\\n# Test: Predefined code\\\\\\\\nEx().check_function(&#39;print&#39;).check_args(0).has_equal_ast()\\\\\\\\n\\\\\\\\nsuccess_msg(\\\\\\\\&quot;Awesome!\\\\\\\\&quot;)\\\\\\\\n&quot;,&quot;instructions&quot;,&quot;&lt;ul&gt;\\\\\\\\n&lt;li&gt;Import the package &lt;code&gt;requests&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;li&gt;Assign the URL of interest to the variable &lt;code&gt;url&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;li&gt;Package the request to the URL, send the request and catch the response with a single function &lt;code&gt;requests.get()&lt;/code&gt;, assigning the response to the variable &lt;code&gt;r&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;li&gt;Use the &lt;code&gt;text&lt;/code&gt; attribute of the object &lt;code&gt;r&lt;/code&gt; to return the HTML of the webpage as a string; store the result in a variable &lt;code&gt;text&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;li&gt;Hit submit to print the HTML of the webpage.&lt;/li&gt;\\\\\\\\n&lt;/ul&gt;&quot;,&quot;externalId&quot;,42713,&quot;question&quot;,&quot;&quot;,&quot;hint&quot;,&quot;&lt;ul&gt;\\\\\\\\n&lt;li&gt;To import a package &lt;code&gt;x&lt;/code&gt;, execute &lt;code&gt;import x&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;li&gt;Did you type in the URL correctly?&lt;/li&gt;\\\\\\\\n&lt;li&gt;Pass the &lt;em&gt;url&lt;/em&gt; (the &lt;code&gt;url&lt;/code&gt; object you defined) as an argument to &lt;code&gt;requests.get()&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;li&gt;You can access the &lt;code&gt;text&lt;/code&gt; attribute of the object &lt;code&gt;r&lt;/code&gt; by executing &lt;code&gt;r.text&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;li&gt;You don&#39;t have to modify the code for printing the HTML of the webpage.&lt;/li&gt;\\\\\\\\n&lt;/ul&gt;&quot;,&quot;possible_answers&quot;,[&quot;^@&quot;,[]],&quot;runtime_config&quot;,null,&quot;number&quot;,8,&quot;randomNumber&quot;,0.9499234036356423,&quot;assignment&quot;,&quot;&lt;p&gt;Now that you&#39;ve got your head and hands around making HTTP requests using the urllib package, you&#39;re going to figure out how to do the same using the higher-level requests library. You&#39;ll once again be pinging DataCamp servers for their &lt;code&gt;\\\\\\\\&quot;http://www.datacamp.com/teach/documentation\\\\\\\\&quot;&lt;/code&gt; page.&lt;/p&gt;\\\\\\\\n&lt;p&gt;Note that unlike in the previous exercises using urllib, you don&#39;t have to close the connection when using requests!&lt;/p&gt;&quot;,&quot;feedbacks&quot;,[&quot;^@&quot;,[]],&quot;attachments&quot;,null,&quot;exercise_image&quot;,null,&quot;title&quot;,&quot;Performing HTTP requests in Python using requests&quot;,&quot;xp&quot;,100,&quot;language&quot;,&quot;python&quot;,&quot;pre_exercise_code&quot;,&quot;&quot;,&quot;solution&quot;,&quot;# Import package\\\\\\\\nimport requests\\\\\\\\n\\\\\\\\n# Specify the url: url\\\\\\\\nurl = \\\\\\\\&quot;http://www.datacamp.com/teach/documentation\\\\\\\\&quot;\\\\\\\\n\\\\\\\\n# Packages the request, send the request and catch the response: r\\\\\\\\nr = requests.get(url)\\\\\\\\n\\\\\\\\n# Extract the response: text\\\\\\\\ntext = r.text\\\\\\\\n\\\\\\\\n# Print the html\\\\\\\\nprint(text)&quot;,&quot;type&quot;,&quot;NormalExercise&quot;,&quot;id&quot;,42713,&quot;programming_language&quot;,null]],[&quot;^?&quot;,[&quot;sample_code&quot;,&quot;&quot;,&quot;sct&quot;,&quot;&quot;,&quot;aspect_ratio&quot;,56.25,&quot;instructions&quot;,null,&quot;externalId&quot;,990670,&quot;question&quot;,&quot;&quot;,&quot;hint&quot;,null,&quot;possible_answers&quot;,[&quot;^@&quot;,[]],&quot;runtime_config&quot;,null,&quot;number&quot;,9,&quot;video_hls&quot;,null,&quot;randomNumber&quot;,0.6150986604311994,&quot;chapter_id&quot;,4135,&quot;assignment&quot;,null,&quot;feedbacks&quot;,[&quot;^@&quot;,[]],&quot;attachments&quot;,null,&quot;exercise_image&quot;,null,&quot;version&quot;,&quot;v0&quot;,&quot;title&quot;,&quot;Scraping the web in Python&quot;,&quot;xp&quot;,50,&quot;language&quot;,&quot;python&quot;,&quot;pre_exercise_code&quot;,&quot;&quot;,&quot;solution&quot;,&quot;&quot;,&quot;type&quot;,&quot;VideoExercise&quot;,&quot;id&quot;,990670,&quot;projector_key&quot;,&quot;course_1606_9d1f8a331d1200c7e1bdbfcaf3a7a491&quot;,&quot;video_link&quot;,null,&quot;programming_language&quot;,null,&quot;key&quot;,&quot;da43858012&quot;,&quot;course_id&quot;,1606]],[&quot;^?&quot;,[&quot;sample_code&quot;,&quot;# Import packages\\\\\\\\nimport requests\\\\\\\\nfrom ____ import ____\\\\\\\\n\\\\\\\\n# Specify url: url\\\\\\\\n\\\\\\\\n\\\\\\\\n# Package the request, send the request and catch the response: r\\\\\\\\n\\\\\\\\n\\\\\\\\n# Extracts the response as html: html_doc\\\\\\\\n\\\\\\\\n\\\\\\\\n# Create a BeautifulSoup object from the HTML: soup\\\\\\\\n\\\\\\\\n\\\\\\\\n# Prettify the BeautifulSoup object: pretty_soup\\\\\\\\n\\\\\\\\n\\\\\\\\n# Print the response\\\\\\\\nprint(pretty_soup)&quot;,&quot;sct&quot;,&quot;# Test: Predefined code\\\\\\\\npredef_msg = \\\\\\\\&quot;You don&#39;t have to change any of the predefined code.\\\\\\\\&quot;\\\\\\\\nEx().has_import(\\\\\\\\n    \\\\\\\\&quot;requests\\\\\\\\&quot;,\\\\\\\\n    not_imported_msg=predef_msg\\\\\\\\n)\\\\\\\\n\\\\\\\\n# Test: import BeautifulSoup\\\\\\\\nimport_msg = \\\\\\\\&quot;Did you correctly import the required packages?\\\\\\\\&quot;\\\\\\\\nEx().has_import(\\\\\\\\n    \\\\\\\\&quot;bs4.BeautifulSoup\\\\\\\\&quot;,\\\\\\\\n    not_imported_msg=import_msg\\\\\\\\n)\\\\\\\\n\\\\\\\\n# Test: &#39;url&#39; variable\\\\\\\\nEx().check_object(\\\\\\\\&quot;url\\\\\\\\&quot;).has_equal_value()\\\\\\\\n\\\\\\\\n# Test: call to requests.get() and &#39;r&#39; variable\\\\\\\\nEx().check_function(\\\\\\\\&quot;requests.get\\\\\\\\&quot;).check_args(0).has_equal_value()\\\\\\\\nEx().check_object(\\\\\\\\&quot;r\\\\\\\\&quot;)\\\\\\\\n\\\\\\\\n\\\\\\\\n# Test: &#39;html_doc&#39; variable\\\\\\\\nEx().check_correct(\\\\\\\\n  check_object(\\\\\\\\&quot;html_doc\\\\\\\\&quot;).has_equal_value(),\\\\\\\\n  has_code(\\\\\\\\&quot;r.text\\\\\\\\&quot;, pattern = False, not_typed_msg=\\\\\\\\&quot;Have you used `r.text` to create `html_doc`?\\\\\\\\&quot;)\\\\\\\\n)\\\\\\\\n\\\\\\\\n# Test: call to BeautifulSoup() and &#39;soup&#39; variable\\\\\\\\nEx().check_correct(\\\\\\\\n  check_object(\\\\\\\\&quot;soup\\\\\\\\&quot;).has_equal_value(),\\\\\\\\n  check_function(\\\\\\\\&quot;bs4.BeautifulSoup\\\\\\\\&quot;).check_args(0).has_equal_value()\\\\\\\\n  )\\\\\\\\n\\\\\\\\n# Test: call to prettify() and &#39;pretty_soup&#39; variable\\\\\\\\nEx().check_correct(\\\\\\\\n  check_object(\\\\\\\\&quot;pretty_soup\\\\\\\\&quot;).has_equal_value(),\\\\\\\\n  check_function(\\\\\\\\&quot;soup.prettify\\\\\\\\&quot;)\\\\\\\\n  )\\\\\\\\n\\\\\\\\n# Test: Predefined code\\\\\\\\nEx().has_printout(0)\\\\\\\\n\\\\\\\\nsuccess_msg(\\\\\\\\&quot;Awesome!\\\\\\\\&quot;)\\\\\\\\n&quot;,&quot;instructions&quot;,&quot;&lt;ul&gt;\\\\\\\\n&lt;li&gt;Import the function &lt;code&gt;BeautifulSoup&lt;/code&gt; from the package &lt;code&gt;bs4&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;li&gt;Assign the URL of interest to the variable &lt;code&gt;url&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;li&gt;Package the request to the URL, send the request and catch the response with a single function &lt;code&gt;requests.get()&lt;/code&gt;, assigning the response to the variable &lt;code&gt;r&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;li&gt;Use the &lt;code&gt;text&lt;/code&gt; attribute of the object &lt;code&gt;r&lt;/code&gt; to return the HTML of the webpage as a string; store the result in a variable &lt;code&gt;html_doc&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;li&gt;Create a BeautifulSoup object &lt;code&gt;soup&lt;/code&gt; from the resulting HTML using the function &lt;code&gt;BeautifulSoup()&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;li&gt;Use the method &lt;code&gt;prettify()&lt;/code&gt; on &lt;code&gt;soup&lt;/code&gt; and assign the result to &lt;code&gt;pretty_soup&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;li&gt;Hit submit to print to prettified HTML to your shell!&lt;/li&gt;\\\\\\\\n&lt;/ul&gt;&quot;,&quot;externalId&quot;,42715,&quot;question&quot;,&quot;&quot;,&quot;hint&quot;,&quot;&lt;ul&gt;\\\\\\\\n&lt;li&gt;To import a function &lt;code&gt;y&lt;/code&gt; from a package &lt;code&gt;x&lt;/code&gt;, execute &lt;code&gt;from x import y&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;li&gt;Check the URL to make sure that you typed it in correctly.&lt;/li&gt;\\\\\\\\n&lt;li&gt;Pass the &lt;em&gt;url&lt;/em&gt; (the &lt;code&gt;url&lt;/code&gt; object you defined) as an argument to &lt;code&gt;requests.get()&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;li&gt;You can access the &lt;code&gt;text&lt;/code&gt; attribute of the object &lt;code&gt;r&lt;/code&gt; by executing &lt;code&gt;r.text&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;li&gt;Pass the extracted &lt;em&gt;HTML&lt;/em&gt; as an argument to &lt;code&gt;BeautifulSoup()&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;li&gt;To use the &lt;code&gt;prettify()&lt;/code&gt; method on the BeautifulSoup object &lt;code&gt;soup&lt;/code&gt;, execute &lt;code&gt;soup.prettify()&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;li&gt;You don&#39;t have to modify the code to print the prettified HTML.&lt;/li&gt;\\\\\\\\n&lt;/ul&gt;&quot;,&quot;possible_answers&quot;,[&quot;^@&quot;,[]],&quot;runtime_config&quot;,null,&quot;number&quot;,10,&quot;randomNumber&quot;,0.9907962772955521,&quot;assignment&quot;,&quot;&lt;p&gt;In this interactive exercise, you&#39;ll learn how to use the BeautifulSoup package to &lt;em&gt;parse&lt;/em&gt;, &lt;em&gt;prettify&lt;/em&gt; and &lt;em&gt;extract&lt;/em&gt; information from HTML. You&#39;ll scrape the data from the webpage of Guido van Rossum, Python&#39;s very own &lt;a href=\\\\\\\\&quot;https://en.wikipedia.org/wiki/Benevolent_dictator_for_life\\\\\\\\&quot;&gt;Benevolent Dictator for Life&lt;/a&gt;. In the following exercises, you&#39;ll prettify the HTML and then extract the text and the hyperlinks.&lt;/p&gt;\\\\\\\\n&lt;p&gt;The URL of interest is &lt;code&gt;url = &#39;https://www.python.org/~guido/&#39;&lt;/code&gt;.&lt;/p&gt;&quot;,&quot;feedbacks&quot;,[&quot;^@&quot;,[]],&quot;attachments&quot;,null,&quot;exercise_image&quot;,null,&quot;title&quot;,&quot;Parsing HTML with BeautifulSoup&quot;,&quot;xp&quot;,100,&quot;language&quot;,&quot;python&quot;,&quot;pre_exercise_code&quot;,&quot;&quot;,&quot;solution&quot;,&quot;# Import packages\\\\\\\\nimport requests\\\\\\\\nfrom bs4 import BeautifulSoup\\\\\\\\n\\\\\\\\n# Specify url: url\\\\\\\\nurl = &#39;https://www.python.org/~guido/&#39;\\\\\\\\n\\\\\\\\n# Package the request, send the request and catch the response: r\\\\\\\\nr = requests.get(url)\\\\\\\\n\\\\\\\\n# Extracts the response as html: html_doc\\\\\\\\nhtml_doc = r.text\\\\\\\\n\\\\\\\\n# Create a BeautifulSoup object from the HTML: soup\\\\\\\\nsoup = BeautifulSoup(html_doc)\\\\\\\\n\\\\\\\\n# Prettify the BeautifulSoup object: pretty_soup\\\\\\\\npretty_soup = soup.prettify()\\\\\\\\n\\\\\\\\n# Print the response\\\\\\\\nprint(pretty_soup)&quot;,&quot;type&quot;,&quot;NormalExercise&quot;,&quot;id&quot;,42715,&quot;programming_language&quot;,null]],[&quot;^?&quot;,[&quot;sample_code&quot;,&quot;# Import packages\\\\\\\\nimport requests\\\\\\\\nfrom bs4 import BeautifulSoup\\\\\\\\n\\\\\\\\n# Specify url: url\\\\\\\\nurl = &#39;https://www.python.org/~guido/&#39;\\\\\\\\n\\\\\\\\n# Package the request, send the request and catch the response: r\\\\\\\\nr = requests.get(url)\\\\\\\\n\\\\\\\\n# Extract the response as html: html_doc\\\\\\\\nhtml_doc = r.text\\\\\\\\n\\\\\\\\n# Create a BeautifulSoup object from the HTML: soup\\\\\\\\n\\\\\\\\n\\\\\\\\n# Get the title of Guido&#39;s webpage: guido_title\\\\\\\\n\\\\\\\\n\\\\\\\\n# Print the title of Guido&#39;s webpage to the shell\\\\\\\\n\\\\\\\\n\\\\\\\\n# Get Guido&#39;s text: guido_text\\\\\\\\n\\\\\\\\n\\\\\\\\n# Print Guido&#39;s text to the shell\\\\\\\\nprint(guido_text)&quot;,&quot;sct&quot;,&quot;# Test: Predefined code\\\\\\\\npredef_msg = \\\\\\\\&quot;You don&#39;t have to change any of the predefined code.\\\\\\\\&quot;\\\\\\\\nEx().has_import(\\\\\\\\n    \\\\\\\\&quot;requests\\\\\\\\&quot;,\\\\\\\\n    not_imported_msg=predef_msg\\\\\\\\n)\\\\\\\\n\\\\\\\\n# Test: import BeautifulSoup\\\\\\\\nEx().has_import(\\\\\\\\n    \\\\\\\\&quot;bs4.BeautifulSoup\\\\\\\\&quot;,\\\\\\\\n    not_imported_msg=predef_msg\\\\\\\\n)\\\\\\\\n\\\\\\\\n# Test: &#39;url&#39; variable\\\\\\\\nEx().check_object(\\\\\\\\&quot;url\\\\\\\\&quot;).has_equal_value()\\\\\\\\n\\\\\\\\n# Test: call to requests.get() and &#39;r&#39; variable\\\\\\\\nEx().check_function(\\\\\\\\&quot;requests.get\\\\\\\\&quot;).check_args(0).has_equal_value()\\\\\\\\nEx().check_object(\\\\\\\\&quot;r\\\\\\\\&quot;)\\\\\\\\n\\\\\\\\n\\\\\\\\n# Test: &#39;html_doc&#39; variable\\\\\\\\nEx().check_correct(\\\\\\\\n  check_object(\\\\\\\\&quot;html_doc\\\\\\\\&quot;).has_equal_value(),\\\\\\\\n  has_code(\\\\\\\\&quot;r.text\\\\\\\\&quot;, pattern = False, not_typed_msg=\\\\\\\\&quot;Have you used `r.text` to create `html_doc`?\\\\\\\\&quot;)\\\\\\\\n)\\\\\\\\n\\\\\\\\n# Test: call to BeautifulSoup() and &#39;soup&#39; variable\\\\\\\\nEx().check_correct(\\\\\\\\n  check_object(\\\\\\\\&quot;soup\\\\\\\\&quot;).has_equal_value(),\\\\\\\\n  check_function(\\\\\\\\&quot;bs4.BeautifulSoup\\\\\\\\&quot;).check_args(0).has_equal_value()\\\\\\\\n  )\\\\\\\\n\\\\\\\\n# Test: &#39;guido_title&#39; variable\\\\\\\\nEx().check_correct(\\\\\\\\n  check_object(\\\\\\\\&quot;guido_title\\\\\\\\&quot;).has_equal_value(),\\\\\\\\n  has_code(\\\\\\\\&quot;soup.title\\\\\\\\&quot;, pattern = False, not_typed_msg=\\\\\\\\&quot;Have you used `soup.title` to create `guido_title`?\\\\\\\\&quot;)\\\\\\\\n)\\\\\\\\n\\\\\\\\n# Test: call to print()\\\\\\\\nEx().has_printout(0)\\\\\\\\n\\\\\\\\n# Test: call to soup.get_text() and &#39;guido_text&#39; variable\\\\\\\\nEx().check_correct(\\\\\\\\n  check_object(\\\\\\\\&quot;guido_text\\\\\\\\&quot;).has_equal_value(),\\\\\\\\n  check_function(\\\\\\\\&quot;soup.get_text\\\\\\\\&quot;)\\\\\\\\n  )\\\\\\\\n\\\\\\\\n# Test: Predefined code\\\\\\\\nEx().has_printout(1)\\\\\\\\n\\\\\\\\nsuccess_msg(\\\\\\\\&quot;Awesome!\\\\\\\\&quot;)\\\\\\\\n&quot;,&quot;instructions&quot;,&quot;&lt;ul&gt;\\\\\\\\n&lt;li&gt;In the sample code, the HTML response object &lt;code&gt;html_doc&lt;/code&gt; has already been created: your first task is to Soupify it using the function &lt;code&gt;BeautifulSoup()&lt;/code&gt; and to assign the resulting soup to the variable &lt;code&gt;soup&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;li&gt;Extract the title from the HTML soup &lt;code&gt;soup&lt;/code&gt; using the attribute &lt;code&gt;title&lt;/code&gt; and assign the result to &lt;code&gt;guido_title&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;li&gt;Print the title of Guido&#39;s webpage to the shell using the &lt;code&gt;print()&lt;/code&gt; function.&lt;/li&gt;\\\\\\\\n&lt;li&gt;Extract the text from the HTML soup &lt;code&gt;soup&lt;/code&gt; using the method &lt;code&gt;get_text()&lt;/code&gt; and assign to &lt;code&gt;guido_text&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;li&gt;Hit submit to print the text from Guido&#39;s webpage to the shell.&lt;/li&gt;\\\\\\\\n&lt;/ul&gt;&quot;,&quot;externalId&quot;,42716,&quot;question&quot;,&quot;&quot;,&quot;hint&quot;,&quot;&lt;ul&gt;\\\\\\\\n&lt;li&gt;Pass the &lt;em&gt;HTML response object&lt;/em&gt; as an argument to &lt;code&gt;BeautifulSoup()&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;li&gt;You can access the &lt;code&gt;title&lt;/code&gt; attribute of the object &lt;code&gt;soup&lt;/code&gt; by executing &lt;code&gt;soup.title&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;li&gt;The object that contains the title of Guido&#39;s webpage is &lt;code&gt;guido_title&lt;/code&gt;; pass this as an argument to &lt;code&gt;print()&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;li&gt;Use the method &lt;code&gt;get_text()&lt;/code&gt; on the HTML soup &lt;code&gt;soup&lt;/code&gt; by executing &lt;code&gt;soup.get_text()&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;li&gt;You don&#39;t have to modify the code to print the text from Guido&#39;s webpage.&lt;/li&gt;\\\\\\\\n&lt;/ul&gt;&quot;,&quot;possible_answers&quot;,[&quot;^@&quot;,[]],&quot;runtime_config&quot;,null,&quot;number&quot;,11,&quot;randomNumber&quot;,0.9359883737326375,&quot;assignment&quot;,&quot;&lt;p&gt;As promised, in the following exercises, you&#39;ll learn the basics of extracting information from HTML soup. In this exercise, you&#39;ll figure out how to extract the text from the BDFL&#39;s webpage, along with printing the webpage&#39;s title.&lt;/p&gt;&quot;,&quot;feedbacks&quot;,[&quot;^@&quot;,[]],&quot;attachments&quot;,null,&quot;exercise_image&quot;,null,&quot;title&quot;,&quot;Turning a webpage into data using BeautifulSoup: getting the text&quot;,&quot;xp&quot;,100,&quot;language&quot;,&quot;python&quot;,&quot;pre_exercise_code&quot;,&quot;&quot;,&quot;solution&quot;,&quot;# Import packages\\\\\\\\nimport requests\\\\\\\\nfrom bs4 import BeautifulSoup\\\\\\\\n\\\\\\\\n# Specify url: url\\\\\\\\nurl = &#39;https://www.python.org/~guido/&#39;\\\\\\\\n\\\\\\\\n# Package the request, send the request and catch the response: r\\\\\\\\nr = requests.get(url)\\\\\\\\n\\\\\\\\n# Extract the response as html: html_doc\\\\\\\\nhtml_doc = r.text\\\\\\\\n\\\\\\\\n# Create a BeautifulSoup object from the HTML: soup\\\\\\\\nsoup = BeautifulSoup(html_doc)\\\\\\\\n\\\\\\\\n# Get the title of Guido&#39;s webpage: guido_title\\\\\\\\nguido_title = soup.title\\\\\\\\n\\\\\\\\n# Print the title of Guido&#39;s webpage to the shell\\\\\\\\nprint(guido_title)\\\\\\\\n\\\\\\\\n# Get Guido&#39;s text: guido_text\\\\\\\\nguido_text = soup.get_text()\\\\\\\\n\\\\\\\\n# Print Guido&#39;s text to the shell\\\\\\\\nprint(guido_text)&quot;,&quot;type&quot;,&quot;NormalExercise&quot;,&quot;id&quot;,42716,&quot;programming_language&quot;,null]],[&quot;^?&quot;,[&quot;sample_code&quot;,&quot;# Import packages\\\\\\\\nimport requests\\\\\\\\nfrom bs4 import BeautifulSoup\\\\\\\\n\\\\\\\\n# Specify url\\\\\\\\nurl = &#39;https://www.python.org/~guido/&#39;\\\\\\\\n\\\\\\\\n# Package the request, send the request and catch the response: r\\\\\\\\nr = requests.get(url)\\\\\\\\n\\\\\\\\n# Extracts the response as html: html_doc\\\\\\\\nhtml_doc = r.text\\\\\\\\n\\\\\\\\n# create a BeautifulSoup object from the HTML: soup\\\\\\\\nsoup = BeautifulSoup(html_doc)\\\\\\\\n\\\\\\\\n# Print the title of Guido&#39;s webpage\\\\\\\\nprint(soup.title)\\\\\\\\n\\\\\\\\n# Find all &#39;a&#39; tags (which define hyperlinks): a_tags\\\\\\\\n\\\\\\\\n\\\\\\\\n# Print the URLs to the shell\\\\\\\\nfor ____ in ____:\\\\\\\\n    ____&quot;,&quot;sct&quot;,&quot;predef_msg = \\\\\\\\&quot;You don&#39;t have to change any of the predefined code.\\\\\\\\&quot;\\\\\\\\nEx().has_import(\\\\\\\\&quot;requests\\\\\\\\&quot;)\\\\\\\\nEx().has_import(\\\\\\\\&quot;bs4.BeautifulSoup\\\\\\\\&quot;)\\\\\\\\nEx().check_object(\\\\\\\\&quot;url\\\\\\\\&quot;).has_equal_value(incorrect_msg = predef_msg)\\\\\\\\nEx().check_function(\\\\\\\\&quot;requests.get\\\\\\\\&quot;).check_args(0).has_equal_ast()\\\\\\\\nEx().check_object(\\\\\\\\&quot;html_doc\\\\\\\\&quot;).has_equal_value(incorrect_msg = predef_msg)\\\\\\\\nEx().check_object(\\\\\\\\&quot;soup\\\\\\\\&quot;).has_equal_value(incorrect_msg = predef_msg)\\\\\\\\nEx().has_printout(0)\\\\\\\\n\\\\\\\\nEx().check_correct(\\\\\\\\n    check_object(\\\\\\\\&quot;a_tags\\\\\\\\&quot;),\\\\\\\\n    check_function(\\\\\\\\&quot;soup.find_all\\\\\\\\&quot;).check_args(0).has_equal_value()\\\\\\\\n)\\\\\\\\nEx().check_for_loop().multi(\\\\\\\\n        check_iter().has_equal_value(incorrect_msg = \\\\\\\\&quot;You have to iterate over `a_tags`\\\\\\\\&quot;),\\\\\\\\n        check_body().set_context(&#39;&lt;a href=\\\\\\\\&quot;pics.html\\\\\\\\&quot;&gt;&lt;img border=\\\\\\\\&quot;0\\\\\\\\&quot; src=\\\\\\\\&quot;images/IMG_2192.jpg\\\\\\\\&quot;/&gt;&lt;/a&gt;&#39;).check_function(\\\\\\\\&quot;print\\\\\\\\&quot;).check_args(0).check_function(\\\\\\\\&quot;link.get\\\\\\\\&quot;).check_args(0).has_equal_value()\\\\\\\\n    )\\\\\\\\n\\\\\\\\nsuccess_msg(\\\\\\\\&quot;Awesome!\\\\\\\\&quot;)&quot;,&quot;instructions&quot;,&quot;&lt;ul&gt;\\\\\\\\n&lt;li&gt;Use the method &lt;code&gt;find_all()&lt;/code&gt; to find all hyperlinks in &lt;code&gt;soup&lt;/code&gt;, remembering that hyperlinks are defined by the HTML tag &lt;code&gt;&amp;lt;a&amp;gt;&lt;/code&gt; but passed to &lt;code&gt;find_all()&lt;/code&gt; without angle brackets; store the result in the variable &lt;code&gt;a_tags&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;li&gt;The variable &lt;code&gt;a_tags&lt;/code&gt; is a results set: your job now is to enumerate over it, using a &lt;code&gt;for&lt;/code&gt; loop and to print the actual URLs of the hyperlinks; to do this, for every element &lt;code&gt;link&lt;/code&gt; in &lt;code&gt;a_tags&lt;/code&gt;, you want to &lt;code&gt;print()&lt;/code&gt; &lt;code&gt;link.get(&#39;href&#39;)&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;/ul&gt;&quot;,&quot;externalId&quot;,42717,&quot;question&quot;,&quot;&quot;,&quot;hint&quot;,&quot;&lt;ul&gt;\\\\\\\\n&lt;li&gt;Pass the &lt;em&gt;HTML tag&lt;/em&gt; to find (without the angle brackets &lt;code&gt;&amp;lt;&amp;gt;&lt;/code&gt;) as a string argument to &lt;code&gt;find_all()&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;li&gt;Recall that the &lt;code&gt;for&lt;/code&gt; loop recipe is: &lt;code&gt;for&lt;/code&gt; &lt;em&gt;loop variable&lt;/em&gt; &lt;code&gt;in&lt;/code&gt; &lt;em&gt;results set&lt;/em&gt;&lt;code&gt;:&lt;/code&gt;. Don&#39;t forget to pass &lt;code&gt;link.get(&#39;href&#39;)&lt;/code&gt; as an argument to &lt;code&gt;print()&lt;/code&gt; inside the &lt;code&gt;for&lt;/code&gt; loop body.&lt;/li&gt;\\\\\\\\n&lt;/ul&gt;&quot;,&quot;possible_answers&quot;,[&quot;^@&quot;,[]],&quot;runtime_config&quot;,null,&quot;number&quot;,12,&quot;randomNumber&quot;,0.5560594333253173,&quot;assignment&quot;,&quot;&lt;p&gt;In this exercise, you&#39;ll figure out how to extract the URLs of the hyperlinks from the BDFL&#39;s webpage. In the process, you&#39;ll become close friends with the soup method &lt;code&gt;find_all()&lt;/code&gt;.&lt;/p&gt;&quot;,&quot;feedbacks&quot;,[&quot;^@&quot;,[]],&quot;attachments&quot;,null,&quot;exercise_image&quot;,null,&quot;title&quot;,&quot;Turning a webpage into data using BeautifulSoup: getting the hyperlinks&quot;,&quot;xp&quot;,100,&quot;language&quot;,&quot;python&quot;,&quot;pre_exercise_code&quot;,&quot;&quot;,&quot;solution&quot;,&quot;# Import packages\\\\\\\\nimport requests\\\\\\\\nfrom bs4 import BeautifulSoup\\\\\\\\n\\\\\\\\n# Specify url\\\\\\\\nurl = &#39;https://www.python.org/~guido/&#39;\\\\\\\\n\\\\\\\\n# Package the request, send the request and catch the response: r\\\\\\\\nr = requests.get(url)\\\\\\\\n\\\\\\\\n# Extracts the response as html: html_doc\\\\\\\\nhtml_doc = r.text\\\\\\\\n\\\\\\\\n# create a BeautifulSoup object from the HTML: soup\\\\\\\\nsoup = BeautifulSoup(html_doc)\\\\\\\\n\\\\\\\\n# Print the title of Guido&#39;s webpage\\\\\\\\nprint(soup.title)\\\\\\\\n\\\\\\\\n# Find all &#39;a&#39; tags (which define hyperlinks): a_tags\\\\\\\\na_tags = soup.find_all(&#39;a&#39;)\\\\\\\\n\\\\\\\\n# Print the URLs to the shell\\\\\\\\nfor link in a_tags:\\\\\\\\n    print(link.get(&#39;href&#39;))&quot;,&quot;type&quot;,&quot;NormalExercise&quot;,&quot;id&quot;,42717,&quot;programming_language&quot;,null]]]],&quot;canRateChapter&quot;,false,&quot;isChapterCompleted&quot;,false]],&quot;learningMode&quot;,&quot;course&quot;,&quot;learningRecap&quot;,null,&quot;location&quot;,[&quot;^?&quot;,[&quot;current&quot;,[&quot;^?&quot;,[&quot;pathname&quot;,&quot;/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1&quot;,&quot;query&quot;,[&quot;^?&quot;,[&quot;ex&quot;,&quot;2&quot;]]]],&quot;language&quot;,&quot;en&quot;,&quot;canonical&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1?ex=2&quot;,&quot;before&quot;,[&quot;^?&quot;,[&quot;pathname&quot;,&quot;/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1&quot;,&quot;query&quot;,[&quot;^?&quot;,[&quot;ex&quot;,&quot;2&quot;]]]]]],&quot;mobilePopup&quot;,[&quot;^?&quot;,[]],&quot;onboardingMilestones&quot;,[&quot;^ &quot;,&quot;isStarted&quot;,false,&quot;isActive&quot;,true,&quot;step&quot;,0],&quot;notes&quot;,[&quot;^ &quot;,&quot;workspaceNotes&quot;,null,&quot;workspaceTemplate&quot;,[&quot;^ &quot;,&quot;_tag&quot;,&quot;template&quot;,&quot;id&quot;,3046,&quot;createdAt&quot;,&quot;2022-12-01T15:10:45.124Z&quot;,&quot;updatedAt&quot;,&quot;2022-12-05T06:31:46.338Z&quot;,&quot;key&quot;,&quot;course-dataset-intermediate-importing-data-in-python&quot;,&quot;language&quot;,&quot;Python&quot;,&quot;languageVersion&quot;,null,&quot;title&quot;,&quot;Intermediate Importing Data in Python&quot;,&quot;description&quot;,&quot;Explore the datasets from the course, Intermediate Importing Data in Python.&quot;,&quot;listed&quot;,false,&quot;latestVersion&quot;,&quot;d9783ad9a9e677a4f583a5bd9ed5b9d5987a2859&quot;,&quot;communitySlug&quot;,null,&quot;category&quot;,null,&quot;templateGroupKey&quot;,null,&quot;previewPublicationId&quot;,&quot;ade0176d-8e1d-436c-b7c1-44c3f4f1df8f&quot;,&quot;labels&quot;,[&quot;course-dataset&quot;],&quot;courseId&quot;,1606,&quot;integrationIds&quot;,[],&quot;publicationScreenshot&quot;,null]],&quot;output&quot;,[&quot;^ &quot;,&quot;lastErrorMessage&quot;,null,&quot;^17&quot;,[]],&quot;preFetchedData&quot;,[&quot;^0&quot;,[&quot;^ &quot;,&quot;n&quot;,&quot;PreFetchedDataStateRecord&quot;,&quot;v&quot;,[&quot;^ &quot;,&quot;^&gt;&quot;,[&quot;^0&quot;,[&quot;^ &quot;,&quot;n&quot;,&quot;PreFetchedRequestRecord&quot;,&quot;v&quot;,[&quot;^ &quot;,&quot;^2&quot;,&quot;SUCCESS&quot;,&quot;data&quot;,[&quot;^ &quot;,&quot;id&quot;,4135,&quot;title_meta&quot;,null,&quot;^W&quot;,&quot;Importing data from the Internet&quot;,&quot;^X&quot;,&quot;The web is a rich source of data from which you can extract various types of insights and findings. In this chapter, you will learn how to get data from the web, whether it is stored in files or in HTML. You&#39;ll also learn the basics of scraping and parsing web data.&quot;,&quot;number&quot;,1,&quot;slug&quot;,&quot;importing-data-from-the-internet-1&quot;,&quot;nb_exercises&quot;,12,&quot;badge_completed_url&quot;,&quot;https://assets.datacamp.com/production/default/badges/missing.png&quot;,&quot;badge_uncompleted_url&quot;,&quot;https://assets.datacamp.com/production/default/badges/missing_unc.png&quot;,&quot;last_updated_on&quot;,&quot;26/09/2024&quot;,&quot;slides_link&quot;,&quot;https://projector-video-pdf-converter.datacamp.com/1606/chapter1.pdf&quot;,&quot;free_preview&quot;,true,&quot;xp&quot;,1050,&quot;number_of_videos&quot;,3,&quot;^F&quot;,[[&quot;^ &quot;,&quot;^B&quot;,&quot;VideoExercise&quot;,&quot;^W&quot;,&quot;Importing flat files from the web&quot;,&quot;aggregate_xp&quot;,50,&quot;^1&lt;&quot;,1,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1?ex=1&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^W&quot;,&quot;Importing flat files from the web: your turn!&quot;,&quot;^1E&quot;,100,&quot;^1&lt;&quot;,2,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1?ex=2&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^W&quot;,&quot;Opening and reading flat files from the web&quot;,&quot;^1E&quot;,100,&quot;^1&lt;&quot;,3,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1?ex=3&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^W&quot;,&quot;Importing non-flat files from the web&quot;,&quot;^1E&quot;,100,&quot;^1&lt;&quot;,4,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1?ex=4&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;VideoExercise&quot;,&quot;^W&quot;,&quot;HTTP requests to import files from the web&quot;,&quot;^1E&quot;,50,&quot;^1&lt;&quot;,5,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1?ex=5&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^W&quot;,&quot;Performing HTTP requests in Python using urllib&quot;,&quot;^1E&quot;,100,&quot;^1&lt;&quot;,6,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1?ex=6&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^W&quot;,&quot;Printing HTTP request results in Python using urllib&quot;,&quot;^1E&quot;,100,&quot;^1&lt;&quot;,7,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1?ex=7&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^W&quot;,&quot;Performing HTTP requests in Python using requests&quot;,&quot;^1E&quot;,100,&quot;^1&lt;&quot;,8,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1?ex=8&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;VideoExercise&quot;,&quot;^W&quot;,&quot;Scraping the web in Python&quot;,&quot;^1E&quot;,50,&quot;^1&lt;&quot;,9,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1?ex=9&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^W&quot;,&quot;Parsing HTML with BeautifulSoup&quot;,&quot;^1E&quot;,100,&quot;^1&lt;&quot;,10,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1?ex=10&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^W&quot;,&quot;Turning a webpage into data using BeautifulSoup: getting the text&quot;,&quot;^1E&quot;,100,&quot;^1&lt;&quot;,11,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1?ex=11&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^W&quot;,&quot;Turning a webpage into data using BeautifulSoup: getting the hyperlinks&quot;,&quot;^1E&quot;,100,&quot;^1&lt;&quot;,12,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1?ex=12&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null]]]]]],&quot;^E&quot;,[&quot;^0&quot;,[&quot;^ &quot;,&quot;n&quot;,&quot;PreFetchedRequestRecord&quot;,&quot;v&quot;,[&quot;^ &quot;,&quot;^2&quot;,&quot;SUCCESS&quot;,&quot;^1:&quot;,[&quot;^ &quot;,&quot;id&quot;,1606,&quot;^W&quot;,&quot;Intermediate Importing Data in Python&quot;,&quot;^X&quot;,&quot;As a data scientist, you will need to clean data, wrangle and munge it, visualize it, build predictive models and interpret these models. Before you can do so, however, you will need to know how to get data into Python. In the prequel to this course, you learned many ways to import data into Python: from flat files such as .txt and .csv; from files native to other software such as Excel spreadsheets, Stata, SAS, and MATLAB files; and from relational databases such as SQLite and PostgreSQL. In this course, you&#39;ll extend this knowledge base by learning to import data from the web and by pulling data from Application Programming Interfaces\\xe2\\x80\\x94 APIs\\xe2\\x80\\x94such as the Twitter streaming API, which allows us to stream real-time tweets.&quot;,&quot;short_description&quot;,&quot;Improve your Python data importing skills and learn to work with web and API data.&quot;,&quot;author_field&quot;,null,&quot;author_bio&quot;,null,&quot;author_image&quot;,&quot;https://assets.datacamp.com/production/course_1606/author_images/author_image_course_1606_20200310-1-lgdj4c?1583853939&quot;,&quot;nb_of_subscriptions&quot;,179489,&quot;^1=&quot;,&quot;intermediate-importing-data-in-python&quot;,&quot;image_url&quot;,&quot;https://assets.datacamp.com/production/course_1606/shields/thumb/shield_image_course_1606_20200310-1-17hkmhz?1583853940&quot;,&quot;image_thumbnail_url&quot;,&quot;https://assets.datacamp.com/production/course_1606/shields/thumb_home/shield_image_course_1606_20200310-1-17hkmhz?1583853940&quot;,&quot;^1A&quot;,&quot;11/10/2024&quot;,&quot;link&quot;,&quot;https://www.datacamp.com/courses/intermediate-importing-data-in-python&quot;,&quot;should_cache&quot;,true,&quot;^B&quot;,&quot;datacamp&quot;,&quot;difficulty_level&quot;,2,&quot;state&quot;,&quot;live&quot;,&quot;university&quot;,null,&quot;sharing_links&quot;,[&quot;^ &quot;,&quot;twitter&quot;,&quot;http://bit.ly/1eWTMJh&quot;,&quot;facebook&quot;,&quot;http://bit.ly/1iS42Do&quot;],&quot;marketing_video&quot;,&quot;&quot;,&quot;^1G&quot;,&quot;python&quot;,&quot;paid&quot;,true,&quot;time_needed&quot;,null,&quot;xp&quot;,2300,&quot;topic_id&quot;,18,&quot;technology_id&quot;,2,&quot;reduced_outline&quot;,null,&quot;^1H&quot;,null,&quot;lti_only&quot;,false,&quot;instructors&quot;,[[&quot;^ &quot;,&quot;id&quot;,301837,&quot;marketing_biography&quot;,&quot;Data Scientist&quot;,&quot;biography&quot;,&quot;Hugo is a data scientist, educator, writer and podcaster formerly at DataCamp. His main interests are promoting data &amp; AI literacy, helping to spread data skills through organizations and society and doing amateur stand up comedy in NYC. If you want to know what he likes to talk about, definitely check out &lt;a href=\\\\\\\\&quot;https://www.datacamp.com/community/podcast\\\\\\\\&quot;&gt;DataFramed&lt;/a&gt;, the DataCamp podcast, which he hosted and produced.&quot;,&quot;avatar_url&quot;,&quot;https://assets.datacamp.com/authors/avatars/000/000/006/square/hugoaboutpic.jpg?1705506415&quot;,&quot;full_name&quot;,&quot;Hugo Bowne-Anderson&quot;,&quot;instructor_path&quot;,&quot;/instructors/hugobowne&quot;]],&quot;collaborators&quot;,[[&quot;^ &quot;,&quot;^26&quot;,&quot;https://assets.datacamp.com/authors/avatars/000/000/058/square/francis-photo.jpg?1705506690&quot;,&quot;^27&quot;,&quot;Francisco Castro&quot;]],&quot;datasets&quot;,[[&quot;^ &quot;,&quot;asset_url&quot;,&quot;https://assets.datacamp.com/production/repositories/488/datasets/b422ace2fceada7b569e0ba3e8d833fddc684c4d/latitude.xls&quot;,&quot;name&quot;,&quot;Latitudes (XLS)&quot;],[&quot;^ &quot;,&quot;^2;&quot;,&quot;https://assets.datacamp.com/production/repositories/488/datasets/3ef452f83a91556ea4284624b969392c0506fb33/tweets3.txt&quot;,&quot;^2&lt;&quot;,&quot;Tweets&quot;],[&quot;^ &quot;,&quot;^2;&quot;,&quot;https://assets.datacamp.com/production/repositories/488/datasets/013936d2700e2d00207ec42100d448c23692eb6f/winequality-red.csv&quot;,&quot;^2&lt;&quot;,&quot;Red wine quality&quot;]],&quot;tracks&quot;,[[&quot;^ &quot;,&quot;path&quot;,&quot;/tracks/data-engineer-in-python&quot;,&quot;title_with_subtitle&quot;,&quot;Data Engineer in Python&quot;],[&quot;^ &quot;,&quot;^2&gt;&quot;,&quot;/tracks/data-scientist-in-python&quot;,&quot;^2?&quot;,&quot;Data Scientist in Python&quot;],[&quot;^ &quot;,&quot;^2&gt;&quot;,&quot;/tracks/importing-cleaning-data-with-python&quot;,&quot;^2?&quot;,&quot;Importing &amp; Cleaning Data  in Python&quot;]],&quot;prerequisites&quot;,[[&quot;^ &quot;,&quot;^2&gt;&quot;,&quot;/courses/introduction-to-importing-data-in-python&quot;,&quot;^W&quot;,&quot;Introduction to Importing Data in Python&quot;]],&quot;time_needed_in_hours&quot;,2,&quot;seo_title&quot;,&quot;Intermediate Importing Data in Python&quot;,&quot;seo_description&quot;,&quot;Learn how to import data into Python from sources like the web and by pulling data from APIs, such as the Twitter streaming API to stream real-time tweets.&quot;,&quot;archived_at&quot;,null,&quot;original_image_url&quot;,&quot;https://assets.datacamp.com/production/course_1606/shields/original/shield_image_course_1606_20200310-1-17hkmhz?1583853940&quot;,&quot;external_slug&quot;,&quot;intermediate-importing-data-in-python&quot;,&quot;mobile_enabled&quot;,true,&quot;case_study&quot;,null,&quot;difficulty_level_hardcoded&quot;,null,&quot;long_description&quot;,null,&quot;industry_ids&quot;,[],&quot;audio_recorders&quot;,[],&quot;content_area&quot;,&quot;Data Science and Analytics&quot;,&quot;is_labeled_as_new&quot;,null,&quot;tier&quot;,null,&quot;private&quot;,false,&quot;private_access&quot;,[&quot;^ &quot;],&quot;chapters&quot;,[[&quot;^ &quot;,&quot;id&quot;,4135,&quot;^1;&quot;,null,&quot;^W&quot;,&quot;Importing data from the Internet&quot;,&quot;^X&quot;,&quot;The web is a rich source of data from which you can extract various types of insights and findings. In this chapter, you will learn how to get data from the web, whether it is stored in files or in HTML. You&#39;ll also learn the basics of scraping and parsing web data.&quot;,&quot;^1&lt;&quot;,1,&quot;^1=&quot;,&quot;importing-data-from-the-internet-1&quot;,&quot;^1&gt;&quot;,12,&quot;^1?&quot;,&quot;https://assets.datacamp.com/production/default/badges/missing.png&quot;,&quot;^1@&quot;,&quot;https://assets.datacamp.com/production/default/badges/missing_unc.png&quot;,&quot;^1A&quot;,&quot;26/09/2024&quot;,&quot;^1B&quot;,&quot;https://projector-video-pdf-converter.datacamp.com/1606/chapter1.pdf&quot;,&quot;^1C&quot;,true,&quot;xp&quot;,1050,&quot;^1D&quot;,3,&quot;^F&quot;,[[&quot;^ &quot;,&quot;^B&quot;,&quot;VideoExercise&quot;,&quot;^W&quot;,&quot;Importing flat files from the web&quot;,&quot;^1E&quot;,50,&quot;^1&lt;&quot;,1,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1?ex=1&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^W&quot;,&quot;Importing flat files from the web: your turn!&quot;,&quot;^1E&quot;,100,&quot;^1&lt;&quot;,2,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1?ex=2&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^W&quot;,&quot;Opening and reading flat files from the web&quot;,&quot;^1E&quot;,100,&quot;^1&lt;&quot;,3,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1?ex=3&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^W&quot;,&quot;Importing non-flat files from the web&quot;,&quot;^1E&quot;,100,&quot;^1&lt;&quot;,4,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1?ex=4&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;VideoExercise&quot;,&quot;^W&quot;,&quot;HTTP requests to import files from the web&quot;,&quot;^1E&quot;,50,&quot;^1&lt;&quot;,5,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1?ex=5&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^W&quot;,&quot;Performing HTTP requests in Python using urllib&quot;,&quot;^1E&quot;,100,&quot;^1&lt;&quot;,6,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1?ex=6&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^W&quot;,&quot;Printing HTTP request results in Python using urllib&quot;,&quot;^1E&quot;,100,&quot;^1&lt;&quot;,7,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1?ex=7&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^W&quot;,&quot;Performing HTTP requests in Python using requests&quot;,&quot;^1E&quot;,100,&quot;^1&lt;&quot;,8,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1?ex=8&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;VideoExercise&quot;,&quot;^W&quot;,&quot;Scraping the web in Python&quot;,&quot;^1E&quot;,50,&quot;^1&lt;&quot;,9,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1?ex=9&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^W&quot;,&quot;Parsing HTML with BeautifulSoup&quot;,&quot;^1E&quot;,100,&quot;^1&lt;&quot;,10,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1?ex=10&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^W&quot;,&quot;Turning a webpage into data using BeautifulSoup: getting the text&quot;,&quot;^1E&quot;,100,&quot;^1&lt;&quot;,11,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1?ex=11&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^W&quot;,&quot;Turning a webpage into data using BeautifulSoup: getting the hyperlinks&quot;,&quot;^1E&quot;,100,&quot;^1&lt;&quot;,12,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1?ex=12&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null]]],[&quot;^ &quot;,&quot;id&quot;,4136,&quot;^1;&quot;,null,&quot;^W&quot;,&quot;Interacting with APIs to import data from the web&quot;,&quot;^X&quot;,&quot;In this chapter, you will gain a deeper understanding of how to import data from the web. You will learn the basics of extracting data from APIs, gain insight on the importance of APIs, and practice extracting data by diving into the OMDB and Library of Congress APIs.&quot;,&quot;^1&lt;&quot;,2,&quot;^1=&quot;,&quot;interacting-with-apis-to-import-data-from-the-web-2&quot;,&quot;^1&gt;&quot;,9,&quot;^1?&quot;,&quot;https://assets.datacamp.com/production/default/badges/missing.png&quot;,&quot;^1@&quot;,&quot;https://assets.datacamp.com/production/default/badges/missing_unc.png&quot;,&quot;^1A&quot;,&quot;26/09/2024&quot;,&quot;^1B&quot;,&quot;https://projector-video-pdf-converter.datacamp.com/1606/chapter2.pdf&quot;,&quot;^1C&quot;,null,&quot;xp&quot;,650,&quot;^1D&quot;,2,&quot;^F&quot;,[[&quot;^ &quot;,&quot;^B&quot;,&quot;VideoExercise&quot;,&quot;^W&quot;,&quot;Introduction to APIs and JSONs&quot;,&quot;^1E&quot;,50,&quot;^1&lt;&quot;,1,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/interacting-with-apis-to-import-data-from-the-web-2?ex=1&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;PureMultipleChoiceExercise&quot;,&quot;^W&quot;,&quot;Pop quiz: What exactly is a JSON?&quot;,&quot;^1E&quot;,50,&quot;^1&lt;&quot;,2,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/interacting-with-apis-to-import-data-from-the-web-2?ex=2&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^W&quot;,&quot;Loading and exploring a JSON&quot;,&quot;^1E&quot;,100,&quot;^1&lt;&quot;,3,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/interacting-with-apis-to-import-data-from-the-web-2?ex=3&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;MultipleChoiceExercise&quot;,&quot;^W&quot;,&quot;Pop quiz: Exploring your JSON&quot;,&quot;^1E&quot;,50,&quot;^1&lt;&quot;,4,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/interacting-with-apis-to-import-data-from-the-web-2?ex=4&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;VideoExercise&quot;,&quot;^W&quot;,&quot;APIs and interacting with the world wide web&quot;,&quot;^1E&quot;,50,&quot;^1&lt;&quot;,5,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/interacting-with-apis-to-import-data-from-the-web-2?ex=5&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;PureMultipleChoiceExercise&quot;,&quot;^W&quot;,&quot;Pop quiz: What&#39;s an API?&quot;,&quot;^1E&quot;,50,&quot;^1&lt;&quot;,6,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/interacting-with-apis-to-import-data-from-the-web-2?ex=6&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^W&quot;,&quot;API requests&quot;,&quot;^1E&quot;,100,&quot;^1&lt;&quot;,7,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/interacting-with-apis-to-import-data-from-the-web-2?ex=7&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^W&quot;,&quot;JSON\\xe2\\x80\\x93from the web to Python&quot;,&quot;^1E&quot;,100,&quot;^1&lt;&quot;,8,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/interacting-with-apis-to-import-data-from-the-web-2?ex=8&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^W&quot;,&quot;Checking out the Wikipedia API&quot;,&quot;^1E&quot;,100,&quot;^1&lt;&quot;,9,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/interacting-with-apis-to-import-data-from-the-web-2?ex=9&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null]]],[&quot;^ &quot;,&quot;id&quot;,4140,&quot;^1;&quot;,null,&quot;^W&quot;,&quot;Diving  deep into the Twitter API&quot;,&quot;^X&quot;,&quot;In this chapter, you will consolidate your knowledge of interacting with APIs in a deep dive into the Twitter streaming API. You&#39;ll learn how to stream real-time Twitter data, and how to analyze and visualize it.&quot;,&quot;^1&lt;&quot;,3,&quot;^1=&quot;,&quot;diving-deep-into-the-twitter-api&quot;,&quot;^1&gt;&quot;,7,&quot;^1?&quot;,&quot;https://assets.datacamp.com/production/default/badges/missing.png&quot;,&quot;^1@&quot;,&quot;https://assets.datacamp.com/production/default/badges/missing_unc.png&quot;,&quot;^1A&quot;,&quot;26/09/2024&quot;,&quot;^1B&quot;,&quot;https://projector-video-pdf-converter.datacamp.com/1606/chapter3.pdf&quot;,&quot;^1C&quot;,null,&quot;xp&quot;,600,&quot;^1D&quot;,2,&quot;^F&quot;,[[&quot;^ &quot;,&quot;^B&quot;,&quot;VideoExercise&quot;,&quot;^W&quot;,&quot;The Twitter API and Authentication&quot;,&quot;^1E&quot;,50,&quot;^1&lt;&quot;,1,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/diving-deep-into-the-twitter-api?ex=1&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^W&quot;,&quot;Streaming tweets&quot;,&quot;^1E&quot;,100,&quot;^1&lt;&quot;,2,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/diving-deep-into-the-twitter-api?ex=2&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^W&quot;,&quot;Load and explore your Twitter data&quot;,&quot;^1E&quot;,100,&quot;^1&lt;&quot;,3,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/diving-deep-into-the-twitter-api?ex=3&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^W&quot;,&quot;Twitter data to DataFrame&quot;,&quot;^1E&quot;,100,&quot;^1&lt;&quot;,4,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/diving-deep-into-the-twitter-api?ex=4&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^W&quot;,&quot;A little bit of Twitter text analysis&quot;,&quot;^1E&quot;,100,&quot;^1&lt;&quot;,5,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/diving-deep-into-the-twitter-api?ex=5&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^W&quot;,&quot;Plotting your Twitter data&quot;,&quot;^1E&quot;,100,&quot;^1&lt;&quot;,6,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/diving-deep-into-the-twitter-api?ex=6&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;VideoExercise&quot;,&quot;^W&quot;,&quot;Final Thoughts&quot;,&quot;^1E&quot;,50,&quot;^1&lt;&quot;,7,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/diving-deep-into-the-twitter-api?ex=7&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null]]]],&quot;course_resources&quot;,[],&quot;translated_course_id&quot;,1606]]]],&quot;^F&quot;,[&quot;^0&quot;,[&quot;^ &quot;,&quot;n&quot;,&quot;PreFetchedRequestRecord&quot;,&quot;v&quot;,[&quot;^ &quot;,&quot;^2&quot;,&quot;SUCCESS&quot;,&quot;^1:&quot;,[[&quot;^ &quot;,&quot;id&quot;,990668,&quot;^B&quot;,&quot;VideoExercise&quot;,&quot;assignment&quot;,null,&quot;^W&quot;,&quot;Importing flat files from the web&quot;,&quot;sample_code&quot;,&quot;&quot;,&quot;instructions&quot;,null,&quot;^1&lt;&quot;,1,&quot;sct&quot;,&quot;&quot;,&quot;pre_exercise_code&quot;,&quot;&quot;,&quot;solution&quot;,&quot;&quot;,&quot;hint&quot;,null,&quot;attachments&quot;,null,&quot;xp&quot;,50,&quot;possible_answers&quot;,[],&quot;feedbacks&quot;,[],&quot;question&quot;,&quot;&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null,&quot;video_link&quot;,null,&quot;video_hls&quot;,null,&quot;aspect_ratio&quot;,56.25,&quot;projector_key&quot;,&quot;course_1606_59604c018a6e132016cd26144a12fee0&quot;,&quot;key&quot;,&quot;e36457c7ed&quot;,&quot;^U&quot;,&quot;python&quot;,&quot;course_id&quot;,1606,&quot;chapter_id&quot;,4135,&quot;version&quot;,&quot;v0&quot;,&quot;randomNumber&quot;,0.8364573381546423,&quot;externalId&quot;,990668],[&quot;^ &quot;,&quot;id&quot;,42707,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^2U&quot;,&quot;&lt;p&gt;You are about to import your first file from the web! The flat file you will import will be &lt;code&gt;&#39;winequality-red.csv&#39;&lt;/code&gt; from the University of California, Irvine&#39;s &lt;a href=\\\\\\\\&quot;https://archive.ics.uci.edu/ml/index.php\\\\\\\\&quot;&gt;Machine Learning repository&lt;/a&gt;. The flat file contains tabular data of physiochemical properties of red wine, such as pH, alcohol content and citric acid content, along with wine quality rating.&lt;/p&gt;\\\\\\\\n&lt;p&gt;The URL of the file is&lt;/p&gt;\\\\\\\\n&lt;pre&gt;&lt;code&gt;&#39;https://assets.datacamp.com/production/course_1606/datasets/winequality-red.csv&#39;\\\\\\\\n&lt;/code&gt;&lt;/pre&gt;\\\\\\\\n&lt;p&gt;After you import it, you&#39;ll check your working directory to confirm that it is there and then you&#39;ll load it into a &lt;code&gt;pandas&lt;/code&gt; DataFrame.&lt;/p&gt;&quot;,&quot;^W&quot;,&quot;Importing flat files from the web: your turn!&quot;,&quot;^2V&quot;,&quot;# Import package\\\\\\\\nfrom ____ import ____\\\\\\\\n\\\\\\\\n# Import pandas\\\\\\\\nimport pandas as pd\\\\\\\\n\\\\\\\\n# Assign url of file: url\\\\\\\\n\\\\\\\\n\\\\\\\\n# Save file locally\\\\\\\\n\\\\\\\\n\\\\\\\\n# Read file into a DataFrame and print its head\\\\\\\\ndf = pd.read_csv(&#39;winequality-red.csv&#39;, sep=&#39;;&#39;)\\\\\\\\nprint(df.head())&quot;,&quot;^2W&quot;,&quot;&lt;ul&gt;\\\\\\\\n&lt;li&gt;Import the function &lt;code&gt;urlretrieve&lt;/code&gt; from the subpackage &lt;code&gt;urllib.request&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;li&gt;Assign the URL of the file to the variable &lt;code&gt;url&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;li&gt;Use the function &lt;code&gt;urlretrieve()&lt;/code&gt; to save the file locally as &lt;code&gt;&#39;winequality-red.csv&#39;&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;li&gt;Execute the remaining code to load &lt;code&gt;&#39;winequality-red.csv&#39;&lt;/code&gt; in a pandas DataFrame and to print its head to the shell.&lt;/li&gt;\\\\\\\\n&lt;/ul&gt;&quot;,&quot;^1&lt;&quot;,2,&quot;sct&quot;,&quot;Ex().has_import(\\\\\\\\&quot;urllib.request.urlretrieve\\\\\\\\&quot;)\\\\\\\\nEx().has_import(\\\\\\\\&quot;pandas\\\\\\\\&quot;)\\\\\\\\nEx().check_object(\\\\\\\\&quot;url\\\\\\\\&quot;).has_equal_value()\\\\\\\\nEx().check_function(\\\\\\\\&quot;urllib.request.urlretrieve\\\\\\\\&quot;).multi(\\\\\\\\n  check_args(0).has_equal_value(),\\\\\\\\n  check_args(1).has_equal_value()\\\\\\\\n)\\\\\\\\nEx().check_correct(\\\\\\\\n  check_object(\\\\\\\\&quot;df\\\\\\\\&quot;).has_equal_value(),\\\\\\\\n  check_function(\\\\\\\\&quot;pandas.read_csv\\\\\\\\&quot;).multi(\\\\\\\\n    check_args(0).has_equal_value(),\\\\\\\\n    check_args(1).has_equal_value()\\\\\\\\n  )\\\\\\\\n)\\\\\\\\nEx().has_printout(0)\\\\\\\\nsuccess_msg(\\\\\\\\&quot;Awesome!\\\\\\\\&quot;)\\\\\\\\n&quot;,&quot;^2X&quot;,&quot;&quot;,&quot;^2Y&quot;,&quot;# Import package\\\\\\\\nfrom urllib.request import urlretrieve\\\\\\\\n\\\\\\\\n# Import pandas\\\\\\\\nimport pandas as pd\\\\\\\\n\\\\\\\\n# Assign url of file: url\\\\\\\\nurl = &#39;https://assets.datacamp.com/production/course_1606/datasets/winequality-red.csv&#39;\\\\\\\\n\\\\\\\\n# Save file locally\\\\\\\\nurlretrieve(url, &#39;winequality-red.csv&#39;)\\\\\\\\n\\\\\\\\n# Read file into a DataFrame and print its head\\\\\\\\ndf = pd.read_csv(&#39;winequality-red.csv&#39;, sep=&#39;;&#39;)\\\\\\\\nprint(df.head())&quot;,&quot;^2Z&quot;,&quot;&lt;ul&gt;\\\\\\\\n&lt;li&gt;To import a function &lt;code&gt;y&lt;/code&gt; from a subpackage &lt;code&gt;x&lt;/code&gt;, execute &lt;code&gt;from x import y&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;li&gt;This one&#39;s a long URL. Make sure you typed it in correctly!&lt;/li&gt;\\\\\\\\n&lt;li&gt;Pass the &lt;em&gt;url&lt;/em&gt; to import (in the &lt;code&gt;url&lt;/code&gt; object you defined) as the first argument and the &lt;em&gt;filename&lt;/em&gt; for saving the file locally as the second argument to &lt;code&gt;urlretrieve()&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;li&gt;You don&#39;t have to change the code for loading &lt;code&gt;&#39;winequality-red.csv&#39;&lt;/code&gt; and printing its head.&lt;/li&gt;\\\\\\\\n&lt;/ul&gt;&quot;,&quot;^2[&quot;,null,&quot;xp&quot;,100,&quot;^30&quot;,[],&quot;^31&quot;,[],&quot;^32&quot;,&quot;&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null,&quot;^U&quot;,&quot;python&quot;,&quot;^3:&quot;,0.13306885324133644,&quot;^3;&quot;,42707],[&quot;^ &quot;,&quot;id&quot;,42708,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^2U&quot;,&quot;&lt;p&gt;You have just imported a file from the web, saved it locally and loaded it into a DataFrame. If you just wanted to load a file from the web into a DataFrame without first saving it locally, you can do that easily using &lt;code&gt;pandas&lt;/code&gt;. In particular, you can use the function &lt;code&gt;pd.read_csv()&lt;/code&gt; with the URL as the first argument and the separator &lt;code&gt;sep&lt;/code&gt; as the second argument.&lt;/p&gt;\\\\\\\\n&lt;p&gt;The URL of the file, once again, is&lt;/p&gt;\\\\\\\\n&lt;pre&gt;&lt;code&gt;&#39;https://assets.datacamp.com/production/course_1606/datasets/winequality-red.csv&#39;\\\\\\\\n&lt;/code&gt;&lt;/pre&gt;&quot;,&quot;^W&quot;,&quot;Opening and reading flat files from the web&quot;,&quot;^2V&quot;,&quot;# Import packages\\\\\\\\nimport matplotlib.pyplot as plt\\\\\\\\nimport pandas as pd\\\\\\\\n\\\\\\\\n# Assign url of file: url\\\\\\\\n\\\\\\\\n\\\\\\\\n# Read file into a DataFrame: df\\\\\\\\n\\\\\\\\n\\\\\\\\n# Print the head of the DataFrame\\\\\\\\nprint(____)\\\\\\\\n\\\\\\\\n# Plot first column of df\\\\\\\\ndf.iloc[:, 0].hist()\\\\\\\\nplt.xlabel(&#39;fixed acidity (g(tartaric acid)/dm$^3$)&#39;)\\\\\\\\nplt.ylabel(&#39;count&#39;)\\\\\\\\nplt.show()\\\\\\\\n&quot;,&quot;^2W&quot;,&quot;&lt;ul&gt;\\\\\\\\n&lt;li&gt;Assign the URL of the file to the variable &lt;code&gt;url&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;li&gt;Read file into a DataFrame &lt;code&gt;df&lt;/code&gt; using &lt;code&gt;pd.read_csv()&lt;/code&gt;, recalling that the separator in the file is &lt;code&gt;&#39;;&#39;&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;li&gt;Print the head of the DataFrame &lt;code&gt;df&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;li&gt;Execute the rest of the code to plot histogram of the first feature in the DataFrame &lt;code&gt;df&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;/ul&gt;&quot;,&quot;^1&lt;&quot;,3,&quot;sct&quot;,&quot;Ex().has_import(\\\\\\\\&quot;matplotlib.pyplot\\\\\\\\&quot;)\\\\\\\\nEx().has_import(\\\\\\\\&quot;pandas\\\\\\\\&quot;)\\\\\\\\nEx().check_object(\\\\\\\\&quot;url\\\\\\\\&quot;).has_equal_value()\\\\\\\\nEx().check_correct(\\\\\\\\n  check_object(\\\\\\\\&quot;df\\\\\\\\&quot;).has_equal_value(),\\\\\\\\n  check_function(\\\\\\\\&quot;pandas.read_csv\\\\\\\\&quot;).multi(\\\\\\\\n    check_args(0).has_equal_value(),\\\\\\\\n    check_args(1).has_equal_value()\\\\\\\\n  )\\\\\\\\n)\\\\\\\\nEx().has_printout(0)\\\\\\\\nEx().has_equal_ast(code=\\\\\\\\&quot;df.iloc[:, 0].hist\\\\\\\\&quot;, incorrect_msg=\\\\\\\\&quot;Please do not change the code to plot the histogram.\\\\\\\\&quot;)\\\\\\\\nEx().check_function(\\\\\\\\&quot;matplotlib.pyplot.show\\\\\\\\&quot;)\\\\\\\\n\\\\\\\\nsuccess_msg(\\\\\\\\&quot;Awesome!\\\\\\\\&quot;)\\\\\\\\n&quot;,&quot;^2X&quot;,&quot;&quot;,&quot;^2Y&quot;,&quot;# Import packages\\\\\\\\nimport matplotlib.pyplot as plt\\\\\\\\nimport pandas as pd\\\\\\\\n\\\\\\\\n# Assign url of file: url\\\\\\\\nurl = &#39;https://assets.datacamp.com/production/course_1606/datasets/winequality-red.csv&#39;\\\\\\\\n\\\\\\\\n# Read file into a DataFrame: df\\\\\\\\ndf = pd.read_csv(url, sep=&#39;;&#39;)\\\\\\\\n\\\\\\\\n# Print the head of the DataFrame\\\\\\\\nprint(df.head())\\\\\\\\n\\\\\\\\n# Plot first column of df\\\\\\\\ndf.iloc[:, 0].hist()\\\\\\\\nplt.xlabel(&#39;fixed acidity (g(tartaric acid)/dm$^3$)&#39;)\\\\\\\\nplt.ylabel(&#39;count&#39;)\\\\\\\\nplt.show()\\\\\\\\n&quot;,&quot;^2Z&quot;,&quot;&lt;ul&gt;\\\\\\\\n&lt;li&gt;Make sure you typed the URL correctly!&lt;/li&gt;\\\\\\\\n&lt;li&gt;Pass the &lt;em&gt;url&lt;/em&gt; (the &lt;code&gt;url&lt;/code&gt; object you defined) as the first argument and the &lt;em&gt;separator&lt;/em&gt; as the second argument to &lt;code&gt;pd.read_csv()&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;li&gt;The &lt;em&gt;head&lt;/em&gt; of a DataFrame can be accessed by using &lt;code&gt;head()&lt;/code&gt; on the DataFrame.&lt;/li&gt;\\\\\\\\n&lt;li&gt;You don&#39;t have to change any of the code for plotting the histograms.&lt;/li&gt;\\\\\\\\n&lt;/ul&gt;&quot;,&quot;^2[&quot;,null,&quot;xp&quot;,100,&quot;^30&quot;,[],&quot;^31&quot;,[],&quot;^32&quot;,&quot;&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null,&quot;^U&quot;,&quot;python&quot;,&quot;^3:&quot;,0.7785533906387767,&quot;^3;&quot;,42708],[&quot;^ &quot;,&quot;id&quot;,42709,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^2U&quot;,&quot;&lt;p&gt;Congrats! You&#39;ve just loaded a flat file from the web into a DataFrame without first saving it locally using the &lt;code&gt;pandas&lt;/code&gt; function &lt;code&gt;pd.read_csv()&lt;/code&gt;. This function is super cool because it has close relatives that allow you to load all types of files, not only flat ones. In this interactive exercise, you&#39;ll use &lt;code&gt;pd.read_excel()&lt;/code&gt; to import an Excel spreadsheet.&lt;/p&gt;\\\\\\\\n&lt;p&gt;The URL of the spreadsheet is&lt;/p&gt;\\\\\\\\n&lt;pre&gt;&lt;code&gt;&#39;https://assets.datacamp.com/course/importing_data_into_r/latitude.xls&#39;\\\\\\\\n&lt;/code&gt;&lt;/pre&gt;\\\\\\\\n&lt;p&gt;Your job is to use &lt;code&gt;pd.read_excel()&lt;/code&gt; to read in all of its sheets, print the sheet names and then print the head of the first sheet &lt;em&gt;using its name, not its index&lt;/em&gt;.&lt;/p&gt;\\\\\\\\n&lt;p&gt;Note that the output of &lt;code&gt;pd.read_excel()&lt;/code&gt; is a Python dictionary with sheet names as keys and corresponding DataFrames as corresponding values.&lt;/p&gt;&quot;,&quot;^W&quot;,&quot;Importing non-flat files from the web&quot;,&quot;^2V&quot;,&quot;# Import package\\\\\\\\nimport pandas as pd\\\\\\\\n\\\\\\\\n# Assign url of file: url\\\\\\\\n\\\\\\\\n\\\\\\\\n# Read in all sheets of Excel file: xls\\\\\\\\n\\\\\\\\n\\\\\\\\n# Print the sheetnames to the shell\\\\\\\\n\\\\\\\\n\\\\\\\\n# Print the head of the first sheet (using its name, NOT its index)\\\\\\\\n\\\\\\\\n&quot;,&quot;^2W&quot;,&quot;&lt;ul&gt;\\\\\\\\n&lt;li&gt;Assign the URL of the file to the variable &lt;code&gt;url&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;li&gt;Read the file in &lt;code&gt;url&lt;/code&gt; into a dictionary &lt;code&gt;xls&lt;/code&gt; using &lt;code&gt;pd.read_excel()&lt;/code&gt; recalling that, in order to import all sheets you need to pass &lt;code&gt;None&lt;/code&gt; to the argument &lt;code&gt;sheet_name&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;li&gt;Print the names of the sheets in the Excel spreadsheet; these will be the keys of the dictionary &lt;code&gt;xls&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;li&gt;Print the head of the first sheet &lt;em&gt;using the sheet name, not the index of the sheet&lt;/em&gt;! The sheet name is &lt;code&gt;&#39;1700&#39;&lt;/code&gt;&lt;/li&gt;\\\\\\\\n&lt;/ul&gt;&quot;,&quot;^1&lt;&quot;,4,&quot;sct&quot;,&quot;Ex().has_import(&#39;pandas&#39;)\\\\\\\\nEx().check_correct(\\\\\\\\n    has_printout(0),\\\\\\\\n    multi(\\\\\\\\n        check_correct(\\\\\\\\n            check_object(&#39;xls&#39;).is_instance(dict),\\\\\\\\n            check_correct(\\\\\\\\n                check_function(&#39;pandas.read_excel&#39;).multi(\\\\\\\\n                    check_args(0).has_equal_value(),\\\\\\\\n                    check_args(&#39;sheet_name&#39;).has_equal_value()\\\\\\\\n                ),\\\\\\\\n                check_object(&#39;url&#39;).has_equal_value()\\\\\\\\n            )\\\\\\\\n        )\\\\\\\\n    )\\\\\\\\n)\\\\\\\\nEx().has_printout(1)\\\\\\\\nsuccess_msg(\\\\\\\\&quot;Awesome!\\\\\\\\&quot;)&quot;,&quot;^2X&quot;,&quot;&quot;,&quot;^2Y&quot;,&quot;# Import package\\\\\\\\nimport pandas as pd\\\\\\\\n\\\\\\\\n# Assign url of file: url\\\\\\\\nurl = &#39;https://assets.datacamp.com/course/importing_data_into_r/latitude.xls&#39;\\\\\\\\n\\\\\\\\n# Read in all sheets of Excel file: xls\\\\\\\\nxls = pd.read_excel(url, sheet_name=None)\\\\\\\\n\\\\\\\\n# Print the sheetnames to the shell\\\\\\\\nprint(xls.keys())\\\\\\\\n\\\\\\\\n# Print the head of the first sheet (using its name, NOT its index)\\\\\\\\nprint(xls[&#39;1700&#39;].head())&quot;,&quot;^2Z&quot;,&quot;&lt;ul&gt;\\\\\\\\n&lt;li&gt;Make sure you typed in the URL correctly!&lt;/li&gt;\\\\\\\\n&lt;li&gt;Pass the &lt;em&gt;url&lt;/em&gt; (the &lt;code&gt;url&lt;/code&gt; object you defined) as the first argument and &lt;code&gt;sheet_name&lt;/code&gt; with its corresponding value as the second argument to &lt;code&gt;pd.read_excel()&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;li&gt;The &lt;em&gt;keys&lt;/em&gt; of a dictionary can be accessed by using &lt;code&gt;keys()&lt;/code&gt; on the dictionary.&lt;/li&gt;\\\\\\\\n&lt;li&gt;You can access a sheet using the format: &lt;em&gt;dictionary&lt;/em&gt;&lt;strong&gt;[&lt;/strong&gt;&lt;em&gt;sheet name or index&lt;/em&gt;&lt;strong&gt;]&lt;/strong&gt;.&lt;/li&gt;\\\\\\\\n&lt;/ul&gt;&quot;,&quot;^2[&quot;,null,&quot;xp&quot;,100,&quot;^30&quot;,[],&quot;^31&quot;,[],&quot;^32&quot;,&quot;&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null,&quot;^U&quot;,&quot;python&quot;,&quot;^3:&quot;,0.29677029636305896,&quot;^3;&quot;,42709],[&quot;^ &quot;,&quot;id&quot;,990669,&quot;^B&quot;,&quot;VideoExercise&quot;,&quot;^2U&quot;,null,&quot;^W&quot;,&quot;HTTP requests to import files from the web&quot;,&quot;^2V&quot;,&quot;&quot;,&quot;^2W&quot;,null,&quot;^1&lt;&quot;,5,&quot;sct&quot;,&quot;&quot;,&quot;^2X&quot;,&quot;&quot;,&quot;^2Y&quot;,&quot;&quot;,&quot;^2Z&quot;,null,&quot;^2[&quot;,null,&quot;xp&quot;,50,&quot;^30&quot;,[],&quot;^31&quot;,[],&quot;^32&quot;,&quot;&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null,&quot;^33&quot;,null,&quot;^34&quot;,null,&quot;^35&quot;,56.25,&quot;^36&quot;,&quot;course_1606_9d15ae176be1800b996f7869a82b8087&quot;,&quot;key&quot;,&quot;e480d1fdcf&quot;,&quot;^U&quot;,&quot;python&quot;,&quot;^37&quot;,1606,&quot;^38&quot;,4135,&quot;^39&quot;,&quot;v0&quot;,&quot;^3:&quot;,0.08513839239732768,&quot;^3;&quot;,990669],[&quot;^ &quot;,&quot;id&quot;,42711,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^2U&quot;,&quot;&lt;p&gt;Now that you know the basics behind HTTP GET requests, it&#39;s time to perform some of your own. In this interactive exercise, you will ping our very own DataCamp servers to perform a GET request to extract information from the first coding exercise of this course, &lt;code&gt;\\\\\\\\&quot;https://campus.datacamp.com/courses/1606/4135?ex=2\\\\\\\\&quot;&lt;/code&gt;.&lt;/p&gt;\\\\\\\\n&lt;p&gt;In the next exercise, you&#39;ll extract the HTML itself. Right now, however, you are going to package and send the request and then catch the response.&lt;/p&gt;&quot;,&quot;^W&quot;,&quot;Performing HTTP requests in Python using urllib&quot;,&quot;^2V&quot;,&quot;# Import packages\\\\\\\\n\\\\\\\\n\\\\\\\\n# Specify the url\\\\\\\\nurl = \\\\\\\\&quot;https://campus.datacamp.com/courses/1606/4135?ex=2\\\\\\\\&quot;\\\\\\\\n\\\\\\\\n# This packages the request: request\\\\\\\\n\\\\\\\\n\\\\\\\\n# Sends the request and catches the response: response\\\\\\\\n\\\\\\\\n\\\\\\\\n# Print the datatype of response\\\\\\\\nprint(type(response))\\\\\\\\n\\\\\\\\n# Be polite and close the response!\\\\\\\\nresponse.close()\\\\\\\\n&quot;,&quot;^2W&quot;,&quot;&lt;ul&gt;\\\\\\\\n&lt;li&gt;Import the functions &lt;code&gt;urlopen&lt;/code&gt; and &lt;code&gt;Request&lt;/code&gt; from the subpackage &lt;code&gt;urllib.request&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;li&gt;Package the request to the url &lt;code&gt;\\\\\\\\&quot;https://campus.datacamp.com/courses/1606/4135?ex=2\\\\\\\\&quot;&lt;/code&gt; using the function &lt;code&gt;Request()&lt;/code&gt; and assign it to &lt;code&gt;request&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;li&gt;Send the request and catch the response in the variable &lt;code&gt;response&lt;/code&gt; with  the function &lt;code&gt;urlopen()&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;li&gt;Run the rest of the code to see the datatype of &lt;code&gt;response&lt;/code&gt; and to close the connection!&lt;/li&gt;\\\\\\\\n&lt;/ul&gt;&quot;,&quot;^1&lt;&quot;,6,&quot;sct&quot;,&quot;\\\\\\\\n# Test: import urlopen, Request\\\\\\\\nimport_msg = \\\\\\\\&quot;Did you correctly import the required packages?\\\\\\\\&quot;\\\\\\\\nEx().has_import(\\\\\\\\n    \\\\\\\\&quot;urllib.request.urlopen\\\\\\\\&quot;,\\\\\\\\n    not_imported_msg=import_msg\\\\\\\\n)\\\\\\\\nEx().has_import(\\\\\\\\n    \\\\\\\\&quot;urllib.request.Request\\\\\\\\&quot;,\\\\\\\\n    not_imported_msg=import_msg\\\\\\\\n)\\\\\\\\n\\\\\\\\n# Test: Predefined code\\\\\\\\npredef_msg = \\\\\\\\&quot;You don&#39;t have to change any of the predefined code.\\\\\\\\&quot;\\\\\\\\nEx().check_object(\\\\\\\\&quot;url\\\\\\\\&quot;, missing_msg=predef_msg).has_equal_value(incorrect_msg = predef_msg)\\\\\\\\n\\\\\\\\n# Test: call to Request() and &#39;request&#39; variable\\\\\\\\nEx().check_function(\\\\\\\\&quot;urllib.request.Request\\\\\\\\&quot;).check_args(0).has_equal_value()\\\\\\\\nEx().check_object(\\\\\\\\&quot;request\\\\\\\\&quot;)\\\\\\\\n  \\\\\\\\n# Test: call to urlopen() and &#39;response&#39; variable\\\\\\\\nEx().check_function(\\\\\\\\&quot;urllib.request.urlopen\\\\\\\\&quot;).check_args(0).has_equal_ast()\\\\\\\\nEx().check_object(\\\\\\\\&quot;response\\\\\\\\&quot;),\\\\\\\\n\\\\\\\\n# Test: Predefined code\\\\\\\\nEx().has_printout(0)\\\\\\\\nEx().check_function(\\\\\\\\&quot;response.close\\\\\\\\&quot;)\\\\\\\\n\\\\\\\\nsuccess_msg(\\\\\\\\&quot;Awesome!\\\\\\\\&quot;)\\\\\\\\n&quot;,&quot;^2X&quot;,&quot;&quot;,&quot;^2Y&quot;,&quot;# Import packages\\\\\\\\nfrom urllib.request import urlopen, Request\\\\\\\\n\\\\\\\\n# Specify the url\\\\\\\\nurl = \\\\\\\\&quot;https://campus.datacamp.com/courses/1606/4135?ex=2\\\\\\\\&quot;\\\\\\\\n\\\\\\\\n# This packages the request: request\\\\\\\\nrequest = Request(url)\\\\\\\\n\\\\\\\\n# Sends the request and catches the response: response\\\\\\\\nresponse = urlopen(request)\\\\\\\\n\\\\\\\\n# Print the datatype of response\\\\\\\\nprint(type(response))\\\\\\\\n\\\\\\\\n# Be polite and close the response!\\\\\\\\nresponse.close()\\\\\\\\n&quot;,&quot;^2Z&quot;,&quot;&lt;ul&gt;\\\\\\\\n&lt;li&gt;To import two functions in one line, import the first function as usual and add a comma &lt;code&gt;,&lt;/code&gt; followed by the second function.&lt;/li&gt;\\\\\\\\n&lt;li&gt;Pass the &lt;em&gt;url&lt;/em&gt; (already in the &lt;code&gt;url&lt;/code&gt; object defined) as an argument to &lt;code&gt;Request()&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;li&gt;Pass &lt;code&gt;request&lt;/code&gt; as an argument to &lt;code&gt;urlopen()&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;li&gt;You don&#39;t have to modify the code for printing the datatype of &lt;code&gt;response&lt;/code&gt; and closing the connection.&lt;/li&gt;\\\\\\\\n&lt;/ul&gt;&quot;,&quot;^2[&quot;,null,&quot;xp&quot;,100,&quot;^30&quot;,[],&quot;^31&quot;,[],&quot;^32&quot;,&quot;&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null,&quot;^U&quot;,&quot;python&quot;,&quot;^3:&quot;,0.025167267893165146,&quot;^3;&quot;,42711],[&quot;^ &quot;,&quot;id&quot;,42712,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^2U&quot;,&quot;&lt;p&gt;You have just packaged and sent a GET request to &lt;code&gt;\\\\\\\\&quot;https://campus.datacamp.com/courses/1606/4135?ex=2\\\\\\\\&quot;&lt;/code&gt; and then caught the response. You saw that such a response is a &lt;code&gt;http.client.HTTPResponse&lt;/code&gt; object. The question remains: what can you do with this response?&lt;/p&gt;\\\\\\\\n&lt;p&gt;Well, as it came from an HTML page, you could &lt;em&gt;read&lt;/em&gt; it to extract the HTML and, in fact, such a &lt;code&gt;http.client.HTTPResponse&lt;/code&gt; object has an associated &lt;code&gt;read()&lt;/code&gt; method. In this exercise, you&#39;ll build on your previous great work to extract the response and print the HTML.&lt;/p&gt;&quot;,&quot;^W&quot;,&quot;Printing HTTP request results in Python using urllib&quot;,&quot;^2V&quot;,&quot;# Import packages\\\\\\\\nfrom urllib.request import urlopen, Request\\\\\\\\n\\\\\\\\n# Specify the url\\\\\\\\nurl = \\\\\\\\&quot;https://campus.datacamp.com/courses/1606/4135?ex=2\\\\\\\\&quot;\\\\\\\\n\\\\\\\\n# This packages the request\\\\\\\\nrequest = Request(url)\\\\\\\\n\\\\\\\\n# Sends the request and catches the response: response\\\\\\\\n\\\\\\\\n\\\\\\\\n# Extract the response: html\\\\\\\\n\\\\\\\\n\\\\\\\\n# Print the html\\\\\\\\n\\\\\\\\n\\\\\\\\n# Be polite and close the response!\\\\\\\\nresponse.close()&quot;,&quot;^2W&quot;,&quot;&lt;ul&gt;\\\\\\\\n&lt;li&gt;Send the request and catch the response in the variable &lt;code&gt;response&lt;/code&gt; with the function &lt;code&gt;urlopen()&lt;/code&gt;, as in the previous exercise.&lt;/li&gt;\\\\\\\\n&lt;li&gt;Extract the response using the &lt;code&gt;read()&lt;/code&gt; method and store the result in the variable &lt;code&gt;html&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;li&gt;Print the string &lt;code&gt;html&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;li&gt;Hit submit to perform all of the above and to close the response: be tidy!&lt;/li&gt;\\\\\\\\n&lt;/ul&gt;&quot;,&quot;^1&lt;&quot;,7,&quot;sct&quot;,&quot;\\\\\\\\n# Test: Predefined code\\\\\\\\npredef_msg = \\\\\\\\&quot;You don&#39;t have to change any of the predefined code.\\\\\\\\&quot;\\\\\\\\nEx().has_import(\\\\\\\\n    \\\\\\\\&quot;urllib.request.urlopen\\\\\\\\&quot;,\\\\\\\\n    not_imported_msg=predef_msg\\\\\\\\n)\\\\\\\\n\\\\\\\\nEx().has_import(\\\\\\\\n    \\\\\\\\&quot;urllib.request.Request\\\\\\\\&quot;,\\\\\\\\n    not_imported_msg=predef_msg\\\\\\\\n)\\\\\\\\n\\\\\\\\nEx().check_object(\\\\\\\\&quot;url\\\\\\\\&quot;).has_equal_value()\\\\\\\\n\\\\\\\\n# Test: call to Request() and &#39;request&#39; variable\\\\\\\\nEx().check_function(\\\\\\\\&quot;urllib.request.Request\\\\\\\\&quot;).check_args(0).has_equal_value()\\\\\\\\nEx().check_object(\\\\\\\\&quot;request\\\\\\\\&quot;)\\\\\\\\n\\\\\\\\n# Test: call to urlopen() and &#39;response&#39; variable\\\\\\\\nEx().check_function(\\\\\\\\&quot;urllib.request.urlopen\\\\\\\\&quot;).check_args(0).has_equal_ast()\\\\\\\\nEx().check_object(\\\\\\\\&quot;response\\\\\\\\&quot;)\\\\\\\\n\\\\\\\\n# Test: call to urlopen() and &#39;response&#39; variable\\\\\\\\nEx().check_function(\\\\\\\\&quot;response.read\\\\\\\\&quot;)\\\\\\\\nEx().check_object(\\\\\\\\&quot;html\\\\\\\\&quot;)\\\\\\\\n\\\\\\\\n# Test: call to print()\\\\\\\\nEx().check_function(&#39;print&#39;).check_args(0).has_equal_ast()\\\\\\\\n\\\\\\\\n# Test: Predefined code\\\\\\\\nEx().check_function(\\\\\\\\&quot;response.close\\\\\\\\&quot;)\\\\\\\\n\\\\\\\\nsuccess_msg(\\\\\\\\&quot;Awesome!\\\\\\\\&quot;)\\\\\\\\n&quot;,&quot;^2X&quot;,&quot;&quot;,&quot;^2Y&quot;,&quot;# Import packages\\\\\\\\nfrom urllib.request import urlopen, Request\\\\\\\\n\\\\\\\\n# Specify the url\\\\\\\\nurl = \\\\\\\\&quot;https://campus.datacamp.com/courses/1606/4135?ex=2\\\\\\\\&quot;\\\\\\\\n\\\\\\\\n# This packages the request\\\\\\\\nrequest = Request(url)\\\\\\\\n\\\\\\\\n# Sends the request and catches the response: response\\\\\\\\nresponse = urlopen(request)\\\\\\\\n\\\\\\\\n# Extract the response: html\\\\\\\\nhtml = response.read()\\\\\\\\n\\\\\\\\n# Print the html\\\\\\\\nprint(html)\\\\\\\\n\\\\\\\\n# Be polite and close the response!\\\\\\\\nresponse.close()&quot;,&quot;^2Z&quot;,&quot;&lt;ul&gt;\\\\\\\\n&lt;li&gt;Pass &lt;code&gt;request&lt;/code&gt; as an argument to &lt;code&gt;urlopen()&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;li&gt;Apply the method &lt;code&gt;read()&lt;/code&gt; to the response object &lt;code&gt;response&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;li&gt;Simply pass &lt;code&gt;html&lt;/code&gt; to the &lt;code&gt;print()&lt;/code&gt; function.&lt;/li&gt;\\\\\\\\n&lt;li&gt;You don&#39;t have to modify the code for closing the response.&lt;/li&gt;\\\\\\\\n&lt;/ul&gt;&quot;,&quot;^2[&quot;,null,&quot;xp&quot;,100,&quot;^30&quot;,[],&quot;^31&quot;,[],&quot;^32&quot;,&quot;&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null,&quot;^U&quot;,&quot;python&quot;,&quot;^3:&quot;,0.8963620619853123,&quot;^3;&quot;,42712],[&quot;^ &quot;,&quot;id&quot;,42713,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^2U&quot;,&quot;&lt;p&gt;Now that you&#39;ve got your head and hands around making HTTP requests using the urllib package, you&#39;re going to figure out how to do the same using the higher-level requests library. You&#39;ll once again be pinging DataCamp servers for their &lt;code&gt;\\\\\\\\&quot;http://www.datacamp.com/teach/documentation\\\\\\\\&quot;&lt;/code&gt; page.&lt;/p&gt;\\\\\\\\n&lt;p&gt;Note that unlike in the previous exercises using urllib, you don&#39;t have to close the connection when using requests!&lt;/p&gt;&quot;,&quot;^W&quot;,&quot;Performing HTTP requests in Python using requests&quot;,&quot;^2V&quot;,&quot;# Import package\\\\\\\\n\\\\\\\\n\\\\\\\\n# Specify the url: url\\\\\\\\n\\\\\\\\n\\\\\\\\n# Packages the request, send the request and catch the response: r\\\\\\\\n\\\\\\\\n\\\\\\\\n# Extract the response: text\\\\\\\\n\\\\\\\\n\\\\\\\\n# Print the html\\\\\\\\nprint(text)&quot;,&quot;^2W&quot;,&quot;&lt;ul&gt;\\\\\\\\n&lt;li&gt;Import the package &lt;code&gt;requests&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;li&gt;Assign the URL of interest to the variable &lt;code&gt;url&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;li&gt;Package the request to the URL, send the request and catch the response with a single function &lt;code&gt;requests.get()&lt;/code&gt;, assigning the response to the variable &lt;code&gt;r&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;li&gt;Use the &lt;code&gt;text&lt;/code&gt; attribute of the object &lt;code&gt;r&lt;/code&gt; to return the HTML of the webpage as a string; store the result in a variable &lt;code&gt;text&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;li&gt;Hit submit to print the HTML of the webpage.&lt;/li&gt;\\\\\\\\n&lt;/ul&gt;&quot;,&quot;^1&lt;&quot;,8,&quot;sct&quot;,&quot;\\\\\\\\n# Test: import requests\\\\\\\\nEx().has_import(\\\\\\\\&quot;requests\\\\\\\\&quot;)\\\\\\\\n\\\\\\\\n# Test: &#39;url&#39; variable\\\\\\\\nEx().check_object(\\\\\\\\&quot;url\\\\\\\\&quot;).has_equal_value()\\\\\\\\n\\\\\\\\n# Test: call to requests.get() and &#39;r&#39; variable\\\\\\\\nEx().check_function(\\\\\\\\&quot;requests.get\\\\\\\\&quot;).check_args(0).has_equal_value()\\\\\\\\nEx().check_object(\\\\\\\\&quot;r\\\\\\\\&quot;)\\\\\\\\n\\\\\\\\n# Test: &#39;text&#39; variable\\\\\\\\nEx().has_code(\\\\\\\\&quot;r.text\\\\\\\\&quot;, pattern = False, not_typed_msg=\\\\\\\\&quot;Have you used `r.text` to create `text`?\\\\\\\\&quot;)\\\\\\\\nEx().check_object(\\\\\\\\&quot;text\\\\\\\\&quot;)\\\\\\\\n\\\\\\\\n# Test: Predefined code\\\\\\\\nEx().check_function(&#39;print&#39;).check_args(0).has_equal_ast()\\\\\\\\n\\\\\\\\nsuccess_msg(\\\\\\\\&quot;Awesome!\\\\\\\\&quot;)\\\\\\\\n&quot;,&quot;^2X&quot;,&quot;&quot;,&quot;^2Y&quot;,&quot;# Import package\\\\\\\\nimport requests\\\\\\\\n\\\\\\\\n# Specify the url: url\\\\\\\\nurl = \\\\\\\\&quot;http://www.datacamp.com/teach/documentation\\\\\\\\&quot;\\\\\\\\n\\\\\\\\n# Packages the request, send the request and catch the response: r\\\\\\\\nr = requests.get(url)\\\\\\\\n\\\\\\\\n# Extract the response: text\\\\\\\\ntext = r.text\\\\\\\\n\\\\\\\\n# Print the html\\\\\\\\nprint(text)&quot;,&quot;^2Z&quot;,&quot;&lt;ul&gt;\\\\\\\\n&lt;li&gt;To import a package &lt;code&gt;x&lt;/code&gt;, execute &lt;code&gt;import x&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;li&gt;Did you type in the URL correctly?&lt;/li&gt;\\\\\\\\n&lt;li&gt;Pass the &lt;em&gt;url&lt;/em&gt; (the &lt;code&gt;url&lt;/code&gt; object you defined) as an argument to &lt;code&gt;requests.get()&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;li&gt;You can access the &lt;code&gt;text&lt;/code&gt; attribute of the object &lt;code&gt;r&lt;/code&gt; by executing &lt;code&gt;r.text&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;li&gt;You don&#39;t have to modify the code for printing the HTML of the webpage.&lt;/li&gt;\\\\\\\\n&lt;/ul&gt;&quot;,&quot;^2[&quot;,null,&quot;xp&quot;,100,&quot;^30&quot;,[],&quot;^31&quot;,[],&quot;^32&quot;,&quot;&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null,&quot;^U&quot;,&quot;python&quot;,&quot;^3:&quot;,0.9499234036356423,&quot;^3;&quot;,42713],[&quot;^ &quot;,&quot;id&quot;,990670,&quot;^B&quot;,&quot;VideoExercise&quot;,&quot;^2U&quot;,null,&quot;^W&quot;,&quot;Scraping the web in Python&quot;,&quot;^2V&quot;,&quot;&quot;,&quot;^2W&quot;,null,&quot;^1&lt;&quot;,9,&quot;sct&quot;,&quot;&quot;,&quot;^2X&quot;,&quot;&quot;,&quot;^2Y&quot;,&quot;&quot;,&quot;^2Z&quot;,null,&quot;^2[&quot;,null,&quot;xp&quot;,50,&quot;^30&quot;,[],&quot;^31&quot;,[],&quot;^32&quot;,&quot;&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null,&quot;^33&quot;,null,&quot;^34&quot;,null,&quot;^35&quot;,56.25,&quot;^36&quot;,&quot;course_1606_9d1f8a331d1200c7e1bdbfcaf3a7a491&quot;,&quot;key&quot;,&quot;da43858012&quot;,&quot;^U&quot;,&quot;python&quot;,&quot;^37&quot;,1606,&quot;^38&quot;,4135,&quot;^39&quot;,&quot;v0&quot;,&quot;^3:&quot;,0.6150986604311994,&quot;^3;&quot;,990670],[&quot;^ &quot;,&quot;id&quot;,42715,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^2U&quot;,&quot;&lt;p&gt;In this interactive exercise, you&#39;ll learn how to use the BeautifulSoup package to &lt;em&gt;parse&lt;/em&gt;, &lt;em&gt;prettify&lt;/em&gt; and &lt;em&gt;extract&lt;/em&gt; information from HTML. You&#39;ll scrape the data from the webpage of Guido van Rossum, Python&#39;s very own &lt;a href=\\\\\\\\&quot;https://en.wikipedia.org/wiki/Benevolent_dictator_for_life\\\\\\\\&quot;&gt;Benevolent Dictator for Life&lt;/a&gt;. In the following exercises, you&#39;ll prettify the HTML and then extract the text and the hyperlinks.&lt;/p&gt;\\\\\\\\n&lt;p&gt;The URL of interest is &lt;code&gt;url = &#39;https://www.python.org/~guido/&#39;&lt;/code&gt;.&lt;/p&gt;&quot;,&quot;^W&quot;,&quot;Parsing HTML with BeautifulSoup&quot;,&quot;^2V&quot;,&quot;# Import packages\\\\\\\\nimport requests\\\\\\\\nfrom ____ import ____\\\\\\\\n\\\\\\\\n# Specify url: url\\\\\\\\n\\\\\\\\n\\\\\\\\n# Package the request, send the request and catch the response: r\\\\\\\\n\\\\\\\\n\\\\\\\\n# Extracts the response as html: html_doc\\\\\\\\n\\\\\\\\n\\\\\\\\n# Create a BeautifulSoup object from the HTML: soup\\\\\\\\n\\\\\\\\n\\\\\\\\n# Prettify the BeautifulSoup object: pretty_soup\\\\\\\\n\\\\\\\\n\\\\\\\\n# Print the response\\\\\\\\nprint(pretty_soup)&quot;,&quot;^2W&quot;,&quot;&lt;ul&gt;\\\\\\\\n&lt;li&gt;Import the function &lt;code&gt;BeautifulSoup&lt;/code&gt; from the package &lt;code&gt;bs4&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;li&gt;Assign the URL of interest to the variable &lt;code&gt;url&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;li&gt;Package the request to the URL, send the request and catch the response with a single function &lt;code&gt;requests.get()&lt;/code&gt;, assigning the response to the variable &lt;code&gt;r&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;li&gt;Use the &lt;code&gt;text&lt;/code&gt; attribute of the object &lt;code&gt;r&lt;/code&gt; to return the HTML of the webpage as a string; store the result in a variable &lt;code&gt;html_doc&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;li&gt;Create a BeautifulSoup object &lt;code&gt;soup&lt;/code&gt; from the resulting HTML using the function &lt;code&gt;BeautifulSoup()&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;li&gt;Use the method &lt;code&gt;prettify()&lt;/code&gt; on &lt;code&gt;soup&lt;/code&gt; and assign the result to &lt;code&gt;pretty_soup&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;li&gt;Hit submit to print to prettified HTML to your shell!&lt;/li&gt;\\\\\\\\n&lt;/ul&gt;&quot;,&quot;^1&lt;&quot;,10,&quot;sct&quot;,&quot;# Test: Predefined code\\\\\\\\npredef_msg = \\\\\\\\&quot;You don&#39;t have to change any of the predefined code.\\\\\\\\&quot;\\\\\\\\nEx().has_import(\\\\\\\\n    \\\\\\\\&quot;requests\\\\\\\\&quot;,\\\\\\\\n    not_imported_msg=predef_msg\\\\\\\\n)\\\\\\\\n\\\\\\\\n# Test: import BeautifulSoup\\\\\\\\nimport_msg = \\\\\\\\&quot;Did you correctly import the required packages?\\\\\\\\&quot;\\\\\\\\nEx().has_import(\\\\\\\\n    \\\\\\\\&quot;bs4.BeautifulSoup\\\\\\\\&quot;,\\\\\\\\n    not_imported_msg=import_msg\\\\\\\\n)\\\\\\\\n\\\\\\\\n# Test: &#39;url&#39; variable\\\\\\\\nEx().check_object(\\\\\\\\&quot;url\\\\\\\\&quot;).has_equal_value()\\\\\\\\n\\\\\\\\n# Test: call to requests.get() and &#39;r&#39; variable\\\\\\\\nEx().check_function(\\\\\\\\&quot;requests.get\\\\\\\\&quot;).check_args(0).has_equal_value()\\\\\\\\nEx().check_object(\\\\\\\\&quot;r\\\\\\\\&quot;)\\\\\\\\n\\\\\\\\n\\\\\\\\n# Test: &#39;html_doc&#39; variable\\\\\\\\nEx().check_correct(\\\\\\\\n  check_object(\\\\\\\\&quot;html_doc\\\\\\\\&quot;).has_equal_value(),\\\\\\\\n  has_code(\\\\\\\\&quot;r.text\\\\\\\\&quot;, pattern = False, not_typed_msg=\\\\\\\\&quot;Have you used `r.text` to create `html_doc`?\\\\\\\\&quot;)\\\\\\\\n)\\\\\\\\n\\\\\\\\n# Test: call to BeautifulSoup() and &#39;soup&#39; variable\\\\\\\\nEx().check_correct(\\\\\\\\n  check_object(\\\\\\\\&quot;soup\\\\\\\\&quot;).has_equal_value(),\\\\\\\\n  check_function(\\\\\\\\&quot;bs4.BeautifulSoup\\\\\\\\&quot;).check_args(0).has_equal_value()\\\\\\\\n  )\\\\\\\\n\\\\\\\\n# Test: call to prettify() and &#39;pretty_soup&#39; variable\\\\\\\\nEx().check_correct(\\\\\\\\n  check_object(\\\\\\\\&quot;pretty_soup\\\\\\\\&quot;).has_equal_value(),\\\\\\\\n  check_function(\\\\\\\\&quot;soup.prettify\\\\\\\\&quot;)\\\\\\\\n  )\\\\\\\\n\\\\\\\\n# Test: Predefined code\\\\\\\\nEx().has_printout(0)\\\\\\\\n\\\\\\\\nsuccess_msg(\\\\\\\\&quot;Awesome!\\\\\\\\&quot;)\\\\\\\\n&quot;,&quot;^2X&quot;,&quot;&quot;,&quot;^2Y&quot;,&quot;# Import packages\\\\\\\\nimport requests\\\\\\\\nfrom bs4 import BeautifulSoup\\\\\\\\n\\\\\\\\n# Specify url: url\\\\\\\\nurl = &#39;https://www.python.org/~guido/&#39;\\\\\\\\n\\\\\\\\n# Package the request, send the request and catch the response: r\\\\\\\\nr = requests.get(url)\\\\\\\\n\\\\\\\\n# Extracts the response as html: html_doc\\\\\\\\nhtml_doc = r.text\\\\\\\\n\\\\\\\\n# Create a BeautifulSoup object from the HTML: soup\\\\\\\\nsoup = BeautifulSoup(html_doc)\\\\\\\\n\\\\\\\\n# Prettify the BeautifulSoup object: pretty_soup\\\\\\\\npretty_soup = soup.prettify()\\\\\\\\n\\\\\\\\n# Print the response\\\\\\\\nprint(pretty_soup)&quot;,&quot;^2Z&quot;,&quot;&lt;ul&gt;\\\\\\\\n&lt;li&gt;To import a function &lt;code&gt;y&lt;/code&gt; from a package &lt;code&gt;x&lt;/code&gt;, execute &lt;code&gt;from x import y&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;li&gt;Check the URL to make sure that you typed it in correctly.&lt;/li&gt;\\\\\\\\n&lt;li&gt;Pass the &lt;em&gt;url&lt;/em&gt; (the &lt;code&gt;url&lt;/code&gt; object you defined) as an argument to &lt;code&gt;requests.get()&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;li&gt;You can access the &lt;code&gt;text&lt;/code&gt; attribute of the object &lt;code&gt;r&lt;/code&gt; by executing &lt;code&gt;r.text&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;li&gt;Pass the extracted &lt;em&gt;HTML&lt;/em&gt; as an argument to &lt;code&gt;BeautifulSoup()&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;li&gt;To use the &lt;code&gt;prettify()&lt;/code&gt; method on the BeautifulSoup object &lt;code&gt;soup&lt;/code&gt;, execute &lt;code&gt;soup.prettify()&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;li&gt;You don&#39;t have to modify the code to print the prettified HTML.&lt;/li&gt;\\\\\\\\n&lt;/ul&gt;&quot;,&quot;^2[&quot;,null,&quot;xp&quot;,100,&quot;^30&quot;,[],&quot;^31&quot;,[],&quot;^32&quot;,&quot;&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null,&quot;^U&quot;,&quot;python&quot;,&quot;^3:&quot;,0.9907962772955521,&quot;^3;&quot;,42715],[&quot;^ &quot;,&quot;id&quot;,42716,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^2U&quot;,&quot;&lt;p&gt;As promised, in the following exercises, you&#39;ll learn the basics of extracting information from HTML soup. In this exercise, you&#39;ll figure out how to extract the text from the BDFL&#39;s webpage, along with printing the webpage&#39;s title.&lt;/p&gt;&quot;,&quot;^W&quot;,&quot;Turning a webpage into data using BeautifulSoup: getting the text&quot;,&quot;^2V&quot;,&quot;# Import packages\\\\\\\\nimport requests\\\\\\\\nfrom bs4 import BeautifulSoup\\\\\\\\n\\\\\\\\n# Specify url: url\\\\\\\\nurl = &#39;https://www.python.org/~guido/&#39;\\\\\\\\n\\\\\\\\n# Package the request, send the request and catch the response: r\\\\\\\\nr = requests.get(url)\\\\\\\\n\\\\\\\\n# Extract the response as html: html_doc\\\\\\\\nhtml_doc = r.text\\\\\\\\n\\\\\\\\n# Create a BeautifulSoup object from the HTML: soup\\\\\\\\n\\\\\\\\n\\\\\\\\n# Get the title of Guido&#39;s webpage: guido_title\\\\\\\\n\\\\\\\\n\\\\\\\\n# Print the title of Guido&#39;s webpage to the shell\\\\\\\\n\\\\\\\\n\\\\\\\\n# Get Guido&#39;s text: guido_text\\\\\\\\n\\\\\\\\n\\\\\\\\n# Print Guido&#39;s text to the shell\\\\\\\\nprint(guido_text)&quot;,&quot;^2W&quot;,&quot;&lt;ul&gt;\\\\\\\\n&lt;li&gt;In the sample code, the HTML response object &lt;code&gt;html_doc&lt;/code&gt; has already been created: your first task is to Soupify it using the function &lt;code&gt;BeautifulSoup()&lt;/code&gt; and to assign the resulting soup to the variable &lt;code&gt;soup&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;li&gt;Extract the title from the HTML soup &lt;code&gt;soup&lt;/code&gt; using the attribute &lt;code&gt;title&lt;/code&gt; and assign the result to &lt;code&gt;guido_title&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;li&gt;Print the title of Guido&#39;s webpage to the shell using the &lt;code&gt;print()&lt;/code&gt; function.&lt;/li&gt;\\\\\\\\n&lt;li&gt;Extract the text from the HTML soup &lt;code&gt;soup&lt;/code&gt; using the method &lt;code&gt;get_text()&lt;/code&gt; and assign to &lt;code&gt;guido_text&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;li&gt;Hit submit to print the text from Guido&#39;s webpage to the shell.&lt;/li&gt;\\\\\\\\n&lt;/ul&gt;&quot;,&quot;^1&lt;&quot;,11,&quot;sct&quot;,&quot;# Test: Predefined code\\\\\\\\npredef_msg = \\\\\\\\&quot;You don&#39;t have to change any of the predefined code.\\\\\\\\&quot;\\\\\\\\nEx().has_import(\\\\\\\\n    \\\\\\\\&quot;requests\\\\\\\\&quot;,\\\\\\\\n    not_imported_msg=predef_msg\\\\\\\\n)\\\\\\\\n\\\\\\\\n# Test: import BeautifulSoup\\\\\\\\nEx().has_import(\\\\\\\\n    \\\\\\\\&quot;bs4.BeautifulSoup\\\\\\\\&quot;,\\\\\\\\n    not_imported_msg=predef_msg\\\\\\\\n)\\\\\\\\n\\\\\\\\n# Test: &#39;url&#39; variable\\\\\\\\nEx().check_object(\\\\\\\\&quot;url\\\\\\\\&quot;).has_equal_value()\\\\\\\\n\\\\\\\\n# Test: call to requests.get() and &#39;r&#39; variable\\\\\\\\nEx().check_function(\\\\\\\\&quot;requests.get\\\\\\\\&quot;).check_args(0).has_equal_value()\\\\\\\\nEx().check_object(\\\\\\\\&quot;r\\\\\\\\&quot;)\\\\\\\\n\\\\\\\\n\\\\\\\\n# Test: &#39;html_doc&#39; variable\\\\\\\\nEx().check_correct(\\\\\\\\n  check_object(\\\\\\\\&quot;html_doc\\\\\\\\&quot;).has_equal_value(),\\\\\\\\n  has_code(\\\\\\\\&quot;r.text\\\\\\\\&quot;, pattern = False, not_typed_msg=\\\\\\\\&quot;Have you used `r.text` to create `html_doc`?\\\\\\\\&quot;)\\\\\\\\n)\\\\\\\\n\\\\\\\\n# Test: call to BeautifulSoup() and &#39;soup&#39; variable\\\\\\\\nEx().check_correct(\\\\\\\\n  check_object(\\\\\\\\&quot;soup\\\\\\\\&quot;).has_equal_value(),\\\\\\\\n  check_function(\\\\\\\\&quot;bs4.BeautifulSoup\\\\\\\\&quot;).check_args(0).has_equal_value()\\\\\\\\n  )\\\\\\\\n\\\\\\\\n# Test: &#39;guido_title&#39; variable\\\\\\\\nEx().check_correct(\\\\\\\\n  check_object(\\\\\\\\&quot;guido_title\\\\\\\\&quot;).has_equal_value(),\\\\\\\\n  has_code(\\\\\\\\&quot;soup.title\\\\\\\\&quot;, pattern = False, not_typed_msg=\\\\\\\\&quot;Have you used `soup.title` to create `guido_title`?\\\\\\\\&quot;)\\\\\\\\n)\\\\\\\\n\\\\\\\\n# Test: call to print()\\\\\\\\nEx().has_printout(0)\\\\\\\\n\\\\\\\\n# Test: call to soup.get_text() and &#39;guido_text&#39; variable\\\\\\\\nEx().check_correct(\\\\\\\\n  check_object(\\\\\\\\&quot;guido_text\\\\\\\\&quot;).has_equal_value(),\\\\\\\\n  check_function(\\\\\\\\&quot;soup.get_text\\\\\\\\&quot;)\\\\\\\\n  )\\\\\\\\n\\\\\\\\n# Test: Predefined code\\\\\\\\nEx().has_printout(1)\\\\\\\\n\\\\\\\\nsuccess_msg(\\\\\\\\&quot;Awesome!\\\\\\\\&quot;)\\\\\\\\n&quot;,&quot;^2X&quot;,&quot;&quot;,&quot;^2Y&quot;,&quot;# Import packages\\\\\\\\nimport requests\\\\\\\\nfrom bs4 import BeautifulSoup\\\\\\\\n\\\\\\\\n# Specify url: url\\\\\\\\nurl = &#39;https://www.python.org/~guido/&#39;\\\\\\\\n\\\\\\\\n# Package the request, send the request and catch the response: r\\\\\\\\nr = requests.get(url)\\\\\\\\n\\\\\\\\n# Extract the response as html: html_doc\\\\\\\\nhtml_doc = r.text\\\\\\\\n\\\\\\\\n# Create a BeautifulSoup object from the HTML: soup\\\\\\\\nsoup = BeautifulSoup(html_doc)\\\\\\\\n\\\\\\\\n# Get the title of Guido&#39;s webpage: guido_title\\\\\\\\nguido_title = soup.title\\\\\\\\n\\\\\\\\n# Print the title of Guido&#39;s webpage to the shell\\\\\\\\nprint(guido_title)\\\\\\\\n\\\\\\\\n# Get Guido&#39;s text: guido_text\\\\\\\\nguido_text = soup.get_text()\\\\\\\\n\\\\\\\\n# Print Guido&#39;s text to the shell\\\\\\\\nprint(guido_text)&quot;,&quot;^2Z&quot;,&quot;&lt;ul&gt;\\\\\\\\n&lt;li&gt;Pass the &lt;em&gt;HTML response object&lt;/em&gt; as an argument to &lt;code&gt;BeautifulSoup()&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;li&gt;You can access the &lt;code&gt;title&lt;/code&gt; attribute of the object &lt;code&gt;soup&lt;/code&gt; by executing &lt;code&gt;soup.title&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;li&gt;The object that contains the title of Guido&#39;s webpage is &lt;code&gt;guido_title&lt;/code&gt;; pass this as an argument to &lt;code&gt;print()&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;li&gt;Use the method &lt;code&gt;get_text()&lt;/code&gt; on the HTML soup &lt;code&gt;soup&lt;/code&gt; by executing &lt;code&gt;soup.get_text()&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;li&gt;You don&#39;t have to modify the code to print the text from Guido&#39;s webpage.&lt;/li&gt;\\\\\\\\n&lt;/ul&gt;&quot;,&quot;^2[&quot;,null,&quot;xp&quot;,100,&quot;^30&quot;,[],&quot;^31&quot;,[],&quot;^32&quot;,&quot;&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null,&quot;^U&quot;,&quot;python&quot;,&quot;^3:&quot;,0.9359883737326375,&quot;^3;&quot;,42716],[&quot;^ &quot;,&quot;id&quot;,42717,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^2U&quot;,&quot;&lt;p&gt;In this exercise, you&#39;ll figure out how to extract the URLs of the hyperlinks from the BDFL&#39;s webpage. In the process, you&#39;ll become close friends with the soup method &lt;code&gt;find_all()&lt;/code&gt;.&lt;/p&gt;&quot;,&quot;^W&quot;,&quot;Turning a webpage into data using BeautifulSoup: getting the hyperlinks&quot;,&quot;^2V&quot;,&quot;# Import packages\\\\\\\\nimport requests\\\\\\\\nfrom bs4 import BeautifulSoup\\\\\\\\n\\\\\\\\n# Specify url\\\\\\\\nurl = &#39;https://www.python.org/~guido/&#39;\\\\\\\\n\\\\\\\\n# Package the request, send the request and catch the response: r\\\\\\\\nr = requests.get(url)\\\\\\\\n\\\\\\\\n# Extracts the response as html: html_doc\\\\\\\\nhtml_doc = r.text\\\\\\\\n\\\\\\\\n# create a BeautifulSoup object from the HTML: soup\\\\\\\\nsoup = BeautifulSoup(html_doc)\\\\\\\\n\\\\\\\\n# Print the title of Guido&#39;s webpage\\\\\\\\nprint(soup.title)\\\\\\\\n\\\\\\\\n# Find all &#39;a&#39; tags (which define hyperlinks): a_tags\\\\\\\\n\\\\\\\\n\\\\\\\\n# Print the URLs to the shell\\\\\\\\nfor ____ in ____:\\\\\\\\n    ____&quot;,&quot;^2W&quot;,&quot;&lt;ul&gt;\\\\\\\\n&lt;li&gt;Use the method &lt;code&gt;find_all()&lt;/code&gt; to find all hyperlinks in &lt;code&gt;soup&lt;/code&gt;, remembering that hyperlinks are defined by the HTML tag &lt;code&gt;&amp;lt;a&amp;gt;&lt;/code&gt; but passed to &lt;code&gt;find_all()&lt;/code&gt; without angle brackets; store the result in the variable &lt;code&gt;a_tags&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;li&gt;The variable &lt;code&gt;a_tags&lt;/code&gt; is a results set: your job now is to enumerate over it, using a &lt;code&gt;for&lt;/code&gt; loop and to print the actual URLs of the hyperlinks; to do this, for every element &lt;code&gt;link&lt;/code&gt; in &lt;code&gt;a_tags&lt;/code&gt;, you want to &lt;code&gt;print()&lt;/code&gt; &lt;code&gt;link.get(&#39;href&#39;)&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;/ul&gt;&quot;,&quot;^1&lt;&quot;,12,&quot;sct&quot;,&quot;predef_msg = \\\\\\\\&quot;You don&#39;t have to change any of the predefined code.\\\\\\\\&quot;\\\\\\\\nEx().has_import(\\\\\\\\&quot;requests\\\\\\\\&quot;)\\\\\\\\nEx().has_import(\\\\\\\\&quot;bs4.BeautifulSoup\\\\\\\\&quot;)\\\\\\\\nEx().check_object(\\\\\\\\&quot;url\\\\\\\\&quot;).has_equal_value(incorrect_msg = predef_msg)\\\\\\\\nEx().check_function(\\\\\\\\&quot;requests.get\\\\\\\\&quot;).check_args(0).has_equal_ast()\\\\\\\\nEx().check_object(\\\\\\\\&quot;html_doc\\\\\\\\&quot;).has_equal_value(incorrect_msg = predef_msg)\\\\\\\\nEx().check_object(\\\\\\\\&quot;soup\\\\\\\\&quot;).has_equal_value(incorrect_msg = predef_msg)\\\\\\\\nEx().has_printout(0)\\\\\\\\n\\\\\\\\nEx().check_correct(\\\\\\\\n    check_object(\\\\\\\\&quot;a_tags\\\\\\\\&quot;),\\\\\\\\n    check_function(\\\\\\\\&quot;soup.find_all\\\\\\\\&quot;).check_args(0).has_equal_value()\\\\\\\\n)\\\\\\\\nEx().check_for_loop().multi(\\\\\\\\n        check_iter().has_equal_value(incorrect_msg = \\\\\\\\&quot;You have to iterate over `a_tags`\\\\\\\\&quot;),\\\\\\\\n        check_body().set_context(&#39;&lt;a href=\\\\\\\\&quot;pics.html\\\\\\\\&quot;&gt;&lt;img border=\\\\\\\\&quot;0\\\\\\\\&quot; src=\\\\\\\\&quot;images/IMG_2192.jpg\\\\\\\\&quot;/&gt;&lt;/a&gt;&#39;).check_function(\\\\\\\\&quot;print\\\\\\\\&quot;).check_args(0).check_function(\\\\\\\\&quot;link.get\\\\\\\\&quot;).check_args(0).has_equal_value()\\\\\\\\n    )\\\\\\\\n\\\\\\\\nsuccess_msg(\\\\\\\\&quot;Awesome!\\\\\\\\&quot;)&quot;,&quot;^2X&quot;,&quot;&quot;,&quot;^2Y&quot;,&quot;# Import packages\\\\\\\\nimport requests\\\\\\\\nfrom bs4 import BeautifulSoup\\\\\\\\n\\\\\\\\n# Specify url\\\\\\\\nurl = &#39;https://www.python.org/~guido/&#39;\\\\\\\\n\\\\\\\\n# Package the request, send the request and catch the response: r\\\\\\\\nr = requests.get(url)\\\\\\\\n\\\\\\\\n# Extracts the response as html: html_doc\\\\\\\\nhtml_doc = r.text\\\\\\\\n\\\\\\\\n# create a BeautifulSoup object from the HTML: soup\\\\\\\\nsoup = BeautifulSoup(html_doc)\\\\\\\\n\\\\\\\\n# Print the title of Guido&#39;s webpage\\\\\\\\nprint(soup.title)\\\\\\\\n\\\\\\\\n# Find all &#39;a&#39; tags (which define hyperlinks): a_tags\\\\\\\\na_tags = soup.find_all(&#39;a&#39;)\\\\\\\\n\\\\\\\\n# Print the URLs to the shell\\\\\\\\nfor link in a_tags:\\\\\\\\n    print(link.get(&#39;href&#39;))&quot;,&quot;^2Z&quot;,&quot;&lt;ul&gt;\\\\\\\\n&lt;li&gt;Pass the &lt;em&gt;HTML tag&lt;/em&gt; to find (without the angle brackets &lt;code&gt;&amp;lt;&amp;gt;&lt;/code&gt;) as a string argument to &lt;code&gt;find_all()&lt;/code&gt;.&lt;/li&gt;\\\\\\\\n&lt;li&gt;Recall that the &lt;code&gt;for&lt;/code&gt; loop recipe is: &lt;code&gt;for&lt;/code&gt; &lt;em&gt;loop variable&lt;/em&gt; &lt;code&gt;in&lt;/code&gt; &lt;em&gt;results set&lt;/em&gt;&lt;code&gt;:&lt;/code&gt;. Don&#39;t forget to pass &lt;code&gt;link.get(&#39;href&#39;)&lt;/code&gt; as an argument to &lt;code&gt;print()&lt;/code&gt; inside the &lt;code&gt;for&lt;/code&gt; loop body.&lt;/li&gt;\\\\\\\\n&lt;/ul&gt;&quot;,&quot;^2[&quot;,null,&quot;xp&quot;,100,&quot;^30&quot;,[],&quot;^31&quot;,[],&quot;^32&quot;,&quot;&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null,&quot;^U&quot;,&quot;python&quot;,&quot;^3:&quot;,0.5560594333253173,&quot;^3;&quot;,42717]]]]],&quot;^H&quot;,[&quot;^0&quot;,[&quot;^ &quot;,&quot;n&quot;,&quot;PreFetchedRequestRecord&quot;,&quot;v&quot;,[&quot;^ &quot;,&quot;^2&quot;,&quot;NOT_FETCHED&quot;,&quot;^1:&quot;,null]]],&quot;sharedImage&quot;,[&quot;^0&quot;,[&quot;^ &quot;,&quot;n&quot;,&quot;PreFetchedRequestRecord&quot;,&quot;v&quot;,[&quot;^ &quot;,&quot;^2&quot;,&quot;NOT_FETCHED&quot;,&quot;^1:&quot;,null]]],&quot;^Q&quot;,[&quot;^0&quot;,[&quot;^ &quot;,&quot;n&quot;,&quot;PreFetchedRequestRecord&quot;,&quot;v&quot;,[&quot;^ &quot;,&quot;^2&quot;,&quot;SUCCESS&quot;,&quot;^1:&quot;,[&quot;^ &quot;,&quot;^R&quot;,&quot;template&quot;,&quot;id&quot;,3046,&quot;^S&quot;,&quot;2022-12-01T15:10:45.124Z&quot;,&quot;^T&quot;,&quot;2022-12-05T06:31:46.338Z&quot;,&quot;key&quot;,&quot;course-dataset-intermediate-importing-data-in-python&quot;,&quot;^U&quot;,&quot;Python&quot;,&quot;^V&quot;,null,&quot;^W&quot;,&quot;Intermediate Importing Data in Python&quot;,&quot;^X&quot;,&quot;Explore the datasets from the course, Intermediate Importing Data in Python.&quot;,&quot;^Y&quot;,false,&quot;^Z&quot;,&quot;d9783ad9a9e677a4f583a5bd9ed5b9d5987a2859&quot;,&quot;^[&quot;,null,&quot;^10&quot;,null,&quot;^11&quot;,null,&quot;^12&quot;,&quot;ade0176d-8e1d-436c-b7c1-44c3f4f1df8f&quot;,&quot;^13&quot;,[&quot;course-dataset&quot;],&quot;^14&quot;,1606,&quot;^15&quot;,[],&quot;^16&quot;,null]]]],&quot;courseImages&quot;,[&quot;^0&quot;,[&quot;^ &quot;,&quot;n&quot;,&quot;PreFetchedRequestRecord&quot;,&quot;v&quot;,[&quot;^ &quot;,&quot;^2&quot;,&quot;SUCCESS&quot;,&quot;^1:&quot;,[&quot;^ &quot;,&quot;imageTag&quot;,&quot;course-1606-master:cb59605c00ed73a970165be3564ff450-20240926095400969&quot;,&quot;^B&quot;,&quot;singleImage&quot;]]]],&quot;categoryPages&quot;,[&quot;^0&quot;,[&quot;^ &quot;,&quot;n&quot;,&quot;PreFetchedRequestRecord&quot;,&quot;v&quot;,[&quot;^ &quot;,&quot;^2&quot;,&quot;SUCCESS&quot;,&quot;^1:&quot;,[[&quot;^ &quot;,&quot;^1=&quot;,&quot;power-bi&quot;,&quot;facet&quot;,[&quot;^ &quot;,&quot;technology_array&quot;,[&quot;Power BI&quot;]]],[&quot;^ &quot;,&quot;^1=&quot;,&quot;r&quot;,&quot;^3@&quot;,[&quot;^ &quot;,&quot;^3A&quot;,[&quot;R&quot;]]],[&quot;^ &quot;,&quot;^1=&quot;,&quot;sql&quot;,&quot;^3@&quot;,[&quot;^ &quot;,&quot;^3A&quot;,[&quot;SQL&quot;]]],[&quot;^ &quot;,&quot;^1=&quot;,&quot;tableau&quot;,&quot;^3@&quot;,[&quot;^ &quot;,&quot;^3A&quot;,[&quot;Tableau&quot;]]],[&quot;^ &quot;,&quot;^1=&quot;,&quot;azure&quot;,&quot;^3@&quot;,[&quot;^ &quot;,&quot;^3A&quot;,[&quot;Azure&quot;]]],[&quot;^ &quot;,&quot;^1=&quot;,&quot;probability-and-statistics&quot;,&quot;^3@&quot;,[&quot;^ &quot;,&quot;topic_array&quot;,[&quot;Probability &amp; Statistics&quot;]]],[&quot;^ &quot;,&quot;^1=&quot;,&quot;artificial-intelligence&quot;,&quot;^3@&quot;,[&quot;^ &quot;,&quot;^3B&quot;,[&quot;Artificial Intelligence&quot;]]],[&quot;^ &quot;,&quot;^1=&quot;,&quot;machine-learning&quot;,&quot;^3@&quot;,[&quot;^ &quot;,&quot;^3B&quot;,[&quot;Machine Learning&quot;]]],[&quot;^ &quot;,&quot;^1=&quot;,&quot;data-engineering&quot;,&quot;^3@&quot;,[&quot;^ &quot;,&quot;^3B&quot;,[&quot;Data Engineering&quot;]]],[&quot;^ &quot;,&quot;^1=&quot;,&quot;data-visualization&quot;,&quot;^3@&quot;,[&quot;^ &quot;,&quot;^3B&quot;,[&quot;Data Visualization&quot;]]],[&quot;^ &quot;,&quot;^1=&quot;,&quot;data-analysis&quot;,&quot;^3@&quot;,[&quot;^ &quot;,&quot;^3B&quot;,[&quot;Reporting&quot;,&quot;Data Manipulation&quot;,&quot;Data Preparation&quot;,&quot;Exploratory Data Analysis&quot;,&quot;Data Visualization&quot;]]],[&quot;^ &quot;,&quot;^1=&quot;,&quot;python&quot;,&quot;^3@&quot;,[&quot;^ &quot;,&quot;^3A&quot;,[&quot;Python&quot;]]]]]]],&quot;translatedCourses&quot;,[&quot;^0&quot;,[&quot;^ &quot;,&quot;n&quot;,&quot;PreFetchedRequestRecord&quot;,&quot;v&quot;,[&quot;^ &quot;,&quot;^2&quot;,&quot;SUCCESS&quot;,&quot;^1:&quot;,[&quot;^ &quot;,&quot;58&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;672&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;735&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;799&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;1477&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;1531&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;1532&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;1606&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;1607&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;1796&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;1975&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;2072&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;2906&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;3423&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;3629&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;4205&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;4267&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;4452&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;4914&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;5065&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;6079&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;6199&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;6280&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;6576&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;6612&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;6919&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;7355&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;13023&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;13185&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;13203&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;13274&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;13367&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;13369&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;13371&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;13690&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;13698&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;13706&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;14519&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;14739&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;14989&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;15108&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;15192&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;15424&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;15876&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;16459&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;16470&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;16921&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;16937&quot;,[&quot;es&quot;],&quot;17118&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;17602&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;19197&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;19854&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;19930&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;20692&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;20822&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;20891&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;21394&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;21544&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;22066&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;22639&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;22723&quot;,[&quot;pt&quot;,&quot;es&quot;,&quot;de&quot;],&quot;22812&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;23080&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;23983&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;24098&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;24252&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;24364&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;24372&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;],&quot;24388&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;],&quot;24558&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;24852&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;24865&quot;,[&quot;pt&quot;],&quot;24878&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;24896&quot;,[&quot;de&quot;,&quot;pt&quot;],&quot;24907&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;25412&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;25472&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;25473&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;25475&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;25711&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;25814&quot;,[&quot;pt&quot;,&quot;es&quot;,&quot;de&quot;],&quot;25923&quot;,[&quot;de&quot;],&quot;25942&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;26827&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;27336&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;27391&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;28169&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;28173&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;28303&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;28314&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;28318&quot;,[&quot;es&quot;,&quot;de&quot;,&quot;pt&quot;],&quot;28765&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;28767&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;28826&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;28921&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;28944&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;28946&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;29081&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;29092&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;29094&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;29140&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;29143&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;29157&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;29302&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;29303&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;29304&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;29355&quot;,[&quot;es&quot;,&quot;de&quot;,&quot;pt&quot;],&quot;29453&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;29478&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;],&quot;29490&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;29533&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;29573&quot;,[&quot;es&quot;,&quot;de&quot;,&quot;pt&quot;],&quot;29712&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;29744&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;29830&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;29835&quot;,[&quot;es&quot;],&quot;29847&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;29902&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;29943&quot;,[&quot;pt&quot;,&quot;de&quot;,&quot;es&quot;],&quot;29968&quot;,[&quot;pt&quot;,&quot;es&quot;],&quot;30523&quot;,[&quot;pt&quot;,&quot;es&quot;],&quot;30563&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;],&quot;30656&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;30891&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;31224&quot;,[&quot;pt&quot;,&quot;es&quot;],&quot;31361&quot;,[&quot;pt&quot;,&quot;es&quot;],&quot;31794&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;31939&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;31950&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;32086&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;32245&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;32271&quot;,[&quot;pt&quot;,&quot;es&quot;],&quot;32326&quot;,[&quot;pt&quot;,&quot;es&quot;],&quot;32428&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;32439&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;32476&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;32509&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;32613&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;32623&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;32740&quot;,[&quot;es&quot;,&quot;de&quot;,&quot;pt&quot;,&quot;fr&quot;],&quot;32932&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;33286&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;33409&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;33412&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;],&quot;33509&quot;,[&quot;es&quot;],&quot;33554&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;33674&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;33727&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;33848&quot;,[&quot;pt&quot;,&quot;es&quot;],&quot;33893&quot;,[&quot;pt&quot;,&quot;es&quot;],&quot;33937&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;34425&quot;,[&quot;pt&quot;,&quot;es&quot;],&quot;34598&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;34614&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;34777&quot;,[&quot;pt&quot;,&quot;es&quot;],&quot;34857&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;34919&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;34961&quot;,[&quot;pt&quot;,&quot;es&quot;],&quot;35064&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;35486&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;35597&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;35684&quot;,[&quot;pt&quot;,&quot;es&quot;,&quot;de&quot;],&quot;35704&quot;,[&quot;de&quot;],&quot;35927&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;35934&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;36079&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;36157&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;36160&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;36164&quot;,[&quot;pt&quot;,&quot;es&quot;],&quot;36398&quot;,[&quot;pt&quot;,&quot;es&quot;,&quot;de&quot;],&quot;36399&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;37483&quot;,[&quot;pt&quot;,&quot;es&quot;,&quot;de&quot;]]]]]]]],&quot;settings&quot;,[&quot;^?&quot;,[&quot;uiTheme&quot;,&quot;DARK&quot;,&quot;feedbackRatingStatus&quot;,&quot;NONE&quot;,&quot;mobileView&quot;,&quot;CONTEXT&quot;]],&quot;streakInfo&quot;,[&quot;^ &quot;,&quot;^B&quot;,&quot;StreakUnknown&quot;],&quot;systemStatus&quot;,[&quot;^?&quot;,[&quot;indicator&quot;,&quot;none&quot;,&quot;description&quot;,&quot;No status has been fetched from the Status Page.&quot;]],&quot;user&quot;,[&quot;^?&quot;,[&quot;status&quot;,&quot;not_initiate&quot;,&quot;settings&quot;,[&quot;^?&quot;,[&quot;aiFlags&quot;,[&quot;^?&quot;,[&quot;aiSolutionExplanationEnabled&quot;,false,&quot;aiErrorExplanationEnabled&quot;,false]]]]]],&quot;images&quot;,[&quot;^ &quot;,&quot;^3&gt;&quot;,&quot;course-1606-master:cb59605c00ed73a970165be3564ff450-20240926095400969&quot;,&quot;^B&quot;,&quot;singleImage&quot;]]]]\";</script><script>window.PRELOADED_LANGUAGE = \"en\";</script><div id=\"root\"><div class=\"theme progress-indicator--visible\"><style data-emotion=\"css 19enzrs\">.css-19enzrs{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;background-color:#F7F7FC;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;height:50px;padding-left:10px;padding-right:10px;position:relative;z-index:15;}</style><header data-cy=\"alpa-navbar\" class=\"css-19enzrs\"><style data-emotion=\"css vpr568\">.css-vpr568{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex:1;-ms-flex:1;flex:1;-webkit-box-pack:start;-ms-flex-pack:start;-webkit-justify-content:flex-start;justify-content:flex-start;}</style><div class=\"css-vpr568\"><style data-emotion=\"css 19lbh5u\">.css-19lbh5u{padding-left:6px;padding-right:6px;}</style><style data-emotion=\"css 12o4242\">.css-12o4242{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;border-color:transparent;border-radius:4px;border-style:solid;border-width:2px;cursor:pointer;display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;font-family:Studio-Feixen-Sans,Arial,sans-serif;font-weight:800;-webkit-box-pack:center;-ms-flex-pack:center;-webkit-justify-content:center;justify-content:center;line-height:1;margin:0;outline:0;padding:0;position:relative;-webkit-text-decoration:none;text-decoration:none;-webkit-transition:background-color 125ms ease-out;transition:background-color 125ms ease-out;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;vertical-align:middle;background-color:transparent;color:var(--wf-text--link, #0065D1);font-size:var(--wf-button--medium, 14px);height:36px;min-width:36px;width:auto;padding-left:16px;padding-right:16px;padding-left:6px;padding-right:6px;}.css-12o4242::before{border-radius:2px;content:\"\";display:block;height:100%;inset:0;position:absolute;width:100%;z-index:0;}.css-12o4242:active{background-color:transparent;}.css-12o4242:disabled{cursor:default;opacity:0.4;pointer-events:none;}.css-12o4242:hover{border-color:var(--wf-bg--hover, rgba(48, 57, 105, 0.06));}.css-12o4242:hover::before{background-color:var(--wf-bg--hover, rgba(48, 57, 105, 0.06));}.css-12o4242 >*{z-index:1;}</style><a class=\"alpa-navbar-logo css-12o4242\" data-cy=\"header-logo\" data-testid=\"alpa-navbar-logo\" data-trackid=\"alpa-navbar-logo\" href=\"https://www.datacamp.com\" aria-label=\"landing\"><style data-emotion=\"css 61bni1\">.css-61bni1{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;height:100%;gap:8px;}</style><span class=\"css-61bni1\"><svg viewbox=\"0 0 27 35\" xml:space=\"preserve\" xmlns=\"http://www.w3.org/2000/svg\" height=\"28\" class=\"css-0\"><path clip-rule=\"evenodd\" d=\"M11.699 8.514v8.333L2.858 21.89V3.44l8.841 5.074zm2.861 17.507v-7.51l11.84-6.757-2.88-1.65-8.96 5.112V7.68a1.442 1.442 0 0 0-.718-1.242L3.056.256C3.027.238 2.998.224 2.97.21A2.064 2.064 0 0 0 0 2.07v21.184a2.067 2.067 0 0 0 2.971 1.865l.082-.042 8.64-4.933v6.72c.002.513.277.987.722 1.243L23.502 34.4l2.88-1.651-11.822-6.728z\" fill=\"var(--wf-brand--text, #05192D)\" fill-rule=\"evenodd\"/></svg></span></a><nav aria-label=\"Breadcrumb\" data-testid=\"alpa-navbar-breadcrumbs\"><style data-emotion=\"css 1goqhco\">.css-1goqhco{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;padding:0;}.css-1goqhco div[aria-hidden=\\'true\\']{color:#5D6A77;display:none;padding:0 4px;}.css-1goqhco div[aria-hidden=\\'true\\']:first-of-type{display:inline-block;}@media screen and (min-width: 820px){.css-1goqhco div[aria-hidden=\\'true\\']{display:inline-block;}}.css-1goqhco li{display:none;-webkit-box-flex:1;-webkit-flex-grow:1;-ms-flex-positive:1;flex-grow:1;-webkit-flex-shrink:1;-ms-flex-negative:1;flex-shrink:1;list-style:none;}@media screen and (min-width: 820px){.css-1goqhco li{display:inline-block;}}.css-1goqhco li:first-of-type{display:inline-block;}.css-1goqhco li:last-of-type{display:inline-block;}.css-1goqhco li a{color:#05192D;font-weight:normal;height:30px;line-height:21px;min-height:unset;padding:2px;}.css-1goqhco li a span{display:inline-block;max-width:20vw;overflow:hidden;text-overflow:ellipsis;white-space:nowrap;}.css-1goqhco li:last-of-type a{font-weight:bold;}</style><ol itemscope itemtype=\"http://schema.org/BreadcrumbList\" class=\"css-1goqhco\"><li itemprop=\"itemListElement\" itemscope itemtype=\"https://schema.org/ListItem\"><style data-emotion=\"css qwtpyn\">.css-qwtpyn{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;border-color:transparent;border-radius:4px;border-style:solid;border-width:2px;cursor:pointer;display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;font-family:Studio-Feixen-Sans,Arial,sans-serif;font-weight:800;-webkit-box-pack:center;-ms-flex-pack:center;-webkit-justify-content:center;justify-content:center;line-height:1;margin:0;outline:0;padding:0;position:relative;-webkit-text-decoration:none;text-decoration:none;-webkit-transition:background-color 125ms ease-out;transition:background-color 125ms ease-out;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;vertical-align:middle;background-color:transparent;color:var(--wf-text--link, #0065D1);font-size:var(--wf-button--medium, 14px);height:36px;min-width:36px;width:auto;padding-left:16px;padding-right:16px;}.css-qwtpyn::before{border-radius:2px;content:\"\";display:block;height:100%;inset:0;position:absolute;width:100%;z-index:0;}.css-qwtpyn:active{background-color:transparent;}.css-qwtpyn:disabled{cursor:default;opacity:0.4;pointer-events:none;}.css-qwtpyn:hover{border-color:var(--wf-bg--hover, rgba(48, 57, 105, 0.06));}.css-qwtpyn:hover::before{background-color:var(--wf-bg--hover, rgba(48, 57, 105, 0.06));}.css-qwtpyn >*{z-index:1;}</style><a data-trackid=\"alpa-navbar-breadcrumb-learn\" href=\"https://www.datacamp.com\" itemprop=\"item\" aria-label=\"Learn\" class=\"css-qwtpyn\"><span class=\"css-61bni1\"><span itemprop=\"name\">Learn</span></span></a><meta content=\"0\" itemprop=\"position\"></li><div aria-hidden=\"true\">/</div><li itemprop=\"itemListElement\" itemscope itemtype=\"https://schema.org/ListItem\"><a data-trackid=\"alpa-navbar-breadcrumb-courses\" href=\"https://www.datacamp.com/category/python\" itemprop=\"item\" aria-label=\"Courses\" class=\"css-qwtpyn\"><span class=\"css-61bni1\"><span itemprop=\"name\">Courses</span></span></a><meta content=\"1\" itemprop=\"position\"></li><div aria-hidden=\"true\">/</div><li itemprop=\"itemListElement\" itemscope itemtype=\"https://schema.org/ListItem\"><a data-trackid=\"alpa-navbar-breadcrumb-course\" href=\"https://www.datacamp.com/courses/intermediate-importing-data-in-python\" itemprop=\"item\" aria-label=\"Intermediate Importing Data in Python\" class=\"css-qwtpyn\"><span class=\"css-61bni1\"><span itemprop=\"name\">Intermediate Importing Data in Python</span></span></a><meta content=\"2\" itemprop=\"position\"></li></ol></nav></div><style data-emotion=\"css 1jov1vc\">.css-1jov1vc{-webkit-box-pack:initial;-ms-flex-pack:initial;-webkit-justify-content:initial;justify-content:initial;}</style><div class=\"css-1jov1vc\"></div><style data-emotion=\"css r4fpqc\">.css-r4fpqc{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex:1;-ms-flex:1;flex:1;-webkit-box-pack:end;-ms-flex-pack:end;-webkit-justify-content:flex-end;justify-content:flex-end;}</style><nav class=\"css-r4fpqc\"><style data-emotion=\"css 79elbk\">.css-79elbk{position:relative;}</style><div class=\"css-79elbk\"><style data-emotion=\"css 10ganm4\">.css-10ganm4{border:none;}</style><style data-emotion=\"css 178iibo\">.css-178iibo{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;border-color:transparent;border-radius:4px;border-style:solid;border-width:2px;cursor:pointer;display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;font-family:Studio-Feixen-Sans,Arial,sans-serif;font-weight:800;-webkit-box-pack:center;-ms-flex-pack:center;-webkit-justify-content:center;justify-content:center;line-height:1;margin:0;outline:0;padding:0;position:relative;-webkit-text-decoration:none;text-decoration:none;-webkit-transition:background-color 125ms ease-out;transition:background-color 125ms ease-out;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;vertical-align:middle;background-color:transparent;color:var(--wf-text--main, #05192D);font-size:var(--wf-button--medium, 14px);height:36px;min-width:36px;width:auto;padding-left:16px;padding-right:16px;border-color:var(--wf-border-color--interactive, rgba(48, 57, 105, 0.6));border:none;}.css-178iibo::before{border-radius:2px;content:\"\";display:block;height:100%;inset:0;position:absolute;width:100%;z-index:0;}.css-178iibo::before{border-radius:2px;margin:0;}.css-178iibo:active{background-color:transparent;}.css-178iibo:disabled{cursor:default;opacity:0.4;pointer-events:none;}.css-178iibo:hover::before{background-color:var(--wf-bg--hover, rgba(48, 57, 105, 0.06));}.css-178iibo >*{z-index:1;}</style><button class=\"css-178iibo\" aria-label=\"course-menu\" type=\"button\"><span class=\"css-61bni1\"><svg aria-hidden=\"true\" height=\"16\" width=\"16\" viewbox=\"0 0 18 18\"><path fill=\"currentColor\" d=\"M2 11a2 2 0 1 1 0-4 2 2 0 0 1 0 4Zm7 0a2 2 0 1 1 0-4 2 2 0 0 1 0 4Zm7 0a2 2 0 1 1 0-4 2 2 0 0 1 0 4Z\"/></svg></span></button><style data-emotion=\"css h7pn2b\">.css-h7pn2b{position:absolute;top:32px;right:0;padding:8px;padding-left:0;padding-right:0;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;max-width:90dvw;z-index:5000;width:0;height:0;overflow:hidden;}.css-h7pn2b button span{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:start;-ms-flex-pack:start;-webkit-justify-content:flex-start;justify-content:flex-start;font-weight:400;width:100%;}</style><style data-emotion=\"css 1ydqvfl\">.css-1ydqvfl{background-color:var(--wf-bg--contrast, #FFFFFF);border-color:var(--wf-border-color--main, rgba(48, 57, 105, 0.15));border-radius:4px;border-style:solid;border-width:1px;display:block;outline:0;padding:16px;position:relative;-webkit-text-decoration:none;text-decoration:none;-webkit-transition:box-shadow 600ms cubic-bezier(0.1, 0.8, 0.2, 1),-webkit-transform 600ms cubic-bezier(0.1, 0.8, 0.2, 1);transition:box-shadow 600ms cubic-bezier(0.1, 0.8, 0.2, 1),transform 600ms cubic-bezier(0.1, 0.8, 0.2, 1);position:absolute;top:32px;right:0;padding:8px;padding-left:0;padding-right:0;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;max-width:90dvw;z-index:5000;width:0;height:0;overflow:hidden;}.css-1ydqvfl:where(a, button){cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;}.css-1ydqvfl button span{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:start;-ms-flex-pack:start;-webkit-justify-content:flex-start;justify-content:flex-start;font-weight:400;width:100%;}</style><section aria-hidden=\"true\" class=\"css-1ydqvfl\"><nav><style data-emotion=\"css 15c08fe\">.css-15c08fe{color:#05192D;border:none;width:100%;}@media screen and (min-width: 820px){.css-15c08fe{border-radius:0;}.css-15c08fe:after{border-radius:0;}}</style><style data-emotion=\"css btjij\">.css-btjij{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;border-color:transparent;border-radius:4px;border-style:solid;border-width:2px;cursor:pointer;display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;font-family:Studio-Feixen-Sans,Arial,sans-serif;font-weight:800;-webkit-box-pack:center;-ms-flex-pack:center;-webkit-justify-content:center;justify-content:center;line-height:1;margin:0;outline:0;padding:0;position:relative;-webkit-text-decoration:none;text-decoration:none;-webkit-transition:background-color 125ms ease-out;transition:background-color 125ms ease-out;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;vertical-align:middle;background-color:transparent;color:var(--wf-text--main, #05192D);font-size:var(--wf-button--medium, 14px);height:36px;min-width:36px;width:auto;padding-left:16px;padding-right:16px;border-color:var(--wf-border-color--interactive, rgba(48, 57, 105, 0.6));color:#05192D;border:none;width:100%;}.css-btjij::before{border-radius:2px;content:\"\";display:block;height:100%;inset:0;position:absolute;width:100%;z-index:0;}.css-btjij::before{border-radius:2px;margin:0;}.css-btjij:active{background-color:transparent;}.css-btjij:disabled{cursor:default;opacity:0.4;pointer-events:none;}.css-btjij:hover::before{background-color:var(--wf-bg--hover, rgba(48, 57, 105, 0.06));}.css-btjij >*{z-index:1;}@media screen and (min-width: 820px){.css-btjij{border-radius:0;}.css-btjij:after{border-radius:0;}}</style><button data-cy=\"header-outline\" class=\"css-btjij\" type=\"button\"><span class=\"css-61bni1\"><svg aria-hidden=\"true\" height=\"16\" width=\"16\" viewbox=\"0 0 18 18\" style=\"flex-shrink:0\"><path fill=\"currentColor\" d=\"M4 6a1 1 0 1 1 0-2h10a1 1 0 0 1 0 2H4Zm0 4a1 1 0 1 1 0-2h10a1 1 0 0 1 0 2H4Zm0 4a1 1 0 0 1 0-2h10a1 1 0 0 1 0 2H4Z\"/></svg>Course Outline</span></button><style data-emotion=\"css ntp9k4\">.css-ntp9k4{height:0;overflow:hidden;position:absolute;top:-9000px;left:-9000px;}</style><div aria-hidden=\"true\" class=\"css-ntp9k4\"><ul data-cy=\"outline-container\"><style data-emotion=\"css p1ihnf\">.css-p1ihnf{border:1px solid rgba(48, 57, 105, 0.15);border-radius:4px;margin-bottom:16px;overflow:hidden;}</style><li data-cy=\"outline-chapter\" class=\"css-p1ihnf\"><style data-emotion=\"css 15hicbc\">.css-15hicbc{padding:16px;padding-bottom:0;}</style><div class=\"css-15hicbc\"><style data-emotion=\"css k008qs\">.css-k008qs{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}</style><header class=\"css-k008qs\"><style data-emotion=\"css mwfol9\">.css-mwfol9{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-flex:1;-webkit-flex-grow:1;-ms-flex-positive:1;flex-grow:1;gap:8px;}</style><div class=\"css-mwfol9\"><style data-emotion=\"css ty7r4z\">.css-ty7r4z{font-weight:800;}</style><style data-emotion=\"css kdtjtf\">.css-kdtjtf{-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;font-family:Studio-Feixen-Sans,Arial,sans-serif;overflow:hidden;background:var(--wf-navy--main, #05192D);border-radius:24px;color:var(--wf-navy--text-on-color, #FFFFFF);font-size:12px;height:24px;line-height:24px;width:24px;font-weight:800;}</style><div class=\"css-kdtjtf\"><style data-emotion=\"css 3xjkdl\">.css-3xjkdl{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;font-variant-numeric:tabular-nums;height:100%;-webkit-box-pack:center;-ms-flex-pack:center;-webkit-justify-content:center;justify-content:center;width:100%;}.css-3xjkdl>*{margin:auto 0;}.css-3xjkdl>:not(svg){min-width:100%;}.css-3xjkdl>*{min-height:14px;}.css-3xjkdl>svg{width:14px;}</style><div class=\"css-3xjkdl\">1</div></div><style data-emotion=\"css 1uk1gs8\">.css-1uk1gs8{margin:0;}</style><style data-emotion=\"css 1g5cl9a\">.css-1g5cl9a{font-weight:800;line-height:1.25;margin-bottom:8px;font-size:16px;margin:0;}</style><style data-emotion=\"css fbt0po\">.css-fbt0po{color:var(--wf-text--main, #05192D);font-family:Studio-Feixen-Sans,Arial,sans-serif;font-weight:400;line-height:1.5;margin:0;padding:0;font-size:14px;font-weight:800;line-height:1.25;margin-bottom:8px;font-size:16px;margin:0;}</style><h3 class=\"css-fbt0po\">Importing data from the Internet</h3><style data-emotion=\"css 17lebkx\">.css-17lebkx{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;font-family:Studio-Feixen-Sans,Arial,sans-serif;font-weight:800;-webkit-box-pack:center;-ms-flex-pack:center;-webkit-justify-content:center;justify-content:center;letter-spacing:0.5px;line-height:1;padding:0 4px;text-transform:uppercase;border-radius:4px;background-color:var(--wf-yellow--main, #FCCE0D);color:var(--wf-yellow--main, #FCCE0D);font-size:12px;height:18px;}.css-17lebkx span{color:var(--wf-yellow--text-on-color, #05192D);}</style><style data-emotion=\"css 1gjxyd4\">.css-1gjxyd4{color:var(--wf-text--main, #05192D);font-family:Studio-Feixen-Sans,Arial,sans-serif;font-weight:400;line-height:1.5;margin:0;padding:0;font-size:14px;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;font-family:Studio-Feixen-Sans,Arial,sans-serif;font-weight:800;-webkit-box-pack:center;-ms-flex-pack:center;-webkit-justify-content:center;justify-content:center;letter-spacing:0.5px;line-height:1;padding:0 4px;text-transform:uppercase;border-radius:4px;background-color:var(--wf-yellow--main, #FCCE0D);color:var(--wf-yellow--main, #FCCE0D);font-size:12px;height:18px;}.css-1gjxyd4 span{color:var(--wf-yellow--text-on-color, #05192D);}</style><span class=\"css-1gjxyd4\"><style data-emotion=\"css 19ist84\">.css-19ist84{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;color:inherit;display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;gap:4px;max-width:164px;}</style><span class=\"css-19ist84\"><style data-emotion=\"css 8uhtka\">.css-8uhtka{overflow:hidden;text-overflow:ellipsis;white-space:nowrap;}</style><span class=\"css-8uhtka\">Free</span></span></span></div><style data-emotion=\"css 1krpqay\">.css-1krpqay{padding-left:16px;width:200px;}</style><div class=\"css-1krpqay\"><style data-emotion=\"css 18oyfde\">.css-18oyfde{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;color:var(--wf-text--subtle, #5D6A77);display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;font-family:Studio-Feixen-Sans,Arial,sans-serif;gap:8px;line-height:1;width:100%;font-size:12px;}</style><div data-testid=\"progress-wrapper\" class=\"css-18oyfde\"><style data-emotion=\"css k1hg5o\">.css-k1hg5o{display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;-webkit-flex:1;-ms-flex:1;flex:1;position:relative;width:100%;}</style><div class=\"css-k1hg5o\"><style data-emotion=\"css 11s5m7q\">.css-11s5m7q{-webkit-appearance:none;-moz-appearance:none;-ms-appearance:none;appearance:none;background-color:var(--wf-transparent-grey--lighter, rgba(48, 57, 105, 0.15));border:none;width:100%;border-radius:4px;-webkit-clip-path:url(#progress-null-clip);clip-path:url(#progress-null-clip);height:8px;}.css-11s5m7q::-webkit-progress-bar{background-color:inherit;}.css-11s5m7q::-moz-progress-bar{-webkit-transition:width 1s ease-in-out;transition:width 1s ease-in-out;background-color:var(--wf-brand--main, #03EF62);border-radius:4px;}.css-11s5m7q::-webkit-progress-bar{border-radius:4px;}.css-11s5m7q::-webkit-progress-value{-webkit-transition:width 1s ease-in-out;transition:width 1s ease-in-out;background-color:var(--wf-brand--main, #03EF62);border-radius:4px;}</style><progress aria-label=\"Progress\" aria-valuemax=\"100\" aria-valuemin=\"0\" aria-valuenow=\"0\" id=\"progress-null\" max=\"100\" value=\"0\" class=\"css-11s5m7q\"></progress></div><label for=\"progress-null\"><span aria-hidden=\"true\">0%</span></label></div></div></header><style data-emotion=\"css y1tonc\">.css-y1tonc{font-size:14px;font-family:Studio-Feixen-Sans,Arial,sans-serif;line-height:1.5;}</style><div class=\"css-y1tonc\"><p class>The web is a rich source of data from which you can extract various types of insights and findings. In this chapter, you will learn how to get data from the web, whether it is stored in files or in HTML. You&apos;ll also learn the basics of scraping and parsing web data.</p></div></div><style data-emotion=\"css 1lkdjmn\">.css-1lkdjmn{background-color:#F7F7FC;padding:8px;}</style><div class=\"css-1lkdjmn\"><style data-emotion=\"css p9ltrc\">.css-p9ltrc{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;border-color:transparent;border-radius:4px;border-style:solid;border-width:2px;cursor:pointer;display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;font-family:Studio-Feixen-Sans,Arial,sans-serif;font-weight:800;-webkit-box-pack:center;-ms-flex-pack:center;-webkit-justify-content:center;justify-content:center;line-height:1;margin:0;outline:0;padding:0;position:relative;-webkit-text-decoration:none;text-decoration:none;-webkit-transition:background-color 125ms ease-out;transition:background-color 125ms ease-out;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;vertical-align:middle;background-color:transparent;color:var(--wf-text--link, #0065D1);font-size:12px;height:28px;min-width:28px;width:auto;padding-left:8px;padding-right:8px;}.css-p9ltrc::before{border-radius:2px;content:\"\";display:block;height:100%;inset:0;position:absolute;width:100%;z-index:0;}.css-p9ltrc:active{background-color:transparent;}.css-p9ltrc:disabled{cursor:default;opacity:0.4;pointer-events:none;}.css-p9ltrc:hover{border-color:var(--wf-bg--hover, rgba(48, 57, 105, 0.06));}.css-p9ltrc:hover::before{background-color:var(--wf-bg--hover, rgba(48, 57, 105, 0.06));}.css-p9ltrc >*{z-index:1;}</style><button tabindex=\"-1\" data-cy=\"outline-expand-chapter\" type=\"button\" class=\"css-p9ltrc\"><style data-emotion=\"css xejdhu\">.css-xejdhu{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;height:100%;gap:4px;}</style><span class=\"css-xejdhu\">View Chapter Details<svg aria-hidden=\"true\" height=\"14\" width=\"14\" viewbox=\"0 0 18 18\" style=\"flex-shrink:0\"><path fill=\"currentColor\" d=\"m8.244 12.155-4.95-4.947a1 1 0 1 1 1.415-1.415l4.294 4.291 4.293-4.279a.998.998 0 0 1 1.413.003c.39.392.388 1.025-.003 1.415l-5.002 4.986a.998.998 0 0 1-1.46-.054Z\"/></svg></span></button></div></li><li data-cy=\"outline-chapter\" class=\"css-p1ihnf\"><div class=\"css-15hicbc\"><header class=\"css-k008qs\"><div class=\"css-mwfol9\"><div class=\"css-kdtjtf\"><div class=\"css-3xjkdl\">2</div></div><h3 class=\"css-fbt0po\">Interacting with APIs to import data from the web</h3></div><div class=\"css-1krpqay\"><div data-testid=\"progress-wrapper\" class=\"css-18oyfde\"><div class=\"css-k1hg5o\"><progress aria-label=\"Progress\" aria-valuemax=\"100\" aria-valuemin=\"0\" aria-valuenow=\"0\" id=\"progress-null\" max=\"100\" value=\"0\" class=\"css-11s5m7q\"></progress></div><label for=\"progress-null\"><span aria-hidden=\"true\">0%</span></label></div></div></header><div class=\"css-y1tonc\"><p class>In this chapter, you will gain a deeper understanding of how to import data from the web. You will learn the basics of extracting data from APIs, gain insight on the importance of APIs, and practice extracting data by diving into the OMDB and Library of Congress APIs.</p></div></div><div class=\"css-1lkdjmn\"><button tabindex=\"-1\" data-cy=\"outline-expand-chapter\" type=\"button\" class=\"css-p9ltrc\"><span class=\"css-xejdhu\">View Chapter Details<svg aria-hidden=\"true\" height=\"14\" width=\"14\" viewbox=\"0 0 18 18\" style=\"flex-shrink:0\"><path fill=\"currentColor\" d=\"m8.244 12.155-4.95-4.947a1 1 0 1 1 1.415-1.415l4.294 4.291 4.293-4.279a.998.998 0 0 1 1.413.003c.39.392.388 1.025-.003 1.415l-5.002 4.986a.998.998 0 0 1-1.46-.054Z\"/></svg></span></button></div></li><li data-cy=\"outline-chapter\" class=\"css-p1ihnf\"><div class=\"css-15hicbc\"><header class=\"css-k008qs\"><div class=\"css-mwfol9\"><div class=\"css-kdtjtf\"><div class=\"css-3xjkdl\">3</div></div><h3 class=\"css-fbt0po\">Diving  deep into the Twitter API</h3></div><div class=\"css-1krpqay\"><div data-testid=\"progress-wrapper\" class=\"css-18oyfde\"><div class=\"css-k1hg5o\"><progress aria-label=\"Progress\" aria-valuemax=\"100\" aria-valuemin=\"0\" aria-valuenow=\"0\" id=\"progress-null\" max=\"100\" value=\"0\" class=\"css-11s5m7q\"></progress></div><label for=\"progress-null\"><span aria-hidden=\"true\">0%</span></label></div></div></header><div class=\"css-y1tonc\"><p class>In this chapter, you will consolidate your knowledge of interacting with APIs in a deep dive into the Twitter streaming API. You&apos;ll learn how to stream real-time Twitter data, and how to analyze and visualize it.</p></div></div><div class=\"css-1lkdjmn\"><button tabindex=\"-1\" data-cy=\"outline-expand-chapter\" type=\"button\" class=\"css-p9ltrc\"><span class=\"css-xejdhu\">View Chapter Details<svg aria-hidden=\"true\" height=\"14\" width=\"14\" viewbox=\"0 0 18 18\" style=\"flex-shrink:0\"><path fill=\"currentColor\" d=\"m8.244 12.155-4.95-4.947a1 1 0 1 1 1.415-1.415l4.294 4.291 4.293-4.279a.998.998 0 0 1 1.413.003c.39.392.388 1.025-.003 1.415l-5.002 4.986a.998.998 0 0 1-1.46-.054Z\"/></svg></span></button></div></li></ul></div></nav><style data-emotion=\"css 16cuyl0\">.css-16cuyl0{color:#05192D;}</style><style data-emotion=\"css r7pabm\">.css-r7pabm{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;border-color:transparent;border-radius:4px;border-style:solid;border-width:2px;cursor:pointer;display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;font-family:Studio-Feixen-Sans,Arial,sans-serif;font-weight:800;-webkit-box-pack:center;-ms-flex-pack:center;-webkit-justify-content:center;justify-content:center;line-height:1;margin:0;outline:0;padding:0;position:relative;-webkit-text-decoration:none;text-decoration:none;-webkit-transition:background-color 125ms ease-out;transition:background-color 125ms ease-out;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;vertical-align:middle;background-color:transparent;color:var(--wf-text--link, #0065D1);font-size:var(--wf-button--medium, 14px);height:36px;min-width:36px;width:auto;padding-left:16px;padding-right:16px;color:#05192D;}.css-r7pabm::before{border-radius:2px;content:\"\";display:block;height:100%;inset:0;position:absolute;width:100%;z-index:0;}.css-r7pabm:active{background-color:transparent;}.css-r7pabm:disabled{cursor:default;opacity:0.4;pointer-events:none;}.css-r7pabm:hover{border-color:var(--wf-bg--hover, rgba(48, 57, 105, 0.06));}.css-r7pabm:hover::before{background-color:var(--wf-bg--hover, rgba(48, 57, 105, 0.06));}.css-r7pabm >*{z-index:1;}</style><button data-cy=\"header-slides\" class=\"css-r7pabm\" type=\"button\"><span class=\"css-61bni1\"><svg aria-hidden=\"true\" height=\"14\" width=\"14\" viewbox=\"0 0 18 18\"><path fill=\"currentColor\" d=\"M14 9.004H9.996a2 2 0 0 1-2-2V2H4v14h10V9.004Zm1.828-2.815A1.938 1.938 0 0 1 16 7v9a2 2 0 0 1-2 2H4a2 2 0 0 1-2-2V2a2 2 0 0 1 2-2h5.003a2 2 0 0 1 1.415.586l4.997 5a2 2 0 0 1 .413.603Zm-1.832.815-4-4v4h4Z\"/></svg>Show Slides</span></button><button data-cy=\"header-video\" class=\"css-r7pabm\" aria-label=\"Show video\" type=\"button\"><span class=\"css-61bni1\"><svg aria-hidden=\"true\" height=\"14\" width=\"14\" viewbox=\"0 0 18 18\"><path fill=\"currentColor\" d=\"m13 6.3 3.331-2.998A1 1 0 0 1 18 4.045v9.91a1 1 0 0 1-1.669.743L13 11.7V14c0 .552-.485 1-1.083 1H1.083C.485 15 0 14.552 0 14V4c0-.552.485-1 1.083-1h10.834C12.515 3 13 3.448 13 4v2.3Zm0 2.69v.02l3 2.7V6.29l-3 2.7ZM2 5v8h9V5H2Z\"/></svg>Show Video</span></button><button data-cy=\"header-notes\" class=\"css-r7pabm\" type=\"button\"><span class=\"css-61bni1\"><svg aria-hidden=\"true\" height=\"14\" width=\"14\" viewbox=\"0 0 18 18\"><path fill=\"currentColor\" fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M12.528.293a.999.999 0 0 1 1.414 0l3.765 3.765a.999.999 0 0 1 0 1.414L5.472 17.707a1 1 0 0 1-.707.293H1a1 1 0 0 1-1-1v-3.765c0-.265.105-.52.293-.707L12.528.293zM2 13.65V16h2.35l8.412-8.412-2.35-2.35L2 13.65zm9.826-9.826 2.351 2.351 1.409-1.409-2.351-2.35-1.409 1.408zM16.529 18h-8a1 1 0 0 1 0-2h8a1 1 0 0 1 0 2z\"/></svg>Take Notes</span></button><button data-cy=\"header-mobile\" class=\"css-r7pabm\" type=\"button\"><span class=\"css-61bni1\"><svg aria-hidden=\"true\" height=\"14\" width=\"14\" viewbox=\"0 0 18 18\"><path fill=\"currentColor\" d=\"M5.5 2v14h7V2h-7Zm-1-2h9a1 1 0 0 1 1 1v16a1 1 0 0 1-1 1h-9a1 1 0 0 1-1-1V1a1 1 0 0 1 1-1Zm4 13h1a1 1 0 0 1 0 2h-1a1 1 0 0 1 0-2Z\"/></svg>Continue Learning on Mobile</span></button><button data-cy=\"header-issue\" data-test-id=\"header-report-issue-button\" class=\"css-r7pabm\" type=\"button\"><span class=\"css-61bni1\"><svg aria-hidden=\"true\" height=\"14\" width=\"14\" viewbox=\"0 0 18 18\"><path fill=\"currentColor\" fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M17.744 14.31 10.869 1.647a2.119 2.119 0 0 0-3.72 0L.268 14.31a2.116 2.116 0 0 0 1.862 3.148h13.75A2.122 2.122 0 0 0 18 15.383a2.12 2.12 0 0 0-.256-1.052v-.021zm-2.054.419L9.448 3.24a.5.5 0 0 0-.879 0L2.322 14.73a.5.5 0 0 0 .439.739H15.25a.502.502 0 0 0 .44-.74zM8.02 7.017a.994.994 0 1 1 1.99 0v2.57a.994.994 0 1 1-1.99 0v-2.57zm1.021 6.961a1.144 1.144 0 0 1-1.054-.704 1.143 1.143 0 0 1 .247-1.243 1.14 1.14 0 0 1 1.947.807 1.14 1.14 0 0 1-1.14 1.14z\"/></svg>Provide Feedback</span></button><style data-emotion=\"css xqh66l\">.css-xqh66l{margin:8px;color:#05192D;opacity:0.15;border-bottom:none;}</style><hr class=\"css-xqh66l\"><style data-emotion=\"css yv011k\">.css-yv011k{padding:8px;padding-left:16px;padding-right:16px;}</style><div class=\"css-yv011k\"><div data-cy=\"header-session\" css=\"[object Object]\"><style data-emotion=\"css 8zmdb0\">.css-8zmdb0{color:#03EF62;}</style><svg aria-hidden=\"true\" height=\"16\" width=\"16\" viewbox=\"0 0 18 18\" aria-label=\"Session Ready\" class=\"css-8zmdb0\"><path fill=\"currentColor\" d=\"M9 18A9 9 0 1 1 9 0a9 9 0 0 1 0 18Z\"/></svg><style data-emotion=\"css 1isemmb\">.css-1isemmb{margin-left:8px;}</style><span class=\"css-1isemmb\">Initializing</span></div></div></section></div></nav></header><style data-emotion=\"css iqa0tj\">.css-iqa0tj{position:absolute;top:100px;bottom:32px;right:12px;left:12px;overflow:hidden;}</style><main class=\"css-iqa0tj\"><div data-cy=\"server-side-loader-placeholder\"><aside class=\"exercise--sidebar\" style=\"width:40%\"><div class=\"exercise--sidebar-content\"><div class=\"listview__outer\"><div class=\"listview__inner\"><div class=\"listview__section\"><div><div role=\"button\" class=\"listview__header\"><style data-emotion=\"css r7m65a\">.css-r7m65a{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;height:100%;padding-right:16px;}</style><div class=\"css-r7m65a\"><style data-emotion=\"css 171fln0\">.css-171fln0{font-size:16px;margin:0;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;gap:8px;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;padding-left:16px;}</style><style data-emotion=\"css 10nfsoz\">.css-10nfsoz{font-weight:800;line-height:1.25;margin-bottom:8px;font-size:18px;font-size:16px;margin:0;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;gap:8px;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;padding-left:16px;}</style><style data-emotion=\"css 1tah88q\">.css-1tah88q{color:var(--wf-text--main, #05192D);font-family:Studio-Feixen-Sans,Arial,sans-serif;font-weight:400;line-height:1.5;margin:0;padding:0;font-size:14px;font-weight:800;line-height:1.25;margin-bottom:8px;font-size:18px;font-size:16px;margin:0;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;gap:8px;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;padding-left:16px;}</style><h2 class=\"css-1tah88q\"><svg aria-hidden=\"true\" height=\"14\" width=\"14\" viewbox=\"0 0 18 18\"><path fill=\"currentColor\" d=\"M4 2a1 1 0 0 0-1 1v12a1 1 0 0 0 1 1h10a1 1 0 0 0 1-1V3a1 1 0 0 0-1-1H4Zm0-2h10a3 3 0 0 1 3 3v12a3 3 0 0 1-3 3H4a3 3 0 0 1-3-3V3a3 3 0 0 1 3-3Zm2 6h6a1 1 0 0 1 0 2H6a1 1 0 1 1 0-2Zm0 4h6a1 1 0 0 1 0 2H6a1 1 0 0 1 0-2Z\"/></svg>Exercise</h2></div></div></div><div class=\"listview__content\"><style data-emotion=\"css ikv0qb\">.css-ikv0qb{position:relative;padding:16px;}</style><div class=\"css-ikv0qb\"><style data-emotion=\"css 1c1rk5o\">.css-1c1rk5o{font-weight:800;line-height:1.25;margin-bottom:8px;font-size:20px;}</style><style data-emotion=\"css fsa3o0\">.css-fsa3o0{color:var(--wf-text--main, #05192D);font-family:Studio-Feixen-Sans,Arial,sans-serif;font-weight:400;line-height:1.5;margin:0;padding:0;font-size:14px;font-weight:800;line-height:1.25;margin-bottom:8px;font-size:20px;}</style><h1 class=\"css-fsa3o0\">Importing flat files from the web: your turn!</h1><style data-emotion=\"css 8czf7d\">.css-8czf7d{line-height:1.5;}.css-8czf7d code{font-family:JetBrainsMonoNL,Menlo,Monaco,\\'Courier New\\',monospace;margin:0 2px;padding:2px 4px;line-height:1.25;background-color:#EFEFF5;border-radius:4px;font-size:86%;mix-blend-mode:multiply;}.css-8czf7d pre{background-color:#EFEFF5;padding:8px;margin:0;border-radius:4px;tab-size:4;white-space:pre;line-height:1.25;mix-blend-mode:multiply;}.css-8czf7d pre>code{margin:0;padding:0;background-color:transparent;}.css-8czf7d ul,.css-8czf7d ol{padding-left:16px;}.css-8czf7d ul:first-of-type,.css-8czf7d ol:first-of-type{margin-top:0;}.css-8czf7d p:first-of-type{margin-top:0;}.css-8czf7d li{margin-bottom:8px;}.css-8czf7d a{color:#0065D1;-webkit-text-decoration:none;text-decoration:none;font-weight:800;border-radius:4px;outline:0;}.css-8czf7d a:hover{color:#0065D1;-webkit-text-decoration:underline;text-decoration:underline;}.css-8czf7d a:focus-visible{box-shadow:0 0 0 2px #257DFE;}.css-8czf7d a code{color:#0065D1;}.css-8czf7d hr{background-color:rgba(48, 57, 105, 0.15);border:0;height:1px;margin:16px 0;}</style><style data-emotion=\"css alxior\">.css-alxior{color:var(--wf-text--main, #05192D);font-family:Studio-Feixen-Sans,Arial,sans-serif;font-weight:400;line-height:1.5;margin:0;padding:0;font-size:14px;line-height:1.5;}.css-alxior code{font-family:JetBrainsMonoNL,Menlo,Monaco,\\'Courier New\\',monospace;margin:0 2px;padding:2px 4px;line-height:1.25;background-color:#EFEFF5;border-radius:4px;font-size:86%;mix-blend-mode:multiply;}.css-alxior pre{background-color:#EFEFF5;padding:8px;margin:0;border-radius:4px;tab-size:4;white-space:pre;line-height:1.25;mix-blend-mode:multiply;}.css-alxior pre>code{margin:0;padding:0;background-color:transparent;}.css-alxior ul,.css-alxior ol{padding-left:16px;}.css-alxior ul:first-of-type,.css-alxior ol:first-of-type{margin-top:0;}.css-alxior p:first-of-type{margin-top:0;}.css-alxior li{margin-bottom:8px;}.css-alxior a{color:#0065D1;-webkit-text-decoration:none;text-decoration:none;font-weight:800;border-radius:4px;outline:0;}.css-alxior a:hover{color:#0065D1;-webkit-text-decoration:underline;text-decoration:underline;}.css-alxior a:focus-visible{box-shadow:0 0 0 2px #257DFE;}.css-alxior a code{color:#0065D1;}.css-alxior hr{background-color:rgba(48, 57, 105, 0.15);border:0;height:1px;margin:16px 0;}</style><div class=\"css-alxior\"><div class><p>You are about to import your first file from the web! The flat file you will import will be <code>&apos;winequality-red.csv&apos;</code> from the University of California, Irvine&apos;s <a href=\"https://archive.ics.uci.edu/ml/index.php\">Machine Learning repository</a>. The flat file contains tabular data of physiochemical properties of red wine, such as pH, alcohol content and citric acid content, along with wine quality rating.</p>\\n<p>The URL of the file is</p>\\n<pre><code>&apos;https://assets.datacamp.com/production/course_1606/datasets/winequality-red.csv&apos;\\n</code></pre>\\n<p>After you import it, you&apos;ll check your working directory to confirm that it is there and then you&apos;ll load it into a <code>pandas</code> DataFrame.</p></div></div></div></div></div><div class=\"listview__section\" style=\"min-height:calc(50% - 33px)\"><div><div role=\"button\" class=\"listview__header\"><div class=\"css-r7m65a\"><style data-emotion=\"css 1ubtfgv\">.css-1ubtfgv{font-size:16px;margin:0;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;gap:8px;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;padding-left:16px;width:100%;-webkit-box-flex:1;-webkit-flex-grow:1;-ms-flex-positive:1;flex-grow:1;}</style><style data-emotion=\"css ycumlt\">.css-ycumlt{font-weight:800;line-height:1.25;margin-bottom:8px;font-size:18px;font-size:16px;margin:0;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;gap:8px;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;padding-left:16px;width:100%;-webkit-box-flex:1;-webkit-flex-grow:1;-ms-flex-positive:1;flex-grow:1;}</style><style data-emotion=\"css 1kphf8n\">.css-1kphf8n{color:var(--wf-text--main, #05192D);font-family:Studio-Feixen-Sans,Arial,sans-serif;font-weight:400;line-height:1.5;margin:0;padding:0;font-size:14px;font-weight:800;line-height:1.25;margin-bottom:8px;font-size:18px;font-size:16px;margin:0;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;gap:8px;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;padding-left:16px;width:100%;-webkit-box-flex:1;-webkit-flex-grow:1;-ms-flex-positive:1;flex-grow:1;}</style><h2 class=\"css-1kphf8n\"><svg aria-hidden=\"true\" height=\"14\" width=\"14\" viewbox=\"0 0 18 18\"><path fill=\"currentColor\" d=\"M9 16A7 7 0 1 0 9 2a7 7 0 0 0 0 14Zm0 2A9 9 0 1 1 9 0a9 9 0 0 1 0 18Zm2.326-11.96a1 1 0 0 1 1.555 1.258L8.773 12.37a1 1 0 0 1-1.534.024l-2.124-2.46a1 1 0 0 1 1.514-1.307l1.342 1.556 3.355-4.144Z\"/></svg>Instructions</h2><style data-emotion=\"css 17lebkx\">.css-17lebkx{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;font-family:Studio-Feixen-Sans,Arial,sans-serif;font-weight:800;-webkit-box-pack:center;-ms-flex-pack:center;-webkit-justify-content:center;justify-content:center;letter-spacing:0.5px;line-height:1;padding:0 4px;text-transform:uppercase;border-radius:4px;background-color:var(--wf-yellow--main, #FCCE0D);color:var(--wf-yellow--main, #FCCE0D);font-size:12px;height:18px;}.css-17lebkx span{color:var(--wf-yellow--text-on-color, #05192D);}</style><style data-emotion=\"css 1gjxyd4\">.css-1gjxyd4{color:var(--wf-text--main, #05192D);font-family:Studio-Feixen-Sans,Arial,sans-serif;font-weight:400;line-height:1.5;margin:0;padding:0;font-size:14px;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;font-family:Studio-Feixen-Sans,Arial,sans-serif;font-weight:800;-webkit-box-pack:center;-ms-flex-pack:center;-webkit-justify-content:center;justify-content:center;letter-spacing:0.5px;line-height:1;padding:0 4px;text-transform:uppercase;border-radius:4px;background-color:var(--wf-yellow--main, #FCCE0D);color:var(--wf-yellow--main, #FCCE0D);font-size:12px;height:18px;}.css-1gjxyd4 span{color:var(--wf-yellow--text-on-color, #05192D);}</style><span class=\"css-1gjxyd4\"><style data-emotion=\"css 19ist84\">.css-19ist84{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;color:inherit;display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;gap:4px;max-width:164px;}</style><span class=\"css-19ist84\"><style data-emotion=\"css 8uhtka\">.css-8uhtka{overflow:hidden;text-overflow:ellipsis;white-space:nowrap;}</style><span class=\"css-8uhtka\">100 XP</span></span></span></div></div></div><div class=\"listview__content\"><div><style data-emotion=\"css 186pnwx\">.css-186pnwx{-webkit-flex:1;-ms-flex:1;flex:1;position:relative;padding:16px;}</style><div class=\"css-186pnwx\"><div class=\"css-alxior\"><div class=\"exercise--instructions__content\"><ul>\\n<li>Import the function <code>urlretrieve</code> from the subpackage <code>urllib.request</code>.</li>\\n<li>Assign the URL of the file to the variable <code>url</code>.</li>\\n<li>Use the function <code>urlretrieve()</code> to save the file locally as <code>&apos;winequality-red.csv&apos;</code>.</li>\\n<li>Execute the remaining code to load <code>&apos;winequality-red.csv&apos;</code> in a pandas DataFrame and to print its head to the shell.</li>\\n</ul></div></div><style data-emotion=\"css kbabwt\">.css-kbabwt{margin:16px -16px 0;}</style><div class=\"css-kbabwt\"><section class=\"dc-sct-feedback\" tabindex=\"-1\"><div></div><nav class=\"dc-sct-feedback__nav\"><style data-emotion=\"css n085mf\">.css-n085mf{padding-left:16px;}</style><div class=\"css-n085mf\"><style data-emotion=\"css 12j1yck\">.css-12j1yck{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;border:0;border-radius:4px;border-style:solid;border-width:2px;cursor:pointer;display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;-webkit-box-pack:center;-ms-flex-pack:center;-webkit-justify-content:center;justify-content:center;position:relative;-webkit-text-decoration:none;text-decoration:none;text-transform:capitalize;-webkit-transition:0.15s;transition:0.15s;vertical-align:baseline;white-space:nowrap;background-color:transparent;border-color:#05192D;color:#05192D;padding:0 15px;}.css-12j1yck:active{-webkit-transform:perspective(1px) scale(0.975);-moz-transform:perspective(1px) scale(0.975);-ms-transform:perspective(1px) scale(0.975);transform:perspective(1px) scale(0.975);}.css-12j1yck:disabled,.css-12j1yck:hover:disabled,.css-12j1yck:active:disabled{-webkit-transform:none;-moz-transform:none;-ms-transform:none;transform:none;}.css-12j1yck:focus{outline:0;}.css-12j1yck:hover{background-color:rgba(5, 25, 45, 0.15);border-color:#05192D;color:#05192D;}</style><button class=\"dc-sct-feedback__nav--hint-solution css-12j1yck\" type=\"button\" data-cy=\"exercise-show-hint\"><svg viewbox=\"0 0 18 18\" aria-hidden=\"true\" height=\"16\" role=\"img\" width=\"16\"><path fill=\"currentColor\" d=\"M9 0a7 7 0 014.95 11.95l-.001-.001c-.794.795-.949 1.1-.949 2.051a1 1 0 01-2 0c0-1.548.396-2.325 1.535-3.467l.04-.037a5 5 0 10-7.11.037C6.605 11.675 7 12.453 7 14a1 1 0 01-2 0c0-.951-.155-1.256-.949-2.051A7 7 0 019 0zm0 7a1 1 0 011 1v6a1 1 0 01-2 0V8a1 1 0 011-1zm0 11c-1.657 0-3-.895-3-2h6c0 1.105-1.343 2-3 2z\" fill-rule=\"evenodd\"/></svg><style data-emotion=\"css aib9ji\">.css-aib9ji{font-size:14px;line-height:32px;color:#05192D;font-weight:bold;margin-left:8px;}</style><style data-emotion=\"css vvk465\">.css-vvk465{-webkit-font-smoothing:antialiased;color:#05192D;font-family:Studio-Feixen-Sans,Arial,sans-serif;font-style:normal;font-size:14px;font-weight:400;font-size:14px;line-height:32px;color:#05192D;font-weight:bold;margin-left:8px;}</style><span class=\"css-vvk465\">Take Hint (-30 XP)</span></button></div></nav></section></div></div></div></div></div></div></div></div></aside><section class=\"exercise--content\" style=\"width:60%\"><div class=\"exercise-waiting\"><style data-emotion=\"css 1gnr744\">.css-1gnr744{position:absolute;top:50%;left:50%;-webkit-transform:translate(-50%, -50%);-moz-transform:translate(-50%, -50%);-ms-transform:translate(-50%, -50%);transform:translate(-50%, -50%);display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-ms-flex-pack:center;-webkit-justify-content:center;justify-content:center;}</style><div class=\"css-1gnr744\"><style data-emotion=\"css 1rm9ybb animation-1pv1bkr\">.css-1rm9ybb{-webkit-animation:animation-1pv1bkr cubic-bezier(0.65, 0, 0.55, 1) 2s infinite alternate;animation:animation-1pv1bkr cubic-bezier(0.65, 0, 0.55, 1) 2s infinite alternate;will-change:clip-path;--wf-loader--color:var(--wf-text--main, #05192D);width:50;}@-webkit-keyframes animation-1pv1bkr{0%,6%{-webkit-clip-path:polygon(0% -12%, 0% -12%, 169% 63%, 169% 63%);clip-path:polygon(0% -12%, 0% -12%, 169% 63%, 169% 63%);}100%{-webkit-clip-path:polygon(0% -12%, 0% 308%, 169% 383%, 169% 63%);clip-path:polygon(0% -12%, 0% 308%, 169% 383%, 169% 63%);}}@keyframes animation-1pv1bkr{0%,6%{-webkit-clip-path:polygon(0% -12%, 0% -12%, 169% 63%, 169% 63%);clip-path:polygon(0% -12%, 0% -12%, 169% 63%, 169% 63%);}100%{-webkit-clip-path:polygon(0% -12%, 0% 308%, 169% 383%, 169% 63%);clip-path:polygon(0% -12%, 0% 308%, 169% 383%, 169% 63%);}}</style><div aria-label=\"Loading\" data-testid=\"loader-wrapper\" role=\"alert\" class=\"css-1rm9ybb\"><style data-emotion=\"css 1j8nxo animation-1h2cwi2\">.css-1j8nxo{-webkit-animation:animation-1h2cwi2 cubic-bezier(0, 0, 0.85, 1) 2s infinite alternate;animation:animation-1h2cwi2 cubic-bezier(0, 0, 0.85, 1) 2s infinite alternate;will-change:clip-path;}@-webkit-keyframes animation-1h2cwi2{0%,71%{-webkit-clip-path:polygon(0% 0%, 0% 78.5%, 100% 34.5%, 100% -44%);clip-path:polygon(0% 0%, 0% 78.5%, 100% 34.5%, 100% -44%);}96%,100%{-webkit-clip-path:polygon(0% 0%, 0% 140%, 100% 96%, 100% -44%);clip-path:polygon(0% 0%, 0% 140%, 100% 96%, 100% -44%);}}@keyframes animation-1h2cwi2{0%,71%{-webkit-clip-path:polygon(0% 0%, 0% 78.5%, 100% 34.5%, 100% -44%);clip-path:polygon(0% 0%, 0% 78.5%, 100% 34.5%, 100% -44%);}96%,100%{-webkit-clip-path:polygon(0% 0%, 0% 140%, 100% 96%, 100% -44%);clip-path:polygon(0% 0%, 0% 140%, 100% 96%, 100% -44%);}}</style><div class=\"css-1j8nxo\"><style data-emotion=\"css zsjzbc\">.css-zsjzbc{-webkit-clip-path:polygon(-0.1% -10%, 169% 65%, -0.1% 139%);clip-path:polygon(-0.1% -10%, 169% 65%, -0.1% 139%);}</style><div class=\"css-zsjzbc\"><style data-emotion=\"css cihpzr\">.css-cihpzr{display:block;overflow:visible;stroke:var(--wf-loader--color, var(--wf-text--main, #05192D));}</style><svg viewbox=\"0 0 2640 3444\" width=\"50\" class=\"css-cihpzr\"><style data-emotion=\"css jy99qt animation-co7x2c\">.css-jy99qt{-webkit-animation:animation-co7x2c cubic-bezier(0.65, 0, 0.55, 1) 2s infinite alternate;animation:animation-co7x2c cubic-bezier(0.65, 0, 0.55, 1) 2s infinite alternate;stroke-dasharray:9800;stroke-dashoffset:9800;will-change:stroke-dashoffset;}@-webkit-keyframes animation-co7x2c{100%{stroke-dashoffset:0;}}@keyframes animation-co7x2c{100%{stroke-dashoffset:0;}}</style><path d=\"M0 0 M2569 1056L143 2447V149l1175 673v1867l1248 715\" fill=\"none\" stroke-linejoin=\"round\" stroke-width=\"300\" class=\"css-jy99qt\"/></svg></div></div></div></div><noscript></noscript></div></section></div></main><div class=\"exercise-footer\"><style data-emotion=\"css 8uttuf\">.css-8uttuf{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-ms-flex-pack:center;-webkit-justify-content:center;justify-content:center;width:100%;max-width:600px;list-style:none;margin:0;padding:0;gap:8px;}</style><ul data-cy=\"progress-container\" class=\"css-8uttuf\"><style data-emotion=\"css 149stfi\">.css-149stfi{-webkit-box-flex:1;-webkit-flex-grow:1;-ms-flex-positive:1;flex-grow:1;max-width:100px;}</style><li class=\"css-149stfi\"><style data-emotion=\"css 46tute\">.css-46tute{display:block;height:8px;border-radius:4px;background-color:rgba(48, 57, 105, 0.15);border-bottom:0;outline:0;}.css-46tute:focus-visible{box-shadow:0 0 0 2px #257DFE;}</style><a href=\"javascript:void(0)\" data-testid=\"progress-indicator-item\" class=\"css-46tute\"><style data-emotion=\"css 1pw8nbl\">.css-1pw8nbl{-webkit-transition:width 250ms linear;transition:width 250ms linear;height:8px;border-radius:4px;background-color:#5EB1FF;}</style><div style=\"width:0%\" class=\"css-1pw8nbl\"></div></a></li><li class=\"css-149stfi\"><a href=\"javascript:void(0)\" data-testid=\"progress-indicator-item\" class=\"css-46tute\"><div style=\"width:0%\" class=\"css-1pw8nbl\"></div></a></li><li class=\"css-149stfi\"><a href=\"javascript:void(0)\" data-testid=\"progress-indicator-item\" class=\"css-46tute\"><div style=\"width:0%\" class=\"css-1pw8nbl\"></div></a></li></ul></div></div></div><script>window.MathJax={options:{ignoreHtmlClass:\"tex2jax_ignore\",processHtmlClass:\"tex2jax_process\"},tex:{autoload:{color:[],colorV2:[\"color\"]},packages:{\"[+]\":[\"noerrors\"]}},loader:{load:[\"[tex]/noerrors\"]}}</script><script src=\"/campus/mathjax@3/es5/tex-chtml.js\" id=\"MathJax-script\" async></script><script>!function(e){function o(o){for(var d,n,r=o[0],s=o[1],m=o[2],t=0,v=[];t<r.length;t++)n=r[t],Object.prototype.hasOwnProperty.call(a,n)&&a[n]&&v.push(a[n][0]),a[n]=0;for(d in s)Object.prototype.hasOwnProperty.call(s,d)&&(e[d]=s[d]);for(b&&b(o);v.length;)v.shift()();return f.push.apply(f,m||[]),c()}function c(){for(var e,o=0;o<f.length;o++){for(var c=f[o],d=!0,n=1;n<c.length;n++){var s=c[n];0!==a[s]&&(d=!1)}d&&(f.splice(o--,1),e=r(r.s=c[0]))}return e}var d={},n={97:0},a={97:0},f=[];function r(o){if(d[o])return d[o].exports;var c=d[o]={i:o,l:!1,exports:{}};return e[o].call(c.exports,c,c.exports,r),c.l=!0,c.exports}r.e=function(e){var o=[];n[e]?o.push(n[e]):0!==n[e]&&{0:1,5:1,11:1,15:1,16:1,17:1,18:1,22:1,24:1,27:1,29:1,32:1,33:1,35:1,41:1,45:1,48:1,51:1,52:1,53:1,54:1,55:1,59:1,61:1,62:1,63:1,66:1,68:1,71:1,72:1,87:1,93:1,94:1,96:1,136:1,138:1,139:1}[e]&&o.push(n[e]=new Promise((function(o,c){for(var d=\"static/css/\"+({0:\"vendors~ce~dnde~ee~ge~idee~pmce~rde~se~ve~vise~a4f7b5e1\",1:\"vendors~ce~dnde~ee~ge~idee~pmce~rde~splitio~ve~vise~253ae210\",2:\"vendors~ce~dnde~ee~ge~idee~pmce~rde~splitio~ve~vise~c7ce39a9\",3:\"vendors~ce~dnde~ee~ge~idee~pmce~rde~splitio~ve~vise~d49b3b41\",4:\"vendors~ce~dnde~ee~ge~idee~pmce~rde~ve~vise~253ae210\",5:\"vendors~dnde~ee~ge~idee~pmce~vise~253ae210\",6:\"vendors~ce~rde~253ae210\",7:\"vendors~ce~rde~7274e1de\",8:\"vendors~ce~rde~b5a0571e\",9:\"vendors~console-monaco~monaco~235b8c57\",10:\"vendors~console-monaco~monaco~253ae210\",11:\"vendors~console-monaco~monaco~36912834\",12:\"vendors~console-monaco~monaco~49d8ad03\",13:\"vendors~console-monaco~monaco~4d911f2e\",14:\"vendors~console-monaco~monaco~5584ff6c\",15:\"vendors~console-monaco~monaco~57c220dc\",16:\"vendors~console-monaco~monaco~589039fc\",17:\"vendors~console-monaco~monaco~5e1bc0de\",18:\"vendors~console-monaco~monaco~6ddf31e8\",19:\"vendors~console-monaco~monaco~80993005\",20:\"vendors~console-monaco~monaco~85a20469\",21:\"vendors~console-monaco~monaco~86ffeb1a\",22:\"vendors~console-monaco~monaco~900aca88\",23:\"vendors~console-monaco~monaco~9c5b28f6\",24:\"vendors~console-monaco~monaco~a03ee73f\",25:\"vendors~console-monaco~monaco~ba2d52b5\",26:\"vendors~console-monaco~monaco~c01cf258\",27:\"vendors~console-monaco~monaco~c682183c\",28:\"vendors~console-monaco~monaco~c73e0090\",29:\"vendors~console-monaco~monaco~d7ac9e7b\",30:\"vendors~console-monaco~monaco~dac6e39f\",31:\"vendors~console-monaco~monaco~e66ff6d3\",32:\"vendors~console-monaco~monaco~e69ef85d\",33:\"vendors~console-monaco~monaco~f7d19227\",35:\"ce~253ae210\",36:\"ce~40b10d04\",37:\"ce~62c53bf1\",38:\"ce~748942c6\",39:\"ce~a4f7b5e1\",40:\"console-monaco~31ecd969\",41:\"dnde~253ae210\",42:\"dnde~9c5b28f6\",43:\"dnde~c8f69aa9\",44:\"ee~253ae210\",45:\"ee~a4f7b5e1\",46:\"ge~06694820\",47:\"ge~235b8c57\",48:\"ge~36912834\",49:\"ge~4d911f2e\",50:\"ge~5584ff6c\",51:\"ge~57c220dc\",52:\"ge~589039fc\",53:\"ge~5e1bc0de\",54:\"ge~6ddf31e8\",55:\"ge~7f323393\",56:\"ge~80993005\",57:\"ge~85a20469\",58:\"ge~86ffeb1a\",59:\"ge~900aca88\",60:\"ge~9c5b28f6\",61:\"ge~a03ee73f\",62:\"ge~a4f7b5e1\",63:\"ge~b6351802\",64:\"ge~ba2d52b5\",65:\"ge~c01cf258\",66:\"ge~c682183c\",67:\"ge~c73e0090\",68:\"ge~d7ac9e7b\",69:\"ge~dac6e39f\",70:\"ge~e66ff6d3\",71:\"ge~f7d19227\",72:\"idee~0f485567\",73:\"idee~253ae210\",80:\"markdown-renderer~2353b14b\",81:\"modal-views~31ecd969\",82:\"monaco~31ecd969\",83:\"pmce~0df6afb5\",84:\"pmce~253ae210\",85:\"pmce~56e1be11\",86:\"pmce~9c5b28f6\",87:\"pmce~a4f7b5e1\",88:\"pmce~d80adb5f\",89:\"pmce~e65503b9\",90:\"pmce~ece0910c\",91:\"rde~1f059a71\",92:\"rde~253ae210\",93:\"rde~3dd5b2e0\",94:\"rde~3ffedb8b\",95:\"rde~5f1bbfc7\",96:\"rde~748942c6\",135:\"vendors~se~253ae210\",136:\"vendors~se~a4f7b5e1\",137:\"vendors~se~d0fcca00\",138:\"vendors~ve~cfba5e8d\",139:\"vendors~xterm~0d30e071\",140:\"vise~b26d07d5\",141:\"vise~da250ca5\",142:\"vise~e65503b9\",143:\"xterm~d021be4b\"}[e]||e)+\".\"+{0:\"f479e7a2\",1:\"31d6cfe0\",2:\"31d6cfe0\",3:\"31d6cfe0\",4:\"31d6cfe0\",5:\"a8d4fad6\",6:\"31d6cfe0\",7:\"31d6cfe0\",8:\"31d6cfe0\",9:\"31d6cfe0\",10:\"31d6cfe0\",11:\"1ad26591\",12:\"31d6cfe0\",13:\"31d6cfe0\",14:\"31d6cfe0\",15:\"ea109276\",16:\"59e05191\",17:\"9bf089b3\",18:\"d2c4604b\",19:\"31d6cfe0\",20:\"31d6cfe0\",21:\"31d6cfe0\",22:\"7a6ad70e\",23:\"31d6cfe0\",24:\"98d862d2\",25:\"31d6cfe0\",26:\"31d6cfe0\",27:\"03248981\",28:\"31d6cfe0\",29:\"9f101993\",30:\"31d6cfe0\",31:\"31d6cfe0\",32:\"3f1ff7c1\",33:\"2281ed76\",34:\"31d6cfe0\",35:\"7986f49c\",36:\"31d6cfe0\",37:\"31d6cfe0\",38:\"31d6cfe0\",39:\"31d6cfe0\",40:\"31d6cfe0\",41:\"f63aa94e\",42:\"31d6cfe0\",43:\"31d6cfe0\",44:\"31d6cfe0\",45:\"318451f9\",46:\"31d6cfe0\",47:\"31d6cfe0\",48:\"1ad26591\",49:\"31d6cfe0\",50:\"31d6cfe0\",51:\"ea109276\",52:\"59e05191\",53:\"9bf089b3\",54:\"d2c4604b\",55:\"96a878eb\",56:\"31d6cfe0\",57:\"31d6cfe0\",58:\"31d6cfe0\",59:\"7a6ad70e\",60:\"31d6cfe0\",61:\"98d862d2\",62:\"d498bfb3\",63:\"28103d70\",64:\"31d6cfe0\",65:\"31d6cfe0\",66:\"03248981\",67:\"31d6cfe0\",68:\"9f101993\",69:\"31d6cfe0\",70:\"31d6cfe0\",71:\"2281ed76\",72:\"c86e1775\",73:\"31d6cfe0\",80:\"31d6cfe0\",81:\"31d6cfe0\",82:\"31d6cfe0\",83:\"31d6cfe0\",84:\"31d6cfe0\",85:\"31d6cfe0\",86:\"31d6cfe0\",87:\"5f802060\",88:\"31d6cfe0\",89:\"31d6cfe0\",90:\"31d6cfe0\",91:\"31d6cfe0\",92:\"31d6cfe0\",93:\"05896465\",94:\"0cc5eb29\",95:\"31d6cfe0\",96:\"53e0c1db\",135:\"31d6cfe0\",136:\"74da6240\",137:\"31d6cfe0\",138:\"37797958\",139:\"9e71d144\",140:\"31d6cfe0\",141:\"31d6cfe0\",142:\"31d6cfe0\",143:\"31d6cfe0\",144:\"31d6cfe0\",145:\"31d6cfe0\",146:\"31d6cfe0\",147:\"31d6cfe0\",148:\"31d6cfe0\",149:\"31d6cfe0\",150:\"31d6cfe0\",151:\"31d6cfe0\",152:\"31d6cfe0\",153:\"31d6cfe0\"}[e]+\".chunk.css\",a=r.p+d,f=document.getElementsByTagName(\"link\"),s=0;s<f.length;s++){var m=(b=f[s]).getAttribute(\"data-href\")||b.getAttribute(\"href\");if(\"stylesheet\"===b.rel&&(m===d||m===a))return o()}var t=document.getElementsByTagName(\"style\");for(s=0;s<t.length;s++){var b;if((m=(b=t[s]).getAttribute(\"data-href\"))===d||m===a)return o()}var v=document.createElement(\"link\");v.rel=\"stylesheet\",v.type=\"text/css\",v.onload=o,v.onerror=function(o){var d=o&&o.target&&o.target.src||a,f=new Error(\"Loading CSS chunk \"+e+\" failed.\\\\n(\"+d+\")\");f.code=\"CSS_CHUNK_LOAD_FAILED\",f.request=d,delete n[e],v.parentNode.removeChild(v),c(f)},v.href=a,document.getElementsByTagName(\"head\")[0].appendChild(v)})).then((function(){n[e]=0})));var c=a[e];if(0!==c)if(c)o.push(c[2]);else{var d=new Promise((function(o,d){c=a[e]=[o,d]}));o.push(c[2]=d);var f,s=document.createElement(\"script\");s.charset=\"utf-8\",s.timeout=120,r.nc&&s.setAttribute(\"nonce\",r.nc),s.src=function(e){return r.p+\"static/js/\"+({0:\"vendors~ce~dnde~ee~ge~idee~pmce~rde~se~ve~vise~a4f7b5e1\",1:\"vendors~ce~dnde~ee~ge~idee~pmce~rde~splitio~ve~vise~253ae210\",2:\"vendors~ce~dnde~ee~ge~idee~pmce~rde~splitio~ve~vise~c7ce39a9\",3:\"vendors~ce~dnde~ee~ge~idee~pmce~rde~splitio~ve~vise~d49b3b41\",4:\"vendors~ce~dnde~ee~ge~idee~pmce~rde~ve~vise~253ae210\",5:\"vendors~dnde~ee~ge~idee~pmce~vise~253ae210\",6:\"vendors~ce~rde~253ae210\",7:\"vendors~ce~rde~7274e1de\",8:\"vendors~ce~rde~b5a0571e\",9:\"vendors~console-monaco~monaco~235b8c57\",10:\"vendors~console-monaco~monaco~253ae210\",11:\"vendors~console-monaco~monaco~36912834\",12:\"vendors~console-monaco~monaco~49d8ad03\",13:\"vendors~console-monaco~monaco~4d911f2e\",14:\"vendors~console-monaco~monaco~5584ff6c\",15:\"vendors~console-monaco~monaco~57c220dc\",16:\"vendors~console-monaco~monaco~589039fc\",17:\"vendors~console-monaco~monaco~5e1bc0de\",18:\"vendors~console-monaco~monaco~6ddf31e8\",19:\"vendors~console-monaco~monaco~80993005\",20:\"vendors~console-monaco~monaco~85a20469\",21:\"vendors~console-monaco~monaco~86ffeb1a\",22:\"vendors~console-monaco~monaco~900aca88\",23:\"vendors~console-monaco~monaco~9c5b28f6\",24:\"vendors~console-monaco~monaco~a03ee73f\",25:\"vendors~console-monaco~monaco~ba2d52b5\",26:\"vendors~console-monaco~monaco~c01cf258\",27:\"vendors~console-monaco~monaco~c682183c\",28:\"vendors~console-monaco~monaco~c73e0090\",29:\"vendors~console-monaco~monaco~d7ac9e7b\",30:\"vendors~console-monaco~monaco~dac6e39f\",31:\"vendors~console-monaco~monaco~e66ff6d3\",32:\"vendors~console-monaco~monaco~e69ef85d\",33:\"vendors~console-monaco~monaco~f7d19227\",35:\"ce~253ae210\",36:\"ce~40b10d04\",37:\"ce~62c53bf1\",38:\"ce~748942c6\",39:\"ce~a4f7b5e1\",40:\"console-monaco~31ecd969\",41:\"dnde~253ae210\",42:\"dnde~9c5b28f6\",43:\"dnde~c8f69aa9\",44:\"ee~253ae210\",45:\"ee~a4f7b5e1\",46:\"ge~06694820\",47:\"ge~235b8c57\",48:\"ge~36912834\",49:\"ge~4d911f2e\",50:\"ge~5584ff6c\",51:\"ge~57c220dc\",52:\"ge~589039fc\",53:\"ge~5e1bc0de\",54:\"ge~6ddf31e8\",55:\"ge~7f323393\",56:\"ge~80993005\",57:\"ge~85a20469\",58:\"ge~86ffeb1a\",59:\"ge~900aca88\",60:\"ge~9c5b28f6\",61:\"ge~a03ee73f\",62:\"ge~a4f7b5e1\",63:\"ge~b6351802\",64:\"ge~ba2d52b5\",65:\"ge~c01cf258\",66:\"ge~c682183c\",67:\"ge~c73e0090\",68:\"ge~d7ac9e7b\",69:\"ge~dac6e39f\",70:\"ge~e66ff6d3\",71:\"ge~f7d19227\",72:\"idee~0f485567\",73:\"idee~253ae210\",80:\"markdown-renderer~2353b14b\",81:\"modal-views~31ecd969\",82:\"monaco~31ecd969\",83:\"pmce~0df6afb5\",84:\"pmce~253ae210\",85:\"pmce~56e1be11\",86:\"pmce~9c5b28f6\",87:\"pmce~a4f7b5e1\",88:\"pmce~d80adb5f\",89:\"pmce~e65503b9\",90:\"pmce~ece0910c\",91:\"rde~1f059a71\",92:\"rde~253ae210\",93:\"rde~3dd5b2e0\",94:\"rde~3ffedb8b\",95:\"rde~5f1bbfc7\",96:\"rde~748942c6\",135:\"vendors~se~253ae210\",136:\"vendors~se~a4f7b5e1\",137:\"vendors~se~d0fcca00\",138:\"vendors~ve~cfba5e8d\",139:\"vendors~xterm~0d30e071\",140:\"vise~b26d07d5\",141:\"vise~da250ca5\",142:\"vise~e65503b9\",143:\"xterm~d021be4b\"}[e]||e)+\".\"+{0:\"1d82e8a6\",1:\"49e109bd\",2:\"12db2881\",3:\"1647a0ff\",4:\"2705d6e6\",5:\"d2c8e124\",6:\"91be1254\",7:\"dc75903c\",8:\"344c3320\",9:\"34551be5\",10:\"312dc061\",11:\"f36228cf\",12:\"2faff24d\",13:\"1dfe5846\",14:\"b5d496c9\",15:\"9549b59d\",16:\"7b88f286\",17:\"583f9755\",18:\"c2d7c43a\",19:\"228ba56e\",20:\"39bed9b8\",21:\"4b7b5385\",22:\"ab6a4a63\",23:\"c67012bc\",24:\"3c5f6279\",25:\"afc56e20\",26:\"847c4771\",27:\"93ab0953\",28:\"244b3464\",29:\"2336e3c0\",30:\"b4ee706f\",31:\"ea970b75\",32:\"c6980440\",33:\"a2e94c09\",34:\"0ba116dc\",35:\"026785e0\",36:\"27bef178\",37:\"a25ea595\",38:\"c8b72a52\",39:\"12a7eefd\",40:\"2b265f1a\",41:\"40ac37b1\",42:\"819dad87\",43:\"3a885e0f\",44:\"a5217467\",45:\"6ea1cd17\",46:\"0e9723e4\",47:\"25735538\",48:\"fe7822b4\",49:\"935834d5\",50:\"5d3f006b\",51:\"f6aefef4\",52:\"484a730a\",53:\"dc6a3bde\",54:\"5ff44360\",55:\"9eaf98ee\",56:\"ada80d8b\",57:\"5e806715\",58:\"d732d9b7\",59:\"d85f6dd6\",60:\"e56d0c62\",61:\"de798489\",62:\"eee506a2\",63:\"e897e396\",64:\"a8ed2264\",65:\"203f0126\",66:\"113d0bea\",67:\"b2ec5b96\",68:\"73dd834a\",69:\"d439387b\",70:\"4bbd3371\",71:\"3e79f0f0\",72:\"5aa2c855\",73:\"2fdc94b1\",80:\"ba19212e\",81:\"6972e36a\",82:\"2a2a9899\",83:\"1c346ca6\",84:\"0c7d1196\",85:\"c81882a6\",86:\"0e95ac27\",87:\"de5d003b\",88:\"5e520d6f\",89:\"6526a9a6\",90:\"dd814856\",91:\"35ea6200\",92:\"f5f95f63\",93:\"b094ff69\",94:\"d025bc87\",95:\"e6cd7cc2\",96:\"ec2f67e7\",135:\"991604b3\",136:\"77548a1c\",137:\"187724fb\",138:\"f5526ffc\",139:\"5d751f87\",140:\"2cf3a967\",141:\"2623c691\",142:\"bf526353\",143:\"53e58be6\",144:\"d96374fc\",145:\"ddab4f00\",146:\"aaa861d2\",147:\"87909d9f\",148:\"62ce2ff3\",149:\"f4ec06fb\",150:\"08e5edc8\",151:\"20a1e5f0\",152:\"428db6be\",153:\"39b8d262\"}[e]+\".chunk.js\"}(e);var m=new Error;f=function(o){s.onerror=s.onload=null,clearTimeout(t);var c=a[e];if(0!==c){if(c){var d=o&&(\"load\"===o.type?\"missing\":o.type),n=o&&o.target&&o.target.src;m.message=\"Loading chunk \"+e+\" failed.\\\\n(\"+d+\": \"+n+\")\",m.name=\"ChunkLoadError\",m.type=d,m.request=n,c[1](m)}a[e]=void 0}};var t=setTimeout((function(){f({type:\"timeout\",target:s})}),12e4);s.onerror=s.onload=f,document.head.appendChild(s)}return Promise.all(o)},r.m=e,r.c=d,r.d=function(e,o,c){r.o(e,o)||Object.defineProperty(e,o,{enumerable:!0,get:c})},r.r=function(e){\"undefined\"!=typeof Symbol&&Symbol.toStringTag&&Object.defineProperty(e,Symbol.toStringTag,{value:\"Module\"}),Object.defineProperty(e,\"__esModule\",{value:!0})},r.t=function(e,o){if(1&o&&(e=r(e)),8&o)return e;if(4&o&&\"object\"==typeof e&&e&&e.__esModule)return e;var c=Object.create(null);if(r.r(c),Object.defineProperty(c,\"default\",{enumerable:!0,value:e}),2&o&&\"string\"!=typeof e)for(var d in e)r.d(c,d,function(o){return e[o]}.bind(null,d));return c},r.n=function(e){var o=e&&e.__esModule?function(){return e.default}:function(){return e};return r.d(o,\"a\",o),o},r.o=function(e,o){return Object.prototype.hasOwnProperty.call(e,o)},r.p=\"/campus/\",r.oe=function(e){throw console.error(e),e};var s=this[\"webpackJsonpcampus-app-v2\"]=this[\"webpackJsonpcampus-app-v2\"]||[],m=s.push.bind(s);s.push=o,s=s.slice();for(var t=0;t<s.length;t++)o(s[t]);var b=m;c()}([])</script><script src=\"/campus/static/js/vendors~main~253ae210.523d3d82.chunk.js\"></script><script src=\"/campus/static/js/vendors~main~0f485567.c868fd6b.chunk.js\"></script><script src=\"/campus/static/js/vendors~main~06694820.44d1436c.chunk.js\"></script><script src=\"/campus/static/js/vendors~main~977b87ed.9d55bb4c.chunk.js\"></script><script src=\"/campus/static/js/vendors~main~ea2ee6ce.7a02ffb4.chunk.js\"></script><script src=\"/campus/static/js/vendors~main~7af1ae76.52983e6d.chunk.js\"></script><script src=\"/campus/static/js/vendors~main~b24a28be.8ab2c38f.chunk.js\"></script><script src=\"/campus/static/js/vendors~main~2374ce8c.6848e79a.chunk.js\"></script><script src=\"/campus/static/js/vendors~main~975751f9.6b6210bf.chunk.js\"></script><script src=\"/campus/static/js/vendors~main~f6d28abc.af7ef5d8.chunk.js\"></script><script src=\"/campus/static/js/vendors~main~89b1000f.d5acdd11.chunk.js\"></script><script src=\"/campus/static/js/vendors~main~a122113c.276d3185.chunk.js\"></script><script src=\"/campus/static/js/vendors~main~ccbc3fde.4aa547a1.chunk.js\"></script><script src=\"/campus/static/js/vendors~main~13f6a649.cf4bb401.chunk.js\"></script><script src=\"/campus/static/js/vendors~main~7274e1de.903d7af6.chunk.js\"></script><script src=\"/campus/static/js/vendors~main~b5906859.004bf36c.chunk.js\"></script><script src=\"/campus/static/js/vendors~main~db300d2f.943f3c0a.chunk.js\"></script><script src=\"/campus/static/js/vendors~main~1f20a385.1f952117.chunk.js\"></script><script src=\"/campus/static/js/vendors~main~7d359b94.9400c848.chunk.js\"></script><script src=\"/campus/static/js/vendors~main~4d01349d.8d40e459.chunk.js\"></script><script src=\"/campus/static/js/vendors~main~d4b3742f.dacf4391.chunk.js\"></script><script src=\"/campus/static/js/vendors~main~690b702c.a5b9fe98.chunk.js\"></script><script src=\"/campus/static/js/vendors~main~2930ad93.aa4320fa.chunk.js\"></script><script src=\"/campus/static/js/vendors~main~bc6b49b0.1f691103.chunk.js\"></script><script src=\"/campus/static/js/vendors~main~9c5b28f6.c2f7398a.chunk.js\"></script><script src=\"/campus/static/js/vendors~main~678f84af.06c24110.chunk.js\"></script><script src=\"/campus/static/js/vendors~main~3f764be9.22d9c230.chunk.js\"></script><script src=\"/campus/static/js/vendors~main~3c941b24.662a3151.chunk.js\"></script><script src=\"/campus/static/js/vendors~main~98431bb7.a234f9ec.chunk.js\"></script><script src=\"/campus/static/js/vendors~main~d51fa4e6.f55bd344.chunk.js\"></script><script src=\"/campus/static/js/vendors~main~f53fef7e.eeddaa80.chunk.js\"></script><script src=\"/campus/static/js/vendors~main~d84fb1a9.6880f18f.chunk.js\"></script><script src=\"/campus/static/js/vendors~main~8e7b4e02.ea628f19.chunk.js\"></script><script src=\"/campus/static/js/vendors~main~33237170.076bc7ed.chunk.js\"></script><script src=\"/campus/static/js/vendors~main~ec8c427e.37e149cf.chunk.js\"></script><script src=\"/campus/static/js/vendors~main~1c3a2c3f.7969310b.chunk.js\"></script><script src=\"/campus/static/js/vendors~main~2900d54e.7cff0633.chunk.js\"></script><script src=\"/campus/static/js/main~748942c6.50d6f7e3.chunk.js\"></script><script src=\"/campus/static/js/main~21833f8f.deeede83.chunk.js\"></script><script src=\"/campus/static/js/main~b553cb79.a5cca2f1.chunk.js\"></script><script src=\"/campus/static/js/main~970f9218.a97caaee.chunk.js\"></script><script src=\"/campus/static/js/main~c714bc7b.f4b170d8.chunk.js\"></script><script src=\"/campus/static/js/main~cc2efef2.e8891ed5.chunk.js\"></script><script>(function(){function c(){var b=a.contentDocument||a.contentWindow.document;if(b){var d=b.createElement(\\'script\\');d.innerHTML=\"window.__CF$cv$params={r:\\'8d1aedbf08b741ae\\',t:\\'MTcyODc3NjM2MC4wMDAwMDA=\\'};var a=document.createElement(\\'script\\');a.nonce=\\'\\';a.src=\\'/cdn-cgi/challenge-platform/scripts/jsd/main.js\\';document.getElementsByTagName(\\'head\\')[0].appendChild(a);\";b.getElementsByTagName(\\'head\\')[0].appendChild(d)}}if(document.body){var a=document.createElement(\\'iframe\\');a.height=1;a.width=1;a.style.position=\\'absolute\\';a.style.top=0;a.style.left=0;a.style.border=\\'none\\';a.style.visibility=\\'hidden\\';document.body.appendChild(a);if(\\'loading\\'!==document.readyState)c();else if(window.addEventListener)document.addEventListener(\\'DOMContentLoaded\\',c);else{var e=document.onreadystatechange||function(){};document.onreadystatechange=function(b){e(b);\\'loading\\'!==document.readyState&&(document.onreadystatechange=e,c())}}}})();</script></body></html>'\n",
            "<!doctype html><html lang=\"en\"><head><meta charset=\"UTF-8\"><link rel=\"apple-touch-icon-precomposed\" sizes=\"57x57\" href=\"/campus/apple-touch-icon-57x57.png\"><link rel=\"apple-touch-icon-precomposed\" sizes=\"114x114\" href=\"/campus/apple-touch-icon-114x114.png\"><link rel=\"apple-touch-icon-precomposed\" sizes=\"72x72\" href=\"/campus/apple-touch-icon-72x72.png\"><link rel=\"apple-touch-icon-precomposed\" sizes=\"144x144\" href=\"/campus/apple-touch-icon-144x144.png\"><link rel=\"apple-touch-icon-precomposed\" sizes=\"60x60\" href=\"/campus/apple-touch-icon-60x60.png\"><link rel=\"apple-touch-icon-precomposed\" sizes=\"120x120\" href=\"/campus/apple-touch-icon-120x120.png\"><link rel=\"apple-touch-icon-precomposed\" sizes=\"76x76\" href=\"/campus/apple-touch-icon-76x76.png\"><link rel=\"apple-touch-icon-precomposed\" sizes=\"152x152\" href=\"/campus/apple-touch-icon-152x152.png\"><link rel=\"icon\" type=\"image/png\" href=\"/campus/favicon.ico\"><link rel=\"icon\" type=\"image/png\" href=\"/campus/favicon-196x196.png\" sizes=\"196x196\"><link rel=\"icon\" type=\"image/png\" href=\"/campus/favicon-96x96.png\" sizes=\"96x96\"><link rel=\"icon\" type=\"image/png\" href=\"/campus/favicon-32x32.png\" sizes=\"32x32\"><link rel=\"icon\" type=\"image/png\" href=\"/campus/favicon-16x16.png\" sizes=\"16x16\"><link rel=\"icon\" type=\"image/png\" href=\"/campus/favicon-128.png\" sizes=\"128x128\"><meta name=\"application-name\" content=\"DataCamp\"><meta name=\"msapplication-TileColor\" content=\"#FFFFFF\"><meta name=\"msapplication-TileImage\" content=\"/campus/mstile-144x144.png\"><meta name=\"msapplication-square70x70logo\" content=\"/campus/mstile-70x70.png\"><meta name=\"msapplication-square150x150logo\" content=\"/campus/mstile-150x150.png\"><meta name=\"msapplication-wide310x150logo\" content=\"/campus/mstile-310x150.png\"><meta name=\"msapplication-square310x310logo\" content=\"/campus/mstile-310x310.png\"><script>!function(n,t,e,r){function a(){return t&&t.now?t.now():null}e.version||(e._events=[],e._errors=[],e._metadata={},e._urlGroup=null,window.RM=e,e.install=function(t){e._options=t;var r=n.createElement(\"script\");r.async=!0,r.crossOrigin=\"anonymous\",r.src=\"https://cdn.requestmetrics.com/agent/current/rm.js\";var a=n.getElementsByTagName(\"script\")[0];a.parentNode.insertBefore(r,a)},e.identify=function(n,t){e._userId=n,e._identifyOptions=t},e.sendEvent=function(n,t){e._events.push({eventName:n,metadata:t,time:a()})},e.setUrlGroup=function(n){e._urlGroup=n},e.track=function(n,t){e._errors.push({error:n,metadata:t,time:a()})},e.addMetadata=function(n){e._metadata=Object.assign(e._metadata,n)})}(document,window.performance,window.RM||{}),window.RM.install({token:\"h4zx2kc:w3sn5gv\"})</script><link href=\"/campus/static/css/vendors~main~977b87ed.cf4b5fcf.chunk.css\" rel=\"stylesheet\"><link href=\"/campus/static/css/vendors~main~1f20a385.ead2d232.chunk.css\" rel=\"stylesheet\"><link href=\"/campus/static/css/vendors~main~678f84af.9b5ca43c.chunk.css\" rel=\"stylesheet\"><link href=\"/campus/static/css/main~c714bc7b.473de2c9.chunk.css\" rel=\"stylesheet\"><title data-react-helmet=\"true\">Importing flat files from the web: your turn! | Python</title><link data-react-helmet=\"true\" rel=\"canonical\" href=\"https://campus.datacamp.com/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1?ex=2\"><link data-react-helmet=\"true\" rel=\"preload\" href=\"https://dcmfe.datacamp.com/assets/fonts/StudioFeixenSansRegular-english-v2.woff2\" as=\"font\" crossorigin=\"anonymous\"><link data-react-helmet=\"true\" rel=\"preload\" href=\"https://dcmfe.datacamp.com/assets/fonts/StudioFeixenSans-Semibold-english.woff2\" as=\"font\" crossorigin=\"anonymous\"><link data-react-helmet=\"true\" rel=\"preload\" href=\"https://dcmfe.datacamp.com/assets/fonts/StudioFeixenSansRegular-latin-v2.woff2\" as=\"font\" crossorigin=\"anonymous\"><link data-react-helmet=\"true\" rel=\"preload\" href=\"https://dcmfe.datacamp.com/assets/fonts/JetBrainsMono-english.woff2\" as=\"font\" crossorigin=\"anonymous\"><link data-react-helmet=\"true\" rel=\"preload\" href=\"https://dcmfe.datacamp.com/assets/fonts/JetBrainsMono-rest.woff2\" as=\"font\" crossorigin=\"anonymous\"><link data-react-helmet=\"true\" rel=\"preconnect\" href=\"https://campus-api.datacamp.com\"><link data-react-helmet=\"true\" rel=\"dns-prefetch\" href=\"https://campus-api.datacamp.com\"><link data-react-helmet=\"true\" rel=\"preconnect\" href=\"https://projector.datacamp.com\"><link data-react-helmet=\"true\" rel=\"dns-prefetch\" href=\"https://projector.datacamp.com\"><link data-react-helmet=\"true\" rel=\"preconnect\" href=\"https://assets.datacamp.com\"><link data-react-helmet=\"true\" rel=\"dns-prefetch\" href=\"https://assets.datacamp.com\"><meta data-react-helmet=\"true\" http-equiv=\"X-UA-Compatible\" content=\"IE=edge,chrome=1\"><meta data-react-helmet=\"true\" name=\"viewport\" content=\"width=device-width, initial-scale=1, maximum-scale=1\"><meta data-react-helmet=\"true\" name=\"fragment\" content=\"!\"><meta data-react-helmet=\"true\" name=\"keywords\" content=\"R, Python, Data analysis, interactive, learning\"><meta data-react-helmet=\"true\" name=\"description\" content=\"Here is an example of Importing flat files from the web: your turn!: You are about to import your first file from the web! The flat file you will import will be &apos;winequality-red.\"><meta data-react-helmet=\"true\" name=\"twitter:card\" content=\"summary\"><meta data-react-helmet=\"true\" name=\"twitter:site\" content=\"@DataCamp\"><meta data-react-helmet=\"true\" name=\"twitter:title\" content=\"Importing flat files from the web: your turn! | Python\"><meta data-react-helmet=\"true\" name=\"twitter:description\" content=\"Here is an example of Importing flat files from the web: your turn!: You are about to import your first file from the web! The flat file you will import will be &apos;winequality-red.\"><meta data-react-helmet=\"true\" name=\"twitter:creator\" content=\"@DataCamp\"><meta data-react-helmet=\"true\" name=\"twitter:image:src\" content=\"/public/assets/images/var/twitter_share.png\"><meta data-react-helmet=\"true\" name=\"twitter:domain\" content=\"www.datacamp.com\"><meta data-react-helmet=\"true\" property=\"og:title\" content=\"Importing flat files from the web: your turn! | Python\"><meta data-react-helmet=\"true\" property=\"og:image\" content=\"/public/assets/images/var/linkedin_share.png\"><meta data-react-helmet=\"true\" name=\"google-signin-clientid\" content=\"892114885437-01a7plbsu1b2vobuhvnckmmanhb58h3a.apps.googleusercontent.com\"><meta data-react-helmet=\"true\" name=\"google-signin-scope\" content=\"email profile\"><meta data-react-helmet=\"true\" name=\"google-signin-cookiepolicy\" content=\"single_host_origin\"><meta content=\"en\" http-equiv=\"content-language\"><link href=\"https://campus.datacamp.com/courses/1606/4135?ex=2\" hreflang=\"x-default\" rel=\"alternate\"><link href=\"https://campus.datacamp.com/courses/1606/4135?ex=2\" hreflang=\"en\" rel=\"alternate\"><link href=\"https://campus.datacamp.com/es/courses/1606/4135?ex=2\" hreflang=\"es\" rel=\"alternate\"><link href=\"https://campus.datacamp.com/pt/courses/1606/4135?ex=2\" hreflang=\"pt\" rel=\"alternate\"><link href=\"https://campus.datacamp.com/de/courses/1606/4135?ex=2\" hreflang=\"de\" rel=\"alternate\"></head><body><script>window.PRELOADED_STATE = \"[&quot;~#iR&quot;,[&quot;^ &quot;,&quot;n&quot;,&quot;StateRecord&quot;,&quot;v&quot;,[&quot;^ &quot;,&quot;backendSession&quot;,[&quot;^ &quot;,&quot;status&quot;,[&quot;^ &quot;,&quot;code&quot;,&quot;none&quot;,&quot;text&quot;,&quot;&quot;],&quot;lastSubmittedCode&quot;,null,&quot;lastSubmittedCommand&quot;,null,&quot;isInitSession&quot;,false,&quot;message&quot;,null,&quot;sessionId&quot;,null],&quot;backendSessionJsonRpc&quot;,[&quot;^ &quot;,&quot;^2&quot;,&quot;initial&quot;],&quot;boot&quot;,[&quot;^0&quot;,[&quot;^ &quot;,&quot;n&quot;,&quot;BootStateRecord&quot;,&quot;v&quot;,[&quot;^ &quot;,&quot;bootState&quot;,&quot;PRE_BOOTED&quot;,&quot;error&quot;,null]]],&quot;chapter&quot;,[&quot;~#iOM&quot;,[&quot;current&quot;,[&quot;^?&quot;,[&quot;badge_uncompleted_url&quot;,&quot;https://assets.datacamp.com/production/default/badges/missing_unc.png&quot;,&quot;number&quot;,1,&quot;number_of_videos&quot;,3,&quot;slug&quot;,&quot;importing-data-from-the-internet-1&quot;,&quot;last_updated_on&quot;,&quot;26/09/2024&quot;,&quot;title_meta&quot;,null,&quot;nb_exercises&quot;,12,&quot;free_preview&quot;,true,&quot;slides_link&quot;,&quot;https://projector-video-pdf-converter.datacamp.com/1606/chapter1.pdf&quot;,&quot;title&quot;,&quot;Importing data from the Internet&quot;,&quot;xp&quot;,1050,&quot;id&quot;,4135,&quot;exercises&quot;,[&quot;~#iL&quot;,[[&quot;^?&quot;,[&quot;type&quot;,&quot;VideoExercise&quot;,&quot;title&quot;,&quot;Importing flat files from the web&quot;,&quot;aggregate_xp&quot;,50,&quot;number&quot;,1,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1?ex=1&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;NormalExercise&quot;,&quot;title&quot;,&quot;Importing flat files from the web: your turn!&quot;,&quot;aggregate_xp&quot;,100,&quot;number&quot;,2,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1?ex=2&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;NormalExercise&quot;,&quot;title&quot;,&quot;Opening and reading flat files from the web&quot;,&quot;aggregate_xp&quot;,100,&quot;number&quot;,3,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1?ex=3&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;NormalExercise&quot;,&quot;title&quot;,&quot;Importing non-flat files from the web&quot;,&quot;aggregate_xp&quot;,100,&quot;number&quot;,4,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1?ex=4&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;VideoExercise&quot;,&quot;title&quot;,&quot;HTTP requests to import files from the web&quot;,&quot;aggregate_xp&quot;,50,&quot;number&quot;,5,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1?ex=5&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;NormalExercise&quot;,&quot;title&quot;,&quot;Performing HTTP requests in Python using urllib&quot;,&quot;aggregate_xp&quot;,100,&quot;number&quot;,6,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1?ex=6&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;NormalExercise&quot;,&quot;title&quot;,&quot;Printing HTTP request results in Python using urllib&quot;,&quot;aggregate_xp&quot;,100,&quot;number&quot;,7,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1?ex=7&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;NormalExercise&quot;,&quot;title&quot;,&quot;Performing HTTP requests in Python using requests&quot;,&quot;aggregate_xp&quot;,100,&quot;number&quot;,8,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1?ex=8&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;VideoExercise&quot;,&quot;title&quot;,&quot;Scraping the web in Python&quot;,&quot;aggregate_xp&quot;,50,&quot;number&quot;,9,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1?ex=9&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;NormalExercise&quot;,&quot;title&quot;,&quot;Parsing HTML with BeautifulSoup&quot;,&quot;aggregate_xp&quot;,100,&quot;number&quot;,10,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1?ex=10&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;NormalExercise&quot;,&quot;title&quot;,&quot;Turning a webpage into data using BeautifulSoup: getting the text&quot;,&quot;aggregate_xp&quot;,100,&quot;number&quot;,11,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1?ex=11&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;NormalExercise&quot;,&quot;title&quot;,&quot;Turning a webpage into data using BeautifulSoup: getting the hyperlinks&quot;,&quot;aggregate_xp&quot;,100,&quot;number&quot;,12,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1?ex=12&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]]]],&quot;description&quot;,&quot;The web is a rich source of data from which you can extract various types of insights and findings. In this chapter, you will learn how to get data from the web, whether it is stored in files or in HTML. You&#39;ll also learn the basics of scraping and parsing web data.&quot;,&quot;badge_completed_url&quot;,&quot;https://assets.datacamp.com/production/default/badges/missing.png&quot;]]]],&quot;codeExplanation&quot;,[&quot;^ &quot;,&quot;^A&quot;,[&quot;^ &quot;,&quot;type&quot;,&quot;initial&quot;]],&quot;contentAuthorization&quot;,[&quot;^ &quot;],&quot;datawarehouseSession&quot;,[&quot;^ &quot;,&quot;^2&quot;,&quot;initial&quot;],&quot;course&quot;,[&quot;^?&quot;,[&quot;difficulty_level&quot;,2,&quot;private_access&quot;,[&quot;^?&quot;,[]],&quot;reduced_outline&quot;,null,&quot;course_resources&quot;,[&quot;^@&quot;,[]],&quot;marketing_video&quot;,&quot;&quot;,&quot;tier&quot;,null,&quot;private&quot;,false,&quot;mobile_enabled&quot;,true,&quot;author_field&quot;,null,&quot;chapters&quot;,[&quot;^@&quot;,[[&quot;^?&quot;,[&quot;badge_uncompleted_url&quot;,&quot;https://assets.datacamp.com/production/default/badges/missing_unc.png&quot;,&quot;number&quot;,1,&quot;number_of_videos&quot;,3,&quot;slug&quot;,&quot;importing-data-from-the-internet-1&quot;,&quot;last_updated_on&quot;,&quot;26/09/2024&quot;,&quot;title_meta&quot;,null,&quot;nb_exercises&quot;,12,&quot;free_preview&quot;,true,&quot;slides_link&quot;,&quot;https://projector-video-pdf-converter.datacamp.com/1606/chapter1.pdf&quot;,&quot;title&quot;,&quot;Importing data from the Internet&quot;,&quot;xp&quot;,1050,&quot;id&quot;,4135,&quot;exercises&quot;,[&quot;^@&quot;,[[&quot;^?&quot;,[&quot;type&quot;,&quot;VideoExercise&quot;,&quot;title&quot;,&quot;Importing flat files from the web&quot;,&quot;aggregate_xp&quot;,50,&quot;number&quot;,1,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1?ex=1&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;NormalExercise&quot;,&quot;title&quot;,&quot;Importing flat files from the web: your turn!&quot;,&quot;aggregate_xp&quot;,100,&quot;number&quot;,2,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1?ex=2&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;NormalExercise&quot;,&quot;title&quot;,&quot;Opening and reading flat files from the web&quot;,&quot;aggregate_xp&quot;,100,&quot;number&quot;,3,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1?ex=3&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;NormalExercise&quot;,&quot;title&quot;,&quot;Importing non-flat files from the web&quot;,&quot;aggregate_xp&quot;,100,&quot;number&quot;,4,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1?ex=4&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;VideoExercise&quot;,&quot;title&quot;,&quot;HTTP requests to import files from the web&quot;,&quot;aggregate_xp&quot;,50,&quot;number&quot;,5,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1?ex=5&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;NormalExercise&quot;,&quot;title&quot;,&quot;Performing HTTP requests in Python using urllib&quot;,&quot;aggregate_xp&quot;,100,&quot;number&quot;,6,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1?ex=6&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;NormalExercise&quot;,&quot;title&quot;,&quot;Printing HTTP request results in Python using urllib&quot;,&quot;aggregate_xp&quot;,100,&quot;number&quot;,7,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1?ex=7&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;NormalExercise&quot;,&quot;title&quot;,&quot;Performing HTTP requests in Python using requests&quot;,&quot;aggregate_xp&quot;,100,&quot;number&quot;,8,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1?ex=8&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;VideoExercise&quot;,&quot;title&quot;,&quot;Scraping the web in Python&quot;,&quot;aggregate_xp&quot;,50,&quot;number&quot;,9,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1?ex=9&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;NormalExercise&quot;,&quot;title&quot;,&quot;Parsing HTML with BeautifulSoup&quot;,&quot;aggregate_xp&quot;,100,&quot;number&quot;,10,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1?ex=10&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;NormalExercise&quot;,&quot;title&quot;,&quot;Turning a webpage into data using BeautifulSoup: getting the text&quot;,&quot;aggregate_xp&quot;,100,&quot;number&quot;,11,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1?ex=11&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;NormalExercise&quot;,&quot;title&quot;,&quot;Turning a webpage into data using BeautifulSoup: getting the hyperlinks&quot;,&quot;aggregate_xp&quot;,100,&quot;number&quot;,12,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1?ex=12&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]]]],&quot;description&quot;,&quot;The web is a rich source of data from which you can extract various types of insights and findings. In this chapter, you will learn how to get data from the web, whether it is stored in files or in HTML. You&#39;ll also learn the basics of scraping and parsing web data.&quot;,&quot;badge_completed_url&quot;,&quot;https://assets.datacamp.com/production/default/badges/missing.png&quot;]],[&quot;^?&quot;,[&quot;badge_uncompleted_url&quot;,&quot;https://assets.datacamp.com/production/default/badges/missing_unc.png&quot;,&quot;number&quot;,2,&quot;number_of_videos&quot;,2,&quot;slug&quot;,&quot;interacting-with-apis-to-import-data-from-the-web-2&quot;,&quot;last_updated_on&quot;,&quot;26/09/2024&quot;,&quot;title_meta&quot;,null,&quot;nb_exercises&quot;,9,&quot;free_preview&quot;,null,&quot;slides_link&quot;,&quot;https://projector-video-pdf-converter.datacamp.com/1606/chapter2.pdf&quot;,&quot;title&quot;,&quot;Interacting with APIs to import data from the web&quot;,&quot;xp&quot;,650,&quot;id&quot;,4136,&quot;exercises&quot;,[&quot;^@&quot;,[[&quot;^?&quot;,[&quot;type&quot;,&quot;VideoExercise&quot;,&quot;title&quot;,&quot;Introduction to APIs and JSONs&quot;,&quot;aggregate_xp&quot;,50,&quot;number&quot;,1,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/interacting-with-apis-to-import-data-from-the-web-2?ex=1&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;PureMultipleChoiceExercise&quot;,&quot;title&quot;,&quot;Pop quiz: What exactly is a JSON?&quot;,&quot;aggregate_xp&quot;,50,&quot;number&quot;,2,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/interacting-with-apis-to-import-data-from-the-web-2?ex=2&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;NormalExercise&quot;,&quot;title&quot;,&quot;Loading and exploring a JSON&quot;,&quot;aggregate_xp&quot;,100,&quot;number&quot;,3,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/interacting-with-apis-to-import-data-from-the-web-2?ex=3&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;MultipleChoiceExercise&quot;,&quot;title&quot;,&quot;Pop quiz: Exploring your JSON&quot;,&quot;aggregate_xp&quot;,50,&quot;number&quot;,4,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/interacting-with-apis-to-import-data-from-the-web-2?ex=4&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;VideoExercise&quot;,&quot;title&quot;,&quot;APIs and interacting with the world wide web&quot;,&quot;aggregate_xp&quot;,50,&quot;number&quot;,5,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/interacting-with-apis-to-import-data-from-the-web-2?ex=5&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;PureMultipleChoiceExercise&quot;,&quot;title&quot;,&quot;Pop quiz: What&#39;s an API?&quot;,&quot;aggregate_xp&quot;,50,&quot;number&quot;,6,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/interacting-with-apis-to-import-data-from-the-web-2?ex=6&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;NormalExercise&quot;,&quot;title&quot;,&quot;API requests&quot;,&quot;aggregate_xp&quot;,100,&quot;number&quot;,7,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/interacting-with-apis-to-import-data-from-the-web-2?ex=7&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;NormalExercise&quot;,&quot;title&quot;,&quot;JSONfrom the web to Python&quot;,&quot;aggregate_xp&quot;,100,&quot;number&quot;,8,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/interacting-with-apis-to-import-data-from-the-web-2?ex=8&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;NormalExercise&quot;,&quot;title&quot;,&quot;Checking out the Wikipedia API&quot;,&quot;aggregate_xp&quot;,100,&quot;number&quot;,9,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/interacting-with-apis-to-import-data-from-the-web-2?ex=9&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]]]],&quot;description&quot;,&quot;In this chapter, you will gain a deeper understanding of how to import data from the web. You will learn the basics of extracting data from APIs, gain insight on the importance of APIs, and practice extracting data by diving into the OMDB and Library of Congress APIs.&quot;,&quot;badge_completed_url&quot;,&quot;https://assets.datacamp.com/production/default/badges/missing.png&quot;]],[&quot;^?&quot;,[&quot;badge_uncompleted_url&quot;,&quot;https://assets.datacamp.com/production/default/badges/missing_unc.png&quot;,&quot;number&quot;,3,&quot;number_of_videos&quot;,2,&quot;slug&quot;,&quot;diving-deep-into-the-twitter-api&quot;,&quot;last_updated_on&quot;,&quot;26/09/2024&quot;,&quot;title_meta&quot;,null,&quot;nb_exercises&quot;,7,&quot;free_preview&quot;,null,&quot;slides_link&quot;,&quot;https://projector-video-pdf-converter.datacamp.com/1606/chapter3.pdf&quot;,&quot;title&quot;,&quot;Diving  deep into the Twitter API&quot;,&quot;xp&quot;,600,&quot;id&quot;,4140,&quot;exercises&quot;,[&quot;^@&quot;,[[&quot;^?&quot;,[&quot;type&quot;,&quot;VideoExercise&quot;,&quot;title&quot;,&quot;The Twitter API and Authentication&quot;,&quot;aggregate_xp&quot;,50,&quot;number&quot;,1,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/diving-deep-into-the-twitter-api?ex=1&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;NormalExercise&quot;,&quot;title&quot;,&quot;Streaming tweets&quot;,&quot;aggregate_xp&quot;,100,&quot;number&quot;,2,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/diving-deep-into-the-twitter-api?ex=2&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;NormalExercise&quot;,&quot;title&quot;,&quot;Load and explore your Twitter data&quot;,&quot;aggregate_xp&quot;,100,&quot;number&quot;,3,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/diving-deep-into-the-twitter-api?ex=3&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;NormalExercise&quot;,&quot;title&quot;,&quot;Twitter data to DataFrame&quot;,&quot;aggregate_xp&quot;,100,&quot;number&quot;,4,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/diving-deep-into-the-twitter-api?ex=4&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;NormalExercise&quot;,&quot;title&quot;,&quot;A little bit of Twitter text analysis&quot;,&quot;aggregate_xp&quot;,100,&quot;number&quot;,5,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/diving-deep-into-the-twitter-api?ex=5&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;NormalExercise&quot;,&quot;title&quot;,&quot;Plotting your Twitter data&quot;,&quot;aggregate_xp&quot;,100,&quot;number&quot;,6,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/diving-deep-into-the-twitter-api?ex=6&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]],[&quot;^?&quot;,[&quot;type&quot;,&quot;VideoExercise&quot;,&quot;title&quot;,&quot;Final Thoughts&quot;,&quot;aggregate_xp&quot;,50,&quot;number&quot;,7,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/diving-deep-into-the-twitter-api?ex=7&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null]]]],&quot;description&quot;,&quot;In this chapter, you will consolidate your knowledge of interacting with APIs in a deep dive into the Twitter streaming API. You&#39;ll learn how to stream real-time Twitter data, and how to analyze and visualize it.&quot;,&quot;badge_completed_url&quot;,&quot;https://assets.datacamp.com/production/default/badges/missing.png&quot;]]]],&quot;time_needed&quot;,null,&quot;author_image&quot;,&quot;https://assets.datacamp.com/production/course_1606/author_images/author_image_course_1606_20200310-1-lgdj4c?1583853939&quot;,&quot;tracks&quot;,[&quot;^@&quot;,[[&quot;^?&quot;,[&quot;path&quot;,&quot;/tracks/data-engineer-in-python&quot;,&quot;title_with_subtitle&quot;,&quot;Data Engineer in Python&quot;]],[&quot;^?&quot;,[&quot;path&quot;,&quot;/tracks/data-scientist-in-python&quot;,&quot;title_with_subtitle&quot;,&quot;Data Scientist in Python&quot;]],[&quot;^?&quot;,[&quot;path&quot;,&quot;/tracks/importing-cleaning-data-with-python&quot;,&quot;title_with_subtitle&quot;,&quot;Importing &amp; Cleaning Data  in Python&quot;]]]],&quot;runtime_config&quot;,null,&quot;lti_only&quot;,false,&quot;image_url&quot;,&quot;https://assets.datacamp.com/production/course_1606/shields/thumb/shield_image_course_1606_20200310-1-17hkmhz?1583853940&quot;,&quot;topic_id&quot;,18,&quot;slug&quot;,&quot;intermediate-importing-data-in-python&quot;,&quot;last_updated_on&quot;,&quot;11/10/2024&quot;,&quot;audio_recorders&quot;,[&quot;^@&quot;,[]],&quot;paid&quot;,true,&quot;collaborators&quot;,[&quot;^@&quot;,[[&quot;^?&quot;,[&quot;avatar_url&quot;,&quot;https://assets.datacamp.com/authors/avatars/000/000/058/square/francis-photo.jpg?1705506690&quot;,&quot;full_name&quot;,&quot;Francisco Castro&quot;]]]],&quot;difficulty_level_hardcoded&quot;,null,&quot;time_needed_in_hours&quot;,2,&quot;technology_id&quot;,2,&quot;university&quot;,null,&quot;archived_at&quot;,null,&quot;state&quot;,&quot;live&quot;,&quot;content_area&quot;,&quot;Data Science and Analytics&quot;,&quot;author_bio&quot;,null,&quot;is_labeled_as_new&quot;,null,&quot;should_cache&quot;,true,&quot;sharing_links&quot;,[&quot;^?&quot;,[&quot;twitter&quot;,&quot;http://bit.ly/1eWTMJh&quot;,&quot;facebook&quot;,&quot;http://bit.ly/1iS42Do&quot;]],&quot;instructors&quot;,[&quot;^@&quot;,[[&quot;^?&quot;,[&quot;id&quot;,301837,&quot;marketing_biography&quot;,&quot;Data Scientist&quot;,&quot;biography&quot;,&quot;Hugo is a data scientist, educator, writer and podcaster formerly at DataCamp. His main interests are promoting data &amp; AI literacy, helping to spread data skills through organizations and society and doing amateur stand up comedy in NYC. If you want to know what he likes to talk about, definitely check out &lt;a href=\\\\&quot;https://www.datacamp.com/community/podcast\\\\&quot;&gt;DataFramed&lt;/a&gt;, the DataCamp podcast, which he hosted and produced.&quot;,&quot;avatar_url&quot;,&quot;https://assets.datacamp.com/authors/avatars/000/000/006/square/hugoaboutpic.jpg?1705506415&quot;,&quot;full_name&quot;,&quot;Hugo Bowne-Anderson&quot;,&quot;instructor_path&quot;,&quot;/instructors/hugobowne&quot;]]]],&quot;translated_course_id&quot;,1606,&quot;seo_title&quot;,&quot;Intermediate Importing Data in Python&quot;,&quot;industry_ids&quot;,[&quot;^@&quot;,[]],&quot;title&quot;,&quot;Intermediate Importing Data in Python&quot;,&quot;xp&quot;,2300,&quot;image_thumbnail_url&quot;,&quot;https://assets.datacamp.com/production/course_1606/shields/thumb_home/shield_image_course_1606_20200310-1-17hkmhz?1583853940&quot;,&quot;short_description&quot;,&quot;Improve your Python data importing skills and learn to work with web and API data.&quot;,&quot;nb_of_subscriptions&quot;,179489,&quot;long_description&quot;,null,&quot;seo_description&quot;,&quot;Learn how to import data into Python from sources like the web and by pulling data from APIs, such as the Twitter streaming API to stream real-time tweets.&quot;,&quot;type&quot;,&quot;datacamp&quot;,&quot;link&quot;,&quot;https://www.datacamp.com/courses/intermediate-importing-data-in-python&quot;,&quot;case_study&quot;,null,&quot;id&quot;,1606,&quot;datasets&quot;,[&quot;^@&quot;,[[&quot;^?&quot;,[&quot;asset_url&quot;,&quot;https://assets.datacamp.com/production/repositories/488/datasets/b422ace2fceada7b569e0ba3e8d833fddc684c4d/latitude.xls&quot;,&quot;name&quot;,&quot;Latitudes (XLS)&quot;]],[&quot;^?&quot;,[&quot;asset_url&quot;,&quot;https://assets.datacamp.com/production/repositories/488/datasets/3ef452f83a91556ea4284624b969392c0506fb33/tweets3.txt&quot;,&quot;name&quot;,&quot;Tweets&quot;]],[&quot;^?&quot;,[&quot;asset_url&quot;,&quot;https://assets.datacamp.com/production/repositories/488/datasets/013936d2700e2d00207ec42100d448c23692eb6f/winequality-red.csv&quot;,&quot;name&quot;,&quot;Red wine quality&quot;]]]],&quot;description&quot;,&quot;As a data scientist, you will need to clean data, wrangle and munge it, visualize it, build predictive models and interpret these models. Before you can do so, however, you will need to know how to get data into Python. In the prequel to this course, you learned many ways to import data into Python: from flat files such as .txt and .csv; from files native to other software such as Excel spreadsheets, Stata, SAS, and MATLAB files; and from relational databases such as SQLite and PostgreSQL. In this course, you&#39;ll extend this knowledge base by learning to import data from the web and by pulling data from Application Programming Interfaces APIssuch as the Twitter streaming API, which allows us to stream real-time tweets.&quot;,&quot;prerequisites&quot;,[&quot;^@&quot;,[[&quot;^?&quot;,[&quot;path&quot;,&quot;/courses/introduction-to-importing-data-in-python&quot;,&quot;title&quot;,&quot;Introduction to Importing Data in Python&quot;]]]],&quot;original_image_url&quot;,&quot;https://assets.datacamp.com/production/course_1606/shields/original/shield_image_course_1606_20200310-1-17hkmhz?1583853940&quot;,&quot;programming_language&quot;,&quot;python&quot;,&quot;external_slug&quot;,&quot;intermediate-importing-data-in-python&quot;]],&quot;exercises&quot;,[&quot;^?&quot;,[&quot;current&quot;,1,&quot;all&quot;,[&quot;^@&quot;,[[&quot;^?&quot;,[&quot;sample_code&quot;,&quot;&quot;,&quot;sct&quot;,&quot;&quot;,&quot;aspect_ratio&quot;,56.25,&quot;instructions&quot;,null,&quot;externalId&quot;,990668,&quot;question&quot;,&quot;&quot;,&quot;hint&quot;,null,&quot;possible_answers&quot;,[&quot;^@&quot;,[]],&quot;runtime_config&quot;,null,&quot;number&quot;,1,&quot;video_hls&quot;,null,&quot;randomNumber&quot;,0.8364573381546423,&quot;chapter_id&quot;,4135,&quot;assignment&quot;,null,&quot;feedbacks&quot;,[&quot;^@&quot;,[]],&quot;attachments&quot;,null,&quot;exercise_image&quot;,null,&quot;version&quot;,&quot;v0&quot;,&quot;title&quot;,&quot;Importing flat files from the web&quot;,&quot;xp&quot;,50,&quot;language&quot;,&quot;python&quot;,&quot;pre_exercise_code&quot;,&quot;&quot;,&quot;solution&quot;,&quot;&quot;,&quot;type&quot;,&quot;VideoExercise&quot;,&quot;id&quot;,990668,&quot;projector_key&quot;,&quot;course_1606_59604c018a6e132016cd26144a12fee0&quot;,&quot;video_link&quot;,null,&quot;programming_language&quot;,null,&quot;key&quot;,&quot;e36457c7ed&quot;,&quot;course_id&quot;,1606]],[&quot;^?&quot;,[&quot;sample_code&quot;,&quot;# Import package\\\\nfrom ____ import ____\\\\n\\\\n# Import pandas\\\\nimport pandas as pd\\\\n\\\\n# Assign url of file: url\\\\n\\\\n\\\\n# Save file locally\\\\n\\\\n\\\\n# Read file into a DataFrame and print its head\\\\ndf = pd.read_csv(&#39;winequality-red.csv&#39;, sep=&#39;;&#39;)\\\\nprint(df.head())&quot;,&quot;sct&quot;,&quot;Ex().has_import(\\\\&quot;urllib.request.urlretrieve\\\\&quot;)\\\\nEx().has_import(\\\\&quot;pandas\\\\&quot;)\\\\nEx().check_object(\\\\&quot;url\\\\&quot;).has_equal_value()\\\\nEx().check_function(\\\\&quot;urllib.request.urlretrieve\\\\&quot;).multi(\\\\n  check_args(0).has_equal_value(),\\\\n  check_args(1).has_equal_value()\\\\n)\\\\nEx().check_correct(\\\\n  check_object(\\\\&quot;df\\\\&quot;).has_equal_value(),\\\\n  check_function(\\\\&quot;pandas.read_csv\\\\&quot;).multi(\\\\n    check_args(0).has_equal_value(),\\\\n    check_args(1).has_equal_value()\\\\n  )\\\\n)\\\\nEx().has_printout(0)\\\\nsuccess_msg(\\\\&quot;Awesome!\\\\&quot;)\\\\n&quot;,&quot;instructions&quot;,&quot;&lt;ul&gt;\\\\n&lt;li&gt;Import the function &lt;code&gt;urlretrieve&lt;/code&gt; from the subpackage &lt;code&gt;urllib.request&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;li&gt;Assign the URL of the file to the variable &lt;code&gt;url&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;li&gt;Use the function &lt;code&gt;urlretrieve()&lt;/code&gt; to save the file locally as &lt;code&gt;&#39;winequality-red.csv&#39;&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;li&gt;Execute the remaining code to load &lt;code&gt;&#39;winequality-red.csv&#39;&lt;/code&gt; in a pandas DataFrame and to print its head to the shell.&lt;/li&gt;\\\\n&lt;/ul&gt;&quot;,&quot;externalId&quot;,42707,&quot;question&quot;,&quot;&quot;,&quot;hint&quot;,&quot;&lt;ul&gt;\\\\n&lt;li&gt;To import a function &lt;code&gt;y&lt;/code&gt; from a subpackage &lt;code&gt;x&lt;/code&gt;, execute &lt;code&gt;from x import y&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;li&gt;This one&#39;s a long URL. Make sure you typed it in correctly!&lt;/li&gt;\\\\n&lt;li&gt;Pass the &lt;em&gt;url&lt;/em&gt; to import (in the &lt;code&gt;url&lt;/code&gt; object you defined) as the first argument and the &lt;em&gt;filename&lt;/em&gt; for saving the file locally as the second argument to &lt;code&gt;urlretrieve()&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;li&gt;You don&#39;t have to change the code for loading &lt;code&gt;&#39;winequality-red.csv&#39;&lt;/code&gt; and printing its head.&lt;/li&gt;\\\\n&lt;/ul&gt;&quot;,&quot;possible_answers&quot;,[&quot;^@&quot;,[]],&quot;runtime_config&quot;,null,&quot;number&quot;,2,&quot;user&quot;,[&quot;^?&quot;,[&quot;isHintShown&quot;,false,&quot;usedAiFeatures&quot;,[&quot;^?&quot;,[&quot;aiIncorrectSubmissions&quot;,false,&quot;aiErrorExplanations&quot;,false]],&quot;lastRunCode&quot;,null,&quot;editorTabs&quot;,[&quot;^?&quot;,[&quot;files/script.py&quot;,[&quot;^?&quot;,[&quot;title&quot;,&quot;script.py&quot;,&quot;isSolution&quot;,false,&quot;props&quot;,[&quot;^?&quot;,[&quot;active&quot;,true,&quot;isClosable&quot;,false,&quot;code&quot;,null,&quot;extra&quot;,[&quot;^?&quot;,[]]]]]]]],&quot;outputMarkdownTabs&quot;,[&quot;^?&quot;,[]],&quot;markdown&quot;,[&quot;^?&quot;,[&quot;titles&quot;,[&quot;^@&quot;,[&quot;Knit PDF&quot;,&quot;Knit HTML&quot;]],&quot;activeTitle&quot;,&quot;Knit HTML&quot;]],&quot;currentXp&quot;,100,&quot;graphicalTabs&quot;,[&quot;^?&quot;,[&quot;plot&quot;,[&quot;^?&quot;,[&quot;extraClass&quot;,&quot;animation--flash&quot;,&quot;title&quot;,&quot;Plots&quot;,&quot;props&quot;,[&quot;^?&quot;,[&quot;sources&quot;,[&quot;^@&quot;,[]],&quot;currentIndex&quot;,0]],&quot;dimension&quot;,[&quot;^?&quot;,[&quot;isRealSize&quot;,false,&quot;width&quot;,1,&quot;height&quot;,1]]]],&quot;html&quot;,[&quot;^?&quot;,[&quot;extraClass&quot;,&quot;animation--flash&quot;,&quot;title&quot;,&quot;HTML Viewer&quot;,&quot;props&quot;,[&quot;^?&quot;,[&quot;sources&quot;,[&quot;^@&quot;,[]],&quot;currentIndex&quot;,0]]]]]],&quot;feedbackMessages&quot;,[&quot;^@&quot;,[]],&quot;lastSubmittedCode&quot;,null,&quot;ltiStatus&quot;,[&quot;^?&quot;,[]],&quot;lastSubmitActiveEditorTab&quot;,null,&quot;consoleSqlTabs&quot;,[&quot;^?&quot;,[&quot;query_result&quot;,[&quot;^?&quot;,[&quot;extraClass&quot;,&quot;&quot;,&quot;title&quot;,&quot;query result&quot;,&quot;props&quot;,[&quot;^?&quot;,[&quot;active&quot;,true,&quot;isNotView&quot;,true,&quot;message&quot;,&quot;No query executed yet...&quot;]]]]]],&quot;consoleTabs&quot;,[&quot;^?&quot;,[&quot;console&quot;,[&quot;^?&quot;,[&quot;title&quot;,&quot;IPython Shell&quot;,&quot;props&quot;,[&quot;^?&quot;,[&quot;active&quot;,true]],&quot;dimension&quot;,[&quot;^?&quot;,[&quot;cols&quot;,400]]]],&quot;slides&quot;,[&quot;^?&quot;,[&quot;title&quot;,&quot;Slides&quot;,&quot;props&quot;,[&quot;^?&quot;,[&quot;active&quot;,false]]]]]],&quot;inputMarkdownTabs&quot;,[&quot;^?&quot;,[]],&quot;consoleObjectViewTabs&quot;,[&quot;^?&quot;,[]]]],&quot;randomNumber&quot;,0.13306885324133644,&quot;assignment&quot;,&quot;&lt;p&gt;You are about to import your first file from the web! The flat file you will import will be &lt;code&gt;&#39;winequality-red.csv&#39;&lt;/code&gt; from the University of California, Irvine&#39;s &lt;a href=\\\\&quot;https://archive.ics.uci.edu/ml/index.php\\\\&quot;&gt;Machine Learning repository&lt;/a&gt;. The flat file contains tabular data of physiochemical properties of red wine, such as pH, alcohol content and citric acid content, along with wine quality rating.&lt;/p&gt;\\\\n&lt;p&gt;The URL of the file is&lt;/p&gt;\\\\n&lt;pre&gt;&lt;code&gt;&#39;https://assets.datacamp.com/production/course_1606/datasets/winequality-red.csv&#39;\\\\n&lt;/code&gt;&lt;/pre&gt;\\\\n&lt;p&gt;After you import it, you&#39;ll check your working directory to confirm that it is there and then you&#39;ll load it into a &lt;code&gt;pandas&lt;/code&gt; DataFrame.&lt;/p&gt;&quot;,&quot;feedbacks&quot;,[&quot;^@&quot;,[]],&quot;attachments&quot;,null,&quot;exercise_image&quot;,null,&quot;title&quot;,&quot;Importing flat files from the web: your turn!&quot;,&quot;xp&quot;,100,&quot;language&quot;,&quot;python&quot;,&quot;pre_exercise_code&quot;,&quot;&quot;,&quot;solution&quot;,&quot;# Import package\\\\nfrom urllib.request import urlretrieve\\\\n\\\\n# Import pandas\\\\nimport pandas as pd\\\\n\\\\n# Assign url of file: url\\\\nurl = &#39;https://assets.datacamp.com/production/course_1606/datasets/winequality-red.csv&#39;\\\\n\\\\n# Save file locally\\\\nurlretrieve(url, &#39;winequality-red.csv&#39;)\\\\n\\\\n# Read file into a DataFrame and print its head\\\\ndf = pd.read_csv(&#39;winequality-red.csv&#39;, sep=&#39;;&#39;)\\\\nprint(df.head())&quot;,&quot;type&quot;,&quot;NormalExercise&quot;,&quot;id&quot;,42707,&quot;programming_language&quot;,null]],[&quot;^?&quot;,[&quot;sample_code&quot;,&quot;# Import packages\\\\nimport matplotlib.pyplot as plt\\\\nimport pandas as pd\\\\n\\\\n# Assign url of file: url\\\\n\\\\n\\\\n# Read file into a DataFrame: df\\\\n\\\\n\\\\n# Print the head of the DataFrame\\\\nprint(____)\\\\n\\\\n# Plot first column of df\\\\ndf.iloc[:, 0].hist()\\\\nplt.xlabel(&#39;fixed acidity (g(tartaric acid)/dm$^3$)&#39;)\\\\nplt.ylabel(&#39;count&#39;)\\\\nplt.show()\\\\n&quot;,&quot;sct&quot;,&quot;Ex().has_import(\\\\&quot;matplotlib.pyplot\\\\&quot;)\\\\nEx().has_import(\\\\&quot;pandas\\\\&quot;)\\\\nEx().check_object(\\\\&quot;url\\\\&quot;).has_equal_value()\\\\nEx().check_correct(\\\\n  check_object(\\\\&quot;df\\\\&quot;).has_equal_value(),\\\\n  check_function(\\\\&quot;pandas.read_csv\\\\&quot;).multi(\\\\n    check_args(0).has_equal_value(),\\\\n    check_args(1).has_equal_value()\\\\n  )\\\\n)\\\\nEx().has_printout(0)\\\\nEx().has_equal_ast(code=\\\\&quot;df.iloc[:, 0].hist\\\\&quot;, incorrect_msg=\\\\&quot;Please do not change the code to plot the histogram.\\\\&quot;)\\\\nEx().check_function(\\\\&quot;matplotlib.pyplot.show\\\\&quot;)\\\\n\\\\nsuccess_msg(\\\\&quot;Awesome!\\\\&quot;)\\\\n&quot;,&quot;instructions&quot;,&quot;&lt;ul&gt;\\\\n&lt;li&gt;Assign the URL of the file to the variable &lt;code&gt;url&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;li&gt;Read file into a DataFrame &lt;code&gt;df&lt;/code&gt; using &lt;code&gt;pd.read_csv()&lt;/code&gt;, recalling that the separator in the file is &lt;code&gt;&#39;;&#39;&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;li&gt;Print the head of the DataFrame &lt;code&gt;df&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;li&gt;Execute the rest of the code to plot histogram of the first feature in the DataFrame &lt;code&gt;df&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;/ul&gt;&quot;,&quot;externalId&quot;,42708,&quot;question&quot;,&quot;&quot;,&quot;hint&quot;,&quot;&lt;ul&gt;\\\\n&lt;li&gt;Make sure you typed the URL correctly!&lt;/li&gt;\\\\n&lt;li&gt;Pass the &lt;em&gt;url&lt;/em&gt; (the &lt;code&gt;url&lt;/code&gt; object you defined) as the first argument and the &lt;em&gt;separator&lt;/em&gt; as the second argument to &lt;code&gt;pd.read_csv()&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;li&gt;The &lt;em&gt;head&lt;/em&gt; of a DataFrame can be accessed by using &lt;code&gt;head()&lt;/code&gt; on the DataFrame.&lt;/li&gt;\\\\n&lt;li&gt;You don&#39;t have to change any of the code for plotting the histograms.&lt;/li&gt;\\\\n&lt;/ul&gt;&quot;,&quot;possible_answers&quot;,[&quot;^@&quot;,[]],&quot;runtime_config&quot;,null,&quot;number&quot;,3,&quot;randomNumber&quot;,0.7785533906387767,&quot;assignment&quot;,&quot;&lt;p&gt;You have just imported a file from the web, saved it locally and loaded it into a DataFrame. If you just wanted to load a file from the web into a DataFrame without first saving it locally, you can do that easily using &lt;code&gt;pandas&lt;/code&gt;. In particular, you can use the function &lt;code&gt;pd.read_csv()&lt;/code&gt; with the URL as the first argument and the separator &lt;code&gt;sep&lt;/code&gt; as the second argument.&lt;/p&gt;\\\\n&lt;p&gt;The URL of the file, once again, is&lt;/p&gt;\\\\n&lt;pre&gt;&lt;code&gt;&#39;https://assets.datacamp.com/production/course_1606/datasets/winequality-red.csv&#39;\\\\n&lt;/code&gt;&lt;/pre&gt;&quot;,&quot;feedbacks&quot;,[&quot;^@&quot;,[]],&quot;attachments&quot;,null,&quot;exercise_image&quot;,null,&quot;title&quot;,&quot;Opening and reading flat files from the web&quot;,&quot;xp&quot;,100,&quot;language&quot;,&quot;python&quot;,&quot;pre_exercise_code&quot;,&quot;&quot;,&quot;solution&quot;,&quot;# Import packages\\\\nimport matplotlib.pyplot as plt\\\\nimport pandas as pd\\\\n\\\\n# Assign url of file: url\\\\nurl = &#39;https://assets.datacamp.com/production/course_1606/datasets/winequality-red.csv&#39;\\\\n\\\\n# Read file into a DataFrame: df\\\\ndf = pd.read_csv(url, sep=&#39;;&#39;)\\\\n\\\\n# Print the head of the DataFrame\\\\nprint(df.head())\\\\n\\\\n# Plot first column of df\\\\ndf.iloc[:, 0].hist()\\\\nplt.xlabel(&#39;fixed acidity (g(tartaric acid)/dm$^3$)&#39;)\\\\nplt.ylabel(&#39;count&#39;)\\\\nplt.show()\\\\n&quot;,&quot;type&quot;,&quot;NormalExercise&quot;,&quot;id&quot;,42708,&quot;programming_language&quot;,null]],[&quot;^?&quot;,[&quot;sample_code&quot;,&quot;# Import package\\\\nimport pandas as pd\\\\n\\\\n# Assign url of file: url\\\\n\\\\n\\\\n# Read in all sheets of Excel file: xls\\\\n\\\\n\\\\n# Print the sheetnames to the shell\\\\n\\\\n\\\\n# Print the head of the first sheet (using its name, NOT its index)\\\\n\\\\n&quot;,&quot;sct&quot;,&quot;Ex().has_import(&#39;pandas&#39;)\\\\nEx().check_correct(\\\\n    has_printout(0),\\\\n    multi(\\\\n        check_correct(\\\\n            check_object(&#39;xls&#39;).is_instance(dict),\\\\n            check_correct(\\\\n                check_function(&#39;pandas.read_excel&#39;).multi(\\\\n                    check_args(0).has_equal_value(),\\\\n                    check_args(&#39;sheet_name&#39;).has_equal_value()\\\\n                ),\\\\n                check_object(&#39;url&#39;).has_equal_value()\\\\n            )\\\\n        )\\\\n    )\\\\n)\\\\nEx().has_printout(1)\\\\nsuccess_msg(\\\\&quot;Awesome!\\\\&quot;)&quot;,&quot;instructions&quot;,&quot;&lt;ul&gt;\\\\n&lt;li&gt;Assign the URL of the file to the variable &lt;code&gt;url&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;li&gt;Read the file in &lt;code&gt;url&lt;/code&gt; into a dictionary &lt;code&gt;xls&lt;/code&gt; using &lt;code&gt;pd.read_excel()&lt;/code&gt; recalling that, in order to import all sheets you need to pass &lt;code&gt;None&lt;/code&gt; to the argument &lt;code&gt;sheet_name&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;li&gt;Print the names of the sheets in the Excel spreadsheet; these will be the keys of the dictionary &lt;code&gt;xls&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;li&gt;Print the head of the first sheet &lt;em&gt;using the sheet name, not the index of the sheet&lt;/em&gt;! The sheet name is &lt;code&gt;&#39;1700&#39;&lt;/code&gt;&lt;/li&gt;\\\\n&lt;/ul&gt;&quot;,&quot;externalId&quot;,42709,&quot;question&quot;,&quot;&quot;,&quot;hint&quot;,&quot;&lt;ul&gt;\\\\n&lt;li&gt;Make sure you typed in the URL correctly!&lt;/li&gt;\\\\n&lt;li&gt;Pass the &lt;em&gt;url&lt;/em&gt; (the &lt;code&gt;url&lt;/code&gt; object you defined) as the first argument and &lt;code&gt;sheet_name&lt;/code&gt; with its corresponding value as the second argument to &lt;code&gt;pd.read_excel()&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;li&gt;The &lt;em&gt;keys&lt;/em&gt; of a dictionary can be accessed by using &lt;code&gt;keys()&lt;/code&gt; on the dictionary.&lt;/li&gt;\\\\n&lt;li&gt;You can access a sheet using the format: &lt;em&gt;dictionary&lt;/em&gt;&lt;strong&gt;[&lt;/strong&gt;&lt;em&gt;sheet name or index&lt;/em&gt;&lt;strong&gt;]&lt;/strong&gt;.&lt;/li&gt;\\\\n&lt;/ul&gt;&quot;,&quot;possible_answers&quot;,[&quot;^@&quot;,[]],&quot;runtime_config&quot;,null,&quot;number&quot;,4,&quot;randomNumber&quot;,0.29677029636305896,&quot;assignment&quot;,&quot;&lt;p&gt;Congrats! You&#39;ve just loaded a flat file from the web into a DataFrame without first saving it locally using the &lt;code&gt;pandas&lt;/code&gt; function &lt;code&gt;pd.read_csv()&lt;/code&gt;. This function is super cool because it has close relatives that allow you to load all types of files, not only flat ones. In this interactive exercise, you&#39;ll use &lt;code&gt;pd.read_excel()&lt;/code&gt; to import an Excel spreadsheet.&lt;/p&gt;\\\\n&lt;p&gt;The URL of the spreadsheet is&lt;/p&gt;\\\\n&lt;pre&gt;&lt;code&gt;&#39;https://assets.datacamp.com/course/importing_data_into_r/latitude.xls&#39;\\\\n&lt;/code&gt;&lt;/pre&gt;\\\\n&lt;p&gt;Your job is to use &lt;code&gt;pd.read_excel()&lt;/code&gt; to read in all of its sheets, print the sheet names and then print the head of the first sheet &lt;em&gt;using its name, not its index&lt;/em&gt;.&lt;/p&gt;\\\\n&lt;p&gt;Note that the output of &lt;code&gt;pd.read_excel()&lt;/code&gt; is a Python dictionary with sheet names as keys and corresponding DataFrames as corresponding values.&lt;/p&gt;&quot;,&quot;feedbacks&quot;,[&quot;^@&quot;,[]],&quot;attachments&quot;,null,&quot;exercise_image&quot;,null,&quot;title&quot;,&quot;Importing non-flat files from the web&quot;,&quot;xp&quot;,100,&quot;language&quot;,&quot;python&quot;,&quot;pre_exercise_code&quot;,&quot;&quot;,&quot;solution&quot;,&quot;# Import package\\\\nimport pandas as pd\\\\n\\\\n# Assign url of file: url\\\\nurl = &#39;https://assets.datacamp.com/course/importing_data_into_r/latitude.xls&#39;\\\\n\\\\n# Read in all sheets of Excel file: xls\\\\nxls = pd.read_excel(url, sheet_name=None)\\\\n\\\\n# Print the sheetnames to the shell\\\\nprint(xls.keys())\\\\n\\\\n# Print the head of the first sheet (using its name, NOT its index)\\\\nprint(xls[&#39;1700&#39;].head())&quot;,&quot;type&quot;,&quot;NormalExercise&quot;,&quot;id&quot;,42709,&quot;programming_language&quot;,null]],[&quot;^?&quot;,[&quot;sample_code&quot;,&quot;&quot;,&quot;sct&quot;,&quot;&quot;,&quot;aspect_ratio&quot;,56.25,&quot;instructions&quot;,null,&quot;externalId&quot;,990669,&quot;question&quot;,&quot;&quot;,&quot;hint&quot;,null,&quot;possible_answers&quot;,[&quot;^@&quot;,[]],&quot;runtime_config&quot;,null,&quot;number&quot;,5,&quot;video_hls&quot;,null,&quot;randomNumber&quot;,0.08513839239732768,&quot;chapter_id&quot;,4135,&quot;assignment&quot;,null,&quot;feedbacks&quot;,[&quot;^@&quot;,[]],&quot;attachments&quot;,null,&quot;exercise_image&quot;,null,&quot;version&quot;,&quot;v0&quot;,&quot;title&quot;,&quot;HTTP requests to import files from the web&quot;,&quot;xp&quot;,50,&quot;language&quot;,&quot;python&quot;,&quot;pre_exercise_code&quot;,&quot;&quot;,&quot;solution&quot;,&quot;&quot;,&quot;type&quot;,&quot;VideoExercise&quot;,&quot;id&quot;,990669,&quot;projector_key&quot;,&quot;course_1606_9d15ae176be1800b996f7869a82b8087&quot;,&quot;video_link&quot;,null,&quot;programming_language&quot;,null,&quot;key&quot;,&quot;e480d1fdcf&quot;,&quot;course_id&quot;,1606]],[&quot;^?&quot;,[&quot;sample_code&quot;,&quot;# Import packages\\\\n\\\\n\\\\n# Specify the url\\\\nurl = \\\\&quot;https://campus.datacamp.com/courses/1606/4135?ex=2\\\\&quot;\\\\n\\\\n# This packages the request: request\\\\n\\\\n\\\\n# Sends the request and catches the response: response\\\\n\\\\n\\\\n# Print the datatype of response\\\\nprint(type(response))\\\\n\\\\n# Be polite and close the response!\\\\nresponse.close()\\\\n&quot;,&quot;sct&quot;,&quot;\\\\n# Test: import urlopen, Request\\\\nimport_msg = \\\\&quot;Did you correctly import the required packages?\\\\&quot;\\\\nEx().has_import(\\\\n    \\\\&quot;urllib.request.urlopen\\\\&quot;,\\\\n    not_imported_msg=import_msg\\\\n)\\\\nEx().has_import(\\\\n    \\\\&quot;urllib.request.Request\\\\&quot;,\\\\n    not_imported_msg=import_msg\\\\n)\\\\n\\\\n# Test: Predefined code\\\\npredef_msg = \\\\&quot;You don&#39;t have to change any of the predefined code.\\\\&quot;\\\\nEx().check_object(\\\\&quot;url\\\\&quot;, missing_msg=predef_msg).has_equal_value(incorrect_msg = predef_msg)\\\\n\\\\n# Test: call to Request() and &#39;request&#39; variable\\\\nEx().check_function(\\\\&quot;urllib.request.Request\\\\&quot;).check_args(0).has_equal_value()\\\\nEx().check_object(\\\\&quot;request\\\\&quot;)\\\\n  \\\\n# Test: call to urlopen() and &#39;response&#39; variable\\\\nEx().check_function(\\\\&quot;urllib.request.urlopen\\\\&quot;).check_args(0).has_equal_ast()\\\\nEx().check_object(\\\\&quot;response\\\\&quot;),\\\\n\\\\n# Test: Predefined code\\\\nEx().has_printout(0)\\\\nEx().check_function(\\\\&quot;response.close\\\\&quot;)\\\\n\\\\nsuccess_msg(\\\\&quot;Awesome!\\\\&quot;)\\\\n&quot;,&quot;instructions&quot;,&quot;&lt;ul&gt;\\\\n&lt;li&gt;Import the functions &lt;code&gt;urlopen&lt;/code&gt; and &lt;code&gt;Request&lt;/code&gt; from the subpackage &lt;code&gt;urllib.request&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;li&gt;Package the request to the url &lt;code&gt;\\\\&quot;https://campus.datacamp.com/courses/1606/4135?ex=2\\\\&quot;&lt;/code&gt; using the function &lt;code&gt;Request()&lt;/code&gt; and assign it to &lt;code&gt;request&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;li&gt;Send the request and catch the response in the variable &lt;code&gt;response&lt;/code&gt; with  the function &lt;code&gt;urlopen()&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;li&gt;Run the rest of the code to see the datatype of &lt;code&gt;response&lt;/code&gt; and to close the connection!&lt;/li&gt;\\\\n&lt;/ul&gt;&quot;,&quot;externalId&quot;,42711,&quot;question&quot;,&quot;&quot;,&quot;hint&quot;,&quot;&lt;ul&gt;\\\\n&lt;li&gt;To import two functions in one line, import the first function as usual and add a comma &lt;code&gt;,&lt;/code&gt; followed by the second function.&lt;/li&gt;\\\\n&lt;li&gt;Pass the &lt;em&gt;url&lt;/em&gt; (already in the &lt;code&gt;url&lt;/code&gt; object defined) as an argument to &lt;code&gt;Request()&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;li&gt;Pass &lt;code&gt;request&lt;/code&gt; as an argument to &lt;code&gt;urlopen()&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;li&gt;You don&#39;t have to modify the code for printing the datatype of &lt;code&gt;response&lt;/code&gt; and closing the connection.&lt;/li&gt;\\\\n&lt;/ul&gt;&quot;,&quot;possible_answers&quot;,[&quot;^@&quot;,[]],&quot;runtime_config&quot;,null,&quot;number&quot;,6,&quot;randomNumber&quot;,0.025167267893165146,&quot;assignment&quot;,&quot;&lt;p&gt;Now that you know the basics behind HTTP GET requests, it&#39;s time to perform some of your own. In this interactive exercise, you will ping our very own DataCamp servers to perform a GET request to extract information from the first coding exercise of this course, &lt;code&gt;\\\\&quot;https://campus.datacamp.com/courses/1606/4135?ex=2\\\\&quot;&lt;/code&gt;.&lt;/p&gt;\\\\n&lt;p&gt;In the next exercise, you&#39;ll extract the HTML itself. Right now, however, you are going to package and send the request and then catch the response.&lt;/p&gt;&quot;,&quot;feedbacks&quot;,[&quot;^@&quot;,[]],&quot;attachments&quot;,null,&quot;exercise_image&quot;,null,&quot;title&quot;,&quot;Performing HTTP requests in Python using urllib&quot;,&quot;xp&quot;,100,&quot;language&quot;,&quot;python&quot;,&quot;pre_exercise_code&quot;,&quot;&quot;,&quot;solution&quot;,&quot;# Import packages\\\\nfrom urllib.request import urlopen, Request\\\\n\\\\n# Specify the url\\\\nurl = \\\\&quot;https://campus.datacamp.com/courses/1606/4135?ex=2\\\\&quot;\\\\n\\\\n# This packages the request: request\\\\nrequest = Request(url)\\\\n\\\\n# Sends the request and catches the response: response\\\\nresponse = urlopen(request)\\\\n\\\\n# Print the datatype of response\\\\nprint(type(response))\\\\n\\\\n# Be polite and close the response!\\\\nresponse.close()\\\\n&quot;,&quot;type&quot;,&quot;NormalExercise&quot;,&quot;id&quot;,42711,&quot;programming_language&quot;,null]],[&quot;^?&quot;,[&quot;sample_code&quot;,&quot;# Import packages\\\\nfrom urllib.request import urlopen, Request\\\\n\\\\n# Specify the url\\\\nurl = \\\\&quot;https://campus.datacamp.com/courses/1606/4135?ex=2\\\\&quot;\\\\n\\\\n# This packages the request\\\\nrequest = Request(url)\\\\n\\\\n# Sends the request and catches the response: response\\\\n\\\\n\\\\n# Extract the response: html\\\\n\\\\n\\\\n# Print the html\\\\n\\\\n\\\\n# Be polite and close the response!\\\\nresponse.close()&quot;,&quot;sct&quot;,&quot;\\\\n# Test: Predefined code\\\\npredef_msg = \\\\&quot;You don&#39;t have to change any of the predefined code.\\\\&quot;\\\\nEx().has_import(\\\\n    \\\\&quot;urllib.request.urlopen\\\\&quot;,\\\\n    not_imported_msg=predef_msg\\\\n)\\\\n\\\\nEx().has_import(\\\\n    \\\\&quot;urllib.request.Request\\\\&quot;,\\\\n    not_imported_msg=predef_msg\\\\n)\\\\n\\\\nEx().check_object(\\\\&quot;url\\\\&quot;).has_equal_value()\\\\n\\\\n# Test: call to Request() and &#39;request&#39; variable\\\\nEx().check_function(\\\\&quot;urllib.request.Request\\\\&quot;).check_args(0).has_equal_value()\\\\nEx().check_object(\\\\&quot;request\\\\&quot;)\\\\n\\\\n# Test: call to urlopen() and &#39;response&#39; variable\\\\nEx().check_function(\\\\&quot;urllib.request.urlopen\\\\&quot;).check_args(0).has_equal_ast()\\\\nEx().check_object(\\\\&quot;response\\\\&quot;)\\\\n\\\\n# Test: call to urlopen() and &#39;response&#39; variable\\\\nEx().check_function(\\\\&quot;response.read\\\\&quot;)\\\\nEx().check_object(\\\\&quot;html\\\\&quot;)\\\\n\\\\n# Test: call to print()\\\\nEx().check_function(&#39;print&#39;).check_args(0).has_equal_ast()\\\\n\\\\n# Test: Predefined code\\\\nEx().check_function(\\\\&quot;response.close\\\\&quot;)\\\\n\\\\nsuccess_msg(\\\\&quot;Awesome!\\\\&quot;)\\\\n&quot;,&quot;instructions&quot;,&quot;&lt;ul&gt;\\\\n&lt;li&gt;Send the request and catch the response in the variable &lt;code&gt;response&lt;/code&gt; with the function &lt;code&gt;urlopen()&lt;/code&gt;, as in the previous exercise.&lt;/li&gt;\\\\n&lt;li&gt;Extract the response using the &lt;code&gt;read()&lt;/code&gt; method and store the result in the variable &lt;code&gt;html&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;li&gt;Print the string &lt;code&gt;html&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;li&gt;Hit submit to perform all of the above and to close the response: be tidy!&lt;/li&gt;\\\\n&lt;/ul&gt;&quot;,&quot;externalId&quot;,42712,&quot;question&quot;,&quot;&quot;,&quot;hint&quot;,&quot;&lt;ul&gt;\\\\n&lt;li&gt;Pass &lt;code&gt;request&lt;/code&gt; as an argument to &lt;code&gt;urlopen()&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;li&gt;Apply the method &lt;code&gt;read()&lt;/code&gt; to the response object &lt;code&gt;response&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;li&gt;Simply pass &lt;code&gt;html&lt;/code&gt; to the &lt;code&gt;print()&lt;/code&gt; function.&lt;/li&gt;\\\\n&lt;li&gt;You don&#39;t have to modify the code for closing the response.&lt;/li&gt;\\\\n&lt;/ul&gt;&quot;,&quot;possible_answers&quot;,[&quot;^@&quot;,[]],&quot;runtime_config&quot;,null,&quot;number&quot;,7,&quot;randomNumber&quot;,0.8963620619853123,&quot;assignment&quot;,&quot;&lt;p&gt;You have just packaged and sent a GET request to &lt;code&gt;\\\\&quot;https://campus.datacamp.com/courses/1606/4135?ex=2\\\\&quot;&lt;/code&gt; and then caught the response. You saw that such a response is a &lt;code&gt;http.client.HTTPResponse&lt;/code&gt; object. The question remains: what can you do with this response?&lt;/p&gt;\\\\n&lt;p&gt;Well, as it came from an HTML page, you could &lt;em&gt;read&lt;/em&gt; it to extract the HTML and, in fact, such a &lt;code&gt;http.client.HTTPResponse&lt;/code&gt; object has an associated &lt;code&gt;read()&lt;/code&gt; method. In this exercise, you&#39;ll build on your previous great work to extract the response and print the HTML.&lt;/p&gt;&quot;,&quot;feedbacks&quot;,[&quot;^@&quot;,[]],&quot;attachments&quot;,null,&quot;exercise_image&quot;,null,&quot;title&quot;,&quot;Printing HTTP request results in Python using urllib&quot;,&quot;xp&quot;,100,&quot;language&quot;,&quot;python&quot;,&quot;pre_exercise_code&quot;,&quot;&quot;,&quot;solution&quot;,&quot;# Import packages\\\\nfrom urllib.request import urlopen, Request\\\\n\\\\n# Specify the url\\\\nurl = \\\\&quot;https://campus.datacamp.com/courses/1606/4135?ex=2\\\\&quot;\\\\n\\\\n# This packages the request\\\\nrequest = Request(url)\\\\n\\\\n# Sends the request and catches the response: response\\\\nresponse = urlopen(request)\\\\n\\\\n# Extract the response: html\\\\nhtml = response.read()\\\\n\\\\n# Print the html\\\\nprint(html)\\\\n\\\\n# Be polite and close the response!\\\\nresponse.close()&quot;,&quot;type&quot;,&quot;NormalExercise&quot;,&quot;id&quot;,42712,&quot;programming_language&quot;,null]],[&quot;^?&quot;,[&quot;sample_code&quot;,&quot;# Import package\\\\n\\\\n\\\\n# Specify the url: url\\\\n\\\\n\\\\n# Packages the request, send the request and catch the response: r\\\\n\\\\n\\\\n# Extract the response: text\\\\n\\\\n\\\\n# Print the html\\\\nprint(text)&quot;,&quot;sct&quot;,&quot;\\\\n# Test: import requests\\\\nEx().has_import(\\\\&quot;requests\\\\&quot;)\\\\n\\\\n# Test: &#39;url&#39; variable\\\\nEx().check_object(\\\\&quot;url\\\\&quot;).has_equal_value()\\\\n\\\\n# Test: call to requests.get() and &#39;r&#39; variable\\\\nEx().check_function(\\\\&quot;requests.get\\\\&quot;).check_args(0).has_equal_value()\\\\nEx().check_object(\\\\&quot;r\\\\&quot;)\\\\n\\\\n# Test: &#39;text&#39; variable\\\\nEx().has_code(\\\\&quot;r.text\\\\&quot;, pattern = False, not_typed_msg=\\\\&quot;Have you used `r.text` to create `text`?\\\\&quot;)\\\\nEx().check_object(\\\\&quot;text\\\\&quot;)\\\\n\\\\n# Test: Predefined code\\\\nEx().check_function(&#39;print&#39;).check_args(0).has_equal_ast()\\\\n\\\\nsuccess_msg(\\\\&quot;Awesome!\\\\&quot;)\\\\n&quot;,&quot;instructions&quot;,&quot;&lt;ul&gt;\\\\n&lt;li&gt;Import the package &lt;code&gt;requests&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;li&gt;Assign the URL of interest to the variable &lt;code&gt;url&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;li&gt;Package the request to the URL, send the request and catch the response with a single function &lt;code&gt;requests.get()&lt;/code&gt;, assigning the response to the variable &lt;code&gt;r&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;li&gt;Use the &lt;code&gt;text&lt;/code&gt; attribute of the object &lt;code&gt;r&lt;/code&gt; to return the HTML of the webpage as a string; store the result in a variable &lt;code&gt;text&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;li&gt;Hit submit to print the HTML of the webpage.&lt;/li&gt;\\\\n&lt;/ul&gt;&quot;,&quot;externalId&quot;,42713,&quot;question&quot;,&quot;&quot;,&quot;hint&quot;,&quot;&lt;ul&gt;\\\\n&lt;li&gt;To import a package &lt;code&gt;x&lt;/code&gt;, execute &lt;code&gt;import x&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;li&gt;Did you type in the URL correctly?&lt;/li&gt;\\\\n&lt;li&gt;Pass the &lt;em&gt;url&lt;/em&gt; (the &lt;code&gt;url&lt;/code&gt; object you defined) as an argument to &lt;code&gt;requests.get()&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;li&gt;You can access the &lt;code&gt;text&lt;/code&gt; attribute of the object &lt;code&gt;r&lt;/code&gt; by executing &lt;code&gt;r.text&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;li&gt;You don&#39;t have to modify the code for printing the HTML of the webpage.&lt;/li&gt;\\\\n&lt;/ul&gt;&quot;,&quot;possible_answers&quot;,[&quot;^@&quot;,[]],&quot;runtime_config&quot;,null,&quot;number&quot;,8,&quot;randomNumber&quot;,0.9499234036356423,&quot;assignment&quot;,&quot;&lt;p&gt;Now that you&#39;ve got your head and hands around making HTTP requests using the urllib package, you&#39;re going to figure out how to do the same using the higher-level requests library. You&#39;ll once again be pinging DataCamp servers for their &lt;code&gt;\\\\&quot;http://www.datacamp.com/teach/documentation\\\\&quot;&lt;/code&gt; page.&lt;/p&gt;\\\\n&lt;p&gt;Note that unlike in the previous exercises using urllib, you don&#39;t have to close the connection when using requests!&lt;/p&gt;&quot;,&quot;feedbacks&quot;,[&quot;^@&quot;,[]],&quot;attachments&quot;,null,&quot;exercise_image&quot;,null,&quot;title&quot;,&quot;Performing HTTP requests in Python using requests&quot;,&quot;xp&quot;,100,&quot;language&quot;,&quot;python&quot;,&quot;pre_exercise_code&quot;,&quot;&quot;,&quot;solution&quot;,&quot;# Import package\\\\nimport requests\\\\n\\\\n# Specify the url: url\\\\nurl = \\\\&quot;http://www.datacamp.com/teach/documentation\\\\&quot;\\\\n\\\\n# Packages the request, send the request and catch the response: r\\\\nr = requests.get(url)\\\\n\\\\n# Extract the response: text\\\\ntext = r.text\\\\n\\\\n# Print the html\\\\nprint(text)&quot;,&quot;type&quot;,&quot;NormalExercise&quot;,&quot;id&quot;,42713,&quot;programming_language&quot;,null]],[&quot;^?&quot;,[&quot;sample_code&quot;,&quot;&quot;,&quot;sct&quot;,&quot;&quot;,&quot;aspect_ratio&quot;,56.25,&quot;instructions&quot;,null,&quot;externalId&quot;,990670,&quot;question&quot;,&quot;&quot;,&quot;hint&quot;,null,&quot;possible_answers&quot;,[&quot;^@&quot;,[]],&quot;runtime_config&quot;,null,&quot;number&quot;,9,&quot;video_hls&quot;,null,&quot;randomNumber&quot;,0.6150986604311994,&quot;chapter_id&quot;,4135,&quot;assignment&quot;,null,&quot;feedbacks&quot;,[&quot;^@&quot;,[]],&quot;attachments&quot;,null,&quot;exercise_image&quot;,null,&quot;version&quot;,&quot;v0&quot;,&quot;title&quot;,&quot;Scraping the web in Python&quot;,&quot;xp&quot;,50,&quot;language&quot;,&quot;python&quot;,&quot;pre_exercise_code&quot;,&quot;&quot;,&quot;solution&quot;,&quot;&quot;,&quot;type&quot;,&quot;VideoExercise&quot;,&quot;id&quot;,990670,&quot;projector_key&quot;,&quot;course_1606_9d1f8a331d1200c7e1bdbfcaf3a7a491&quot;,&quot;video_link&quot;,null,&quot;programming_language&quot;,null,&quot;key&quot;,&quot;da43858012&quot;,&quot;course_id&quot;,1606]],[&quot;^?&quot;,[&quot;sample_code&quot;,&quot;# Import packages\\\\nimport requests\\\\nfrom ____ import ____\\\\n\\\\n# Specify url: url\\\\n\\\\n\\\\n# Package the request, send the request and catch the response: r\\\\n\\\\n\\\\n# Extracts the response as html: html_doc\\\\n\\\\n\\\\n# Create a BeautifulSoup object from the HTML: soup\\\\n\\\\n\\\\n# Prettify the BeautifulSoup object: pretty_soup\\\\n\\\\n\\\\n# Print the response\\\\nprint(pretty_soup)&quot;,&quot;sct&quot;,&quot;# Test: Predefined code\\\\npredef_msg = \\\\&quot;You don&#39;t have to change any of the predefined code.\\\\&quot;\\\\nEx().has_import(\\\\n    \\\\&quot;requests\\\\&quot;,\\\\n    not_imported_msg=predef_msg\\\\n)\\\\n\\\\n# Test: import BeautifulSoup\\\\nimport_msg = \\\\&quot;Did you correctly import the required packages?\\\\&quot;\\\\nEx().has_import(\\\\n    \\\\&quot;bs4.BeautifulSoup\\\\&quot;,\\\\n    not_imported_msg=import_msg\\\\n)\\\\n\\\\n# Test: &#39;url&#39; variable\\\\nEx().check_object(\\\\&quot;url\\\\&quot;).has_equal_value()\\\\n\\\\n# Test: call to requests.get() and &#39;r&#39; variable\\\\nEx().check_function(\\\\&quot;requests.get\\\\&quot;).check_args(0).has_equal_value()\\\\nEx().check_object(\\\\&quot;r\\\\&quot;)\\\\n\\\\n\\\\n# Test: &#39;html_doc&#39; variable\\\\nEx().check_correct(\\\\n  check_object(\\\\&quot;html_doc\\\\&quot;).has_equal_value(),\\\\n  has_code(\\\\&quot;r.text\\\\&quot;, pattern = False, not_typed_msg=\\\\&quot;Have you used `r.text` to create `html_doc`?\\\\&quot;)\\\\n)\\\\n\\\\n# Test: call to BeautifulSoup() and &#39;soup&#39; variable\\\\nEx().check_correct(\\\\n  check_object(\\\\&quot;soup\\\\&quot;).has_equal_value(),\\\\n  check_function(\\\\&quot;bs4.BeautifulSoup\\\\&quot;).check_args(0).has_equal_value()\\\\n  )\\\\n\\\\n# Test: call to prettify() and &#39;pretty_soup&#39; variable\\\\nEx().check_correct(\\\\n  check_object(\\\\&quot;pretty_soup\\\\&quot;).has_equal_value(),\\\\n  check_function(\\\\&quot;soup.prettify\\\\&quot;)\\\\n  )\\\\n\\\\n# Test: Predefined code\\\\nEx().has_printout(0)\\\\n\\\\nsuccess_msg(\\\\&quot;Awesome!\\\\&quot;)\\\\n&quot;,&quot;instructions&quot;,&quot;&lt;ul&gt;\\\\n&lt;li&gt;Import the function &lt;code&gt;BeautifulSoup&lt;/code&gt; from the package &lt;code&gt;bs4&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;li&gt;Assign the URL of interest to the variable &lt;code&gt;url&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;li&gt;Package the request to the URL, send the request and catch the response with a single function &lt;code&gt;requests.get()&lt;/code&gt;, assigning the response to the variable &lt;code&gt;r&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;li&gt;Use the &lt;code&gt;text&lt;/code&gt; attribute of the object &lt;code&gt;r&lt;/code&gt; to return the HTML of the webpage as a string; store the result in a variable &lt;code&gt;html_doc&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;li&gt;Create a BeautifulSoup object &lt;code&gt;soup&lt;/code&gt; from the resulting HTML using the function &lt;code&gt;BeautifulSoup()&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;li&gt;Use the method &lt;code&gt;prettify()&lt;/code&gt; on &lt;code&gt;soup&lt;/code&gt; and assign the result to &lt;code&gt;pretty_soup&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;li&gt;Hit submit to print to prettified HTML to your shell!&lt;/li&gt;\\\\n&lt;/ul&gt;&quot;,&quot;externalId&quot;,42715,&quot;question&quot;,&quot;&quot;,&quot;hint&quot;,&quot;&lt;ul&gt;\\\\n&lt;li&gt;To import a function &lt;code&gt;y&lt;/code&gt; from a package &lt;code&gt;x&lt;/code&gt;, execute &lt;code&gt;from x import y&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;li&gt;Check the URL to make sure that you typed it in correctly.&lt;/li&gt;\\\\n&lt;li&gt;Pass the &lt;em&gt;url&lt;/em&gt; (the &lt;code&gt;url&lt;/code&gt; object you defined) as an argument to &lt;code&gt;requests.get()&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;li&gt;You can access the &lt;code&gt;text&lt;/code&gt; attribute of the object &lt;code&gt;r&lt;/code&gt; by executing &lt;code&gt;r.text&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;li&gt;Pass the extracted &lt;em&gt;HTML&lt;/em&gt; as an argument to &lt;code&gt;BeautifulSoup()&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;li&gt;To use the &lt;code&gt;prettify()&lt;/code&gt; method on the BeautifulSoup object &lt;code&gt;soup&lt;/code&gt;, execute &lt;code&gt;soup.prettify()&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;li&gt;You don&#39;t have to modify the code to print the prettified HTML.&lt;/li&gt;\\\\n&lt;/ul&gt;&quot;,&quot;possible_answers&quot;,[&quot;^@&quot;,[]],&quot;runtime_config&quot;,null,&quot;number&quot;,10,&quot;randomNumber&quot;,0.9907962772955521,&quot;assignment&quot;,&quot;&lt;p&gt;In this interactive exercise, you&#39;ll learn how to use the BeautifulSoup package to &lt;em&gt;parse&lt;/em&gt;, &lt;em&gt;prettify&lt;/em&gt; and &lt;em&gt;extract&lt;/em&gt; information from HTML. You&#39;ll scrape the data from the webpage of Guido van Rossum, Python&#39;s very own &lt;a href=\\\\&quot;https://en.wikipedia.org/wiki/Benevolent_dictator_for_life\\\\&quot;&gt;Benevolent Dictator for Life&lt;/a&gt;. In the following exercises, you&#39;ll prettify the HTML and then extract the text and the hyperlinks.&lt;/p&gt;\\\\n&lt;p&gt;The URL of interest is &lt;code&gt;url = &#39;https://www.python.org/~guido/&#39;&lt;/code&gt;.&lt;/p&gt;&quot;,&quot;feedbacks&quot;,[&quot;^@&quot;,[]],&quot;attachments&quot;,null,&quot;exercise_image&quot;,null,&quot;title&quot;,&quot;Parsing HTML with BeautifulSoup&quot;,&quot;xp&quot;,100,&quot;language&quot;,&quot;python&quot;,&quot;pre_exercise_code&quot;,&quot;&quot;,&quot;solution&quot;,&quot;# Import packages\\\\nimport requests\\\\nfrom bs4 import BeautifulSoup\\\\n\\\\n# Specify url: url\\\\nurl = &#39;https://www.python.org/~guido/&#39;\\\\n\\\\n# Package the request, send the request and catch the response: r\\\\nr = requests.get(url)\\\\n\\\\n# Extracts the response as html: html_doc\\\\nhtml_doc = r.text\\\\n\\\\n# Create a BeautifulSoup object from the HTML: soup\\\\nsoup = BeautifulSoup(html_doc)\\\\n\\\\n# Prettify the BeautifulSoup object: pretty_soup\\\\npretty_soup = soup.prettify()\\\\n\\\\n# Print the response\\\\nprint(pretty_soup)&quot;,&quot;type&quot;,&quot;NormalExercise&quot;,&quot;id&quot;,42715,&quot;programming_language&quot;,null]],[&quot;^?&quot;,[&quot;sample_code&quot;,&quot;# Import packages\\\\nimport requests\\\\nfrom bs4 import BeautifulSoup\\\\n\\\\n# Specify url: url\\\\nurl = &#39;https://www.python.org/~guido/&#39;\\\\n\\\\n# Package the request, send the request and catch the response: r\\\\nr = requests.get(url)\\\\n\\\\n# Extract the response as html: html_doc\\\\nhtml_doc = r.text\\\\n\\\\n# Create a BeautifulSoup object from the HTML: soup\\\\n\\\\n\\\\n# Get the title of Guido&#39;s webpage: guido_title\\\\n\\\\n\\\\n# Print the title of Guido&#39;s webpage to the shell\\\\n\\\\n\\\\n# Get Guido&#39;s text: guido_text\\\\n\\\\n\\\\n# Print Guido&#39;s text to the shell\\\\nprint(guido_text)&quot;,&quot;sct&quot;,&quot;# Test: Predefined code\\\\npredef_msg = \\\\&quot;You don&#39;t have to change any of the predefined code.\\\\&quot;\\\\nEx().has_import(\\\\n    \\\\&quot;requests\\\\&quot;,\\\\n    not_imported_msg=predef_msg\\\\n)\\\\n\\\\n# Test: import BeautifulSoup\\\\nEx().has_import(\\\\n    \\\\&quot;bs4.BeautifulSoup\\\\&quot;,\\\\n    not_imported_msg=predef_msg\\\\n)\\\\n\\\\n# Test: &#39;url&#39; variable\\\\nEx().check_object(\\\\&quot;url\\\\&quot;).has_equal_value()\\\\n\\\\n# Test: call to requests.get() and &#39;r&#39; variable\\\\nEx().check_function(\\\\&quot;requests.get\\\\&quot;).check_args(0).has_equal_value()\\\\nEx().check_object(\\\\&quot;r\\\\&quot;)\\\\n\\\\n\\\\n# Test: &#39;html_doc&#39; variable\\\\nEx().check_correct(\\\\n  check_object(\\\\&quot;html_doc\\\\&quot;).has_equal_value(),\\\\n  has_code(\\\\&quot;r.text\\\\&quot;, pattern = False, not_typed_msg=\\\\&quot;Have you used `r.text` to create `html_doc`?\\\\&quot;)\\\\n)\\\\n\\\\n# Test: call to BeautifulSoup() and &#39;soup&#39; variable\\\\nEx().check_correct(\\\\n  check_object(\\\\&quot;soup\\\\&quot;).has_equal_value(),\\\\n  check_function(\\\\&quot;bs4.BeautifulSoup\\\\&quot;).check_args(0).has_equal_value()\\\\n  )\\\\n\\\\n# Test: &#39;guido_title&#39; variable\\\\nEx().check_correct(\\\\n  check_object(\\\\&quot;guido_title\\\\&quot;).has_equal_value(),\\\\n  has_code(\\\\&quot;soup.title\\\\&quot;, pattern = False, not_typed_msg=\\\\&quot;Have you used `soup.title` to create `guido_title`?\\\\&quot;)\\\\n)\\\\n\\\\n# Test: call to print()\\\\nEx().has_printout(0)\\\\n\\\\n# Test: call to soup.get_text() and &#39;guido_text&#39; variable\\\\nEx().check_correct(\\\\n  check_object(\\\\&quot;guido_text\\\\&quot;).has_equal_value(),\\\\n  check_function(\\\\&quot;soup.get_text\\\\&quot;)\\\\n  )\\\\n\\\\n# Test: Predefined code\\\\nEx().has_printout(1)\\\\n\\\\nsuccess_msg(\\\\&quot;Awesome!\\\\&quot;)\\\\n&quot;,&quot;instructions&quot;,&quot;&lt;ul&gt;\\\\n&lt;li&gt;In the sample code, the HTML response object &lt;code&gt;html_doc&lt;/code&gt; has already been created: your first task is to Soupify it using the function &lt;code&gt;BeautifulSoup()&lt;/code&gt; and to assign the resulting soup to the variable &lt;code&gt;soup&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;li&gt;Extract the title from the HTML soup &lt;code&gt;soup&lt;/code&gt; using the attribute &lt;code&gt;title&lt;/code&gt; and assign the result to &lt;code&gt;guido_title&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;li&gt;Print the title of Guido&#39;s webpage to the shell using the &lt;code&gt;print()&lt;/code&gt; function.&lt;/li&gt;\\\\n&lt;li&gt;Extract the text from the HTML soup &lt;code&gt;soup&lt;/code&gt; using the method &lt;code&gt;get_text()&lt;/code&gt; and assign to &lt;code&gt;guido_text&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;li&gt;Hit submit to print the text from Guido&#39;s webpage to the shell.&lt;/li&gt;\\\\n&lt;/ul&gt;&quot;,&quot;externalId&quot;,42716,&quot;question&quot;,&quot;&quot;,&quot;hint&quot;,&quot;&lt;ul&gt;\\\\n&lt;li&gt;Pass the &lt;em&gt;HTML response object&lt;/em&gt; as an argument to &lt;code&gt;BeautifulSoup()&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;li&gt;You can access the &lt;code&gt;title&lt;/code&gt; attribute of the object &lt;code&gt;soup&lt;/code&gt; by executing &lt;code&gt;soup.title&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;li&gt;The object that contains the title of Guido&#39;s webpage is &lt;code&gt;guido_title&lt;/code&gt;; pass this as an argument to &lt;code&gt;print()&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;li&gt;Use the method &lt;code&gt;get_text()&lt;/code&gt; on the HTML soup &lt;code&gt;soup&lt;/code&gt; by executing &lt;code&gt;soup.get_text()&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;li&gt;You don&#39;t have to modify the code to print the text from Guido&#39;s webpage.&lt;/li&gt;\\\\n&lt;/ul&gt;&quot;,&quot;possible_answers&quot;,[&quot;^@&quot;,[]],&quot;runtime_config&quot;,null,&quot;number&quot;,11,&quot;randomNumber&quot;,0.9359883737326375,&quot;assignment&quot;,&quot;&lt;p&gt;As promised, in the following exercises, you&#39;ll learn the basics of extracting information from HTML soup. In this exercise, you&#39;ll figure out how to extract the text from the BDFL&#39;s webpage, along with printing the webpage&#39;s title.&lt;/p&gt;&quot;,&quot;feedbacks&quot;,[&quot;^@&quot;,[]],&quot;attachments&quot;,null,&quot;exercise_image&quot;,null,&quot;title&quot;,&quot;Turning a webpage into data using BeautifulSoup: getting the text&quot;,&quot;xp&quot;,100,&quot;language&quot;,&quot;python&quot;,&quot;pre_exercise_code&quot;,&quot;&quot;,&quot;solution&quot;,&quot;# Import packages\\\\nimport requests\\\\nfrom bs4 import BeautifulSoup\\\\n\\\\n# Specify url: url\\\\nurl = &#39;https://www.python.org/~guido/&#39;\\\\n\\\\n# Package the request, send the request and catch the response: r\\\\nr = requests.get(url)\\\\n\\\\n# Extract the response as html: html_doc\\\\nhtml_doc = r.text\\\\n\\\\n# Create a BeautifulSoup object from the HTML: soup\\\\nsoup = BeautifulSoup(html_doc)\\\\n\\\\n# Get the title of Guido&#39;s webpage: guido_title\\\\nguido_title = soup.title\\\\n\\\\n# Print the title of Guido&#39;s webpage to the shell\\\\nprint(guido_title)\\\\n\\\\n# Get Guido&#39;s text: guido_text\\\\nguido_text = soup.get_text()\\\\n\\\\n# Print Guido&#39;s text to the shell\\\\nprint(guido_text)&quot;,&quot;type&quot;,&quot;NormalExercise&quot;,&quot;id&quot;,42716,&quot;programming_language&quot;,null]],[&quot;^?&quot;,[&quot;sample_code&quot;,&quot;# Import packages\\\\nimport requests\\\\nfrom bs4 import BeautifulSoup\\\\n\\\\n# Specify url\\\\nurl = &#39;https://www.python.org/~guido/&#39;\\\\n\\\\n# Package the request, send the request and catch the response: r\\\\nr = requests.get(url)\\\\n\\\\n# Extracts the response as html: html_doc\\\\nhtml_doc = r.text\\\\n\\\\n# create a BeautifulSoup object from the HTML: soup\\\\nsoup = BeautifulSoup(html_doc)\\\\n\\\\n# Print the title of Guido&#39;s webpage\\\\nprint(soup.title)\\\\n\\\\n# Find all &#39;a&#39; tags (which define hyperlinks): a_tags\\\\n\\\\n\\\\n# Print the URLs to the shell\\\\nfor ____ in ____:\\\\n    ____&quot;,&quot;sct&quot;,&quot;predef_msg = \\\\&quot;You don&#39;t have to change any of the predefined code.\\\\&quot;\\\\nEx().has_import(\\\\&quot;requests\\\\&quot;)\\\\nEx().has_import(\\\\&quot;bs4.BeautifulSoup\\\\&quot;)\\\\nEx().check_object(\\\\&quot;url\\\\&quot;).has_equal_value(incorrect_msg = predef_msg)\\\\nEx().check_function(\\\\&quot;requests.get\\\\&quot;).check_args(0).has_equal_ast()\\\\nEx().check_object(\\\\&quot;html_doc\\\\&quot;).has_equal_value(incorrect_msg = predef_msg)\\\\nEx().check_object(\\\\&quot;soup\\\\&quot;).has_equal_value(incorrect_msg = predef_msg)\\\\nEx().has_printout(0)\\\\n\\\\nEx().check_correct(\\\\n    check_object(\\\\&quot;a_tags\\\\&quot;),\\\\n    check_function(\\\\&quot;soup.find_all\\\\&quot;).check_args(0).has_equal_value()\\\\n)\\\\nEx().check_for_loop().multi(\\\\n        check_iter().has_equal_value(incorrect_msg = \\\\&quot;You have to iterate over `a_tags`\\\\&quot;),\\\\n        check_body().set_context(&#39;&lt;a href=\\\\&quot;pics.html\\\\&quot;&gt;&lt;img border=\\\\&quot;0\\\\&quot; src=\\\\&quot;images/IMG_2192.jpg\\\\&quot;/&gt;&lt;/a&gt;&#39;).check_function(\\\\&quot;print\\\\&quot;).check_args(0).check_function(\\\\&quot;link.get\\\\&quot;).check_args(0).has_equal_value()\\\\n    )\\\\n\\\\nsuccess_msg(\\\\&quot;Awesome!\\\\&quot;)&quot;,&quot;instructions&quot;,&quot;&lt;ul&gt;\\\\n&lt;li&gt;Use the method &lt;code&gt;find_all()&lt;/code&gt; to find all hyperlinks in &lt;code&gt;soup&lt;/code&gt;, remembering that hyperlinks are defined by the HTML tag &lt;code&gt;&amp;lt;a&amp;gt;&lt;/code&gt; but passed to &lt;code&gt;find_all()&lt;/code&gt; without angle brackets; store the result in the variable &lt;code&gt;a_tags&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;li&gt;The variable &lt;code&gt;a_tags&lt;/code&gt; is a results set: your job now is to enumerate over it, using a &lt;code&gt;for&lt;/code&gt; loop and to print the actual URLs of the hyperlinks; to do this, for every element &lt;code&gt;link&lt;/code&gt; in &lt;code&gt;a_tags&lt;/code&gt;, you want to &lt;code&gt;print()&lt;/code&gt; &lt;code&gt;link.get(&#39;href&#39;)&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;/ul&gt;&quot;,&quot;externalId&quot;,42717,&quot;question&quot;,&quot;&quot;,&quot;hint&quot;,&quot;&lt;ul&gt;\\\\n&lt;li&gt;Pass the &lt;em&gt;HTML tag&lt;/em&gt; to find (without the angle brackets &lt;code&gt;&amp;lt;&amp;gt;&lt;/code&gt;) as a string argument to &lt;code&gt;find_all()&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;li&gt;Recall that the &lt;code&gt;for&lt;/code&gt; loop recipe is: &lt;code&gt;for&lt;/code&gt; &lt;em&gt;loop variable&lt;/em&gt; &lt;code&gt;in&lt;/code&gt; &lt;em&gt;results set&lt;/em&gt;&lt;code&gt;:&lt;/code&gt;. Don&#39;t forget to pass &lt;code&gt;link.get(&#39;href&#39;)&lt;/code&gt; as an argument to &lt;code&gt;print()&lt;/code&gt; inside the &lt;code&gt;for&lt;/code&gt; loop body.&lt;/li&gt;\\\\n&lt;/ul&gt;&quot;,&quot;possible_answers&quot;,[&quot;^@&quot;,[]],&quot;runtime_config&quot;,null,&quot;number&quot;,12,&quot;randomNumber&quot;,0.5560594333253173,&quot;assignment&quot;,&quot;&lt;p&gt;In this exercise, you&#39;ll figure out how to extract the URLs of the hyperlinks from the BDFL&#39;s webpage. In the process, you&#39;ll become close friends with the soup method &lt;code&gt;find_all()&lt;/code&gt;.&lt;/p&gt;&quot;,&quot;feedbacks&quot;,[&quot;^@&quot;,[]],&quot;attachments&quot;,null,&quot;exercise_image&quot;,null,&quot;title&quot;,&quot;Turning a webpage into data using BeautifulSoup: getting the hyperlinks&quot;,&quot;xp&quot;,100,&quot;language&quot;,&quot;python&quot;,&quot;pre_exercise_code&quot;,&quot;&quot;,&quot;solution&quot;,&quot;# Import packages\\\\nimport requests\\\\nfrom bs4 import BeautifulSoup\\\\n\\\\n# Specify url\\\\nurl = &#39;https://www.python.org/~guido/&#39;\\\\n\\\\n# Package the request, send the request and catch the response: r\\\\nr = requests.get(url)\\\\n\\\\n# Extracts the response as html: html_doc\\\\nhtml_doc = r.text\\\\n\\\\n# create a BeautifulSoup object from the HTML: soup\\\\nsoup = BeautifulSoup(html_doc)\\\\n\\\\n# Print the title of Guido&#39;s webpage\\\\nprint(soup.title)\\\\n\\\\n# Find all &#39;a&#39; tags (which define hyperlinks): a_tags\\\\na_tags = soup.find_all(&#39;a&#39;)\\\\n\\\\n# Print the URLs to the shell\\\\nfor link in a_tags:\\\\n    print(link.get(&#39;href&#39;))&quot;,&quot;type&quot;,&quot;NormalExercise&quot;,&quot;id&quot;,42717,&quot;programming_language&quot;,null]]]],&quot;canRateChapter&quot;,false,&quot;isChapterCompleted&quot;,false]],&quot;learningMode&quot;,&quot;course&quot;,&quot;learningRecap&quot;,null,&quot;location&quot;,[&quot;^?&quot;,[&quot;current&quot;,[&quot;^?&quot;,[&quot;pathname&quot;,&quot;/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1&quot;,&quot;query&quot;,[&quot;^?&quot;,[&quot;ex&quot;,&quot;2&quot;]]]],&quot;language&quot;,&quot;en&quot;,&quot;canonical&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1?ex=2&quot;,&quot;before&quot;,[&quot;^?&quot;,[&quot;pathname&quot;,&quot;/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1&quot;,&quot;query&quot;,[&quot;^?&quot;,[&quot;ex&quot;,&quot;2&quot;]]]]]],&quot;mobilePopup&quot;,[&quot;^?&quot;,[]],&quot;onboardingMilestones&quot;,[&quot;^ &quot;,&quot;isStarted&quot;,false,&quot;isActive&quot;,true,&quot;step&quot;,0],&quot;notes&quot;,[&quot;^ &quot;,&quot;workspaceNotes&quot;,null,&quot;workspaceTemplate&quot;,[&quot;^ &quot;,&quot;_tag&quot;,&quot;template&quot;,&quot;id&quot;,3046,&quot;createdAt&quot;,&quot;2022-12-01T15:10:45.124Z&quot;,&quot;updatedAt&quot;,&quot;2022-12-05T06:31:46.338Z&quot;,&quot;key&quot;,&quot;course-dataset-intermediate-importing-data-in-python&quot;,&quot;language&quot;,&quot;Python&quot;,&quot;languageVersion&quot;,null,&quot;title&quot;,&quot;Intermediate Importing Data in Python&quot;,&quot;description&quot;,&quot;Explore the datasets from the course, Intermediate Importing Data in Python.&quot;,&quot;listed&quot;,false,&quot;latestVersion&quot;,&quot;d9783ad9a9e677a4f583a5bd9ed5b9d5987a2859&quot;,&quot;communitySlug&quot;,null,&quot;category&quot;,null,&quot;templateGroupKey&quot;,null,&quot;previewPublicationId&quot;,&quot;ade0176d-8e1d-436c-b7c1-44c3f4f1df8f&quot;,&quot;labels&quot;,[&quot;course-dataset&quot;],&quot;courseId&quot;,1606,&quot;integrationIds&quot;,[],&quot;publicationScreenshot&quot;,null]],&quot;output&quot;,[&quot;^ &quot;,&quot;lastErrorMessage&quot;,null,&quot;^17&quot;,[]],&quot;preFetchedData&quot;,[&quot;^0&quot;,[&quot;^ &quot;,&quot;n&quot;,&quot;PreFetchedDataStateRecord&quot;,&quot;v&quot;,[&quot;^ &quot;,&quot;^&gt;&quot;,[&quot;^0&quot;,[&quot;^ &quot;,&quot;n&quot;,&quot;PreFetchedRequestRecord&quot;,&quot;v&quot;,[&quot;^ &quot;,&quot;^2&quot;,&quot;SUCCESS&quot;,&quot;data&quot;,[&quot;^ &quot;,&quot;id&quot;,4135,&quot;title_meta&quot;,null,&quot;^W&quot;,&quot;Importing data from the Internet&quot;,&quot;^X&quot;,&quot;The web is a rich source of data from which you can extract various types of insights and findings. In this chapter, you will learn how to get data from the web, whether it is stored in files or in HTML. You&#39;ll also learn the basics of scraping and parsing web data.&quot;,&quot;number&quot;,1,&quot;slug&quot;,&quot;importing-data-from-the-internet-1&quot;,&quot;nb_exercises&quot;,12,&quot;badge_completed_url&quot;,&quot;https://assets.datacamp.com/production/default/badges/missing.png&quot;,&quot;badge_uncompleted_url&quot;,&quot;https://assets.datacamp.com/production/default/badges/missing_unc.png&quot;,&quot;last_updated_on&quot;,&quot;26/09/2024&quot;,&quot;slides_link&quot;,&quot;https://projector-video-pdf-converter.datacamp.com/1606/chapter1.pdf&quot;,&quot;free_preview&quot;,true,&quot;xp&quot;,1050,&quot;number_of_videos&quot;,3,&quot;^F&quot;,[[&quot;^ &quot;,&quot;^B&quot;,&quot;VideoExercise&quot;,&quot;^W&quot;,&quot;Importing flat files from the web&quot;,&quot;aggregate_xp&quot;,50,&quot;^1&lt;&quot;,1,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1?ex=1&quot;,&quot;exercise_image&quot;,null,&quot;programming_language&quot;,null,&quot;runtime_config&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^W&quot;,&quot;Importing flat files from the web: your turn!&quot;,&quot;^1E&quot;,100,&quot;^1&lt;&quot;,2,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1?ex=2&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^W&quot;,&quot;Opening and reading flat files from the web&quot;,&quot;^1E&quot;,100,&quot;^1&lt;&quot;,3,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1?ex=3&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^W&quot;,&quot;Importing non-flat files from the web&quot;,&quot;^1E&quot;,100,&quot;^1&lt;&quot;,4,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1?ex=4&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;VideoExercise&quot;,&quot;^W&quot;,&quot;HTTP requests to import files from the web&quot;,&quot;^1E&quot;,50,&quot;^1&lt;&quot;,5,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1?ex=5&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^W&quot;,&quot;Performing HTTP requests in Python using urllib&quot;,&quot;^1E&quot;,100,&quot;^1&lt;&quot;,6,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1?ex=6&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^W&quot;,&quot;Printing HTTP request results in Python using urllib&quot;,&quot;^1E&quot;,100,&quot;^1&lt;&quot;,7,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1?ex=7&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^W&quot;,&quot;Performing HTTP requests in Python using requests&quot;,&quot;^1E&quot;,100,&quot;^1&lt;&quot;,8,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1?ex=8&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;VideoExercise&quot;,&quot;^W&quot;,&quot;Scraping the web in Python&quot;,&quot;^1E&quot;,50,&quot;^1&lt;&quot;,9,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1?ex=9&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^W&quot;,&quot;Parsing HTML with BeautifulSoup&quot;,&quot;^1E&quot;,100,&quot;^1&lt;&quot;,10,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1?ex=10&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^W&quot;,&quot;Turning a webpage into data using BeautifulSoup: getting the text&quot;,&quot;^1E&quot;,100,&quot;^1&lt;&quot;,11,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1?ex=11&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^W&quot;,&quot;Turning a webpage into data using BeautifulSoup: getting the hyperlinks&quot;,&quot;^1E&quot;,100,&quot;^1&lt;&quot;,12,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1?ex=12&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null]]]]]],&quot;^E&quot;,[&quot;^0&quot;,[&quot;^ &quot;,&quot;n&quot;,&quot;PreFetchedRequestRecord&quot;,&quot;v&quot;,[&quot;^ &quot;,&quot;^2&quot;,&quot;SUCCESS&quot;,&quot;^1:&quot;,[&quot;^ &quot;,&quot;id&quot;,1606,&quot;^W&quot;,&quot;Intermediate Importing Data in Python&quot;,&quot;^X&quot;,&quot;As a data scientist, you will need to clean data, wrangle and munge it, visualize it, build predictive models and interpret these models. Before you can do so, however, you will need to know how to get data into Python. In the prequel to this course, you learned many ways to import data into Python: from flat files such as .txt and .csv; from files native to other software such as Excel spreadsheets, Stata, SAS, and MATLAB files; and from relational databases such as SQLite and PostgreSQL. In this course, you&#39;ll extend this knowledge base by learning to import data from the web and by pulling data from Application Programming Interfaces APIssuch as the Twitter streaming API, which allows us to stream real-time tweets.&quot;,&quot;short_description&quot;,&quot;Improve your Python data importing skills and learn to work with web and API data.&quot;,&quot;author_field&quot;,null,&quot;author_bio&quot;,null,&quot;author_image&quot;,&quot;https://assets.datacamp.com/production/course_1606/author_images/author_image_course_1606_20200310-1-lgdj4c?1583853939&quot;,&quot;nb_of_subscriptions&quot;,179489,&quot;^1=&quot;,&quot;intermediate-importing-data-in-python&quot;,&quot;image_url&quot;,&quot;https://assets.datacamp.com/production/course_1606/shields/thumb/shield_image_course_1606_20200310-1-17hkmhz?1583853940&quot;,&quot;image_thumbnail_url&quot;,&quot;https://assets.datacamp.com/production/course_1606/shields/thumb_home/shield_image_course_1606_20200310-1-17hkmhz?1583853940&quot;,&quot;^1A&quot;,&quot;11/10/2024&quot;,&quot;link&quot;,&quot;https://www.datacamp.com/courses/intermediate-importing-data-in-python&quot;,&quot;should_cache&quot;,true,&quot;^B&quot;,&quot;datacamp&quot;,&quot;difficulty_level&quot;,2,&quot;state&quot;,&quot;live&quot;,&quot;university&quot;,null,&quot;sharing_links&quot;,[&quot;^ &quot;,&quot;twitter&quot;,&quot;http://bit.ly/1eWTMJh&quot;,&quot;facebook&quot;,&quot;http://bit.ly/1iS42Do&quot;],&quot;marketing_video&quot;,&quot;&quot;,&quot;^1G&quot;,&quot;python&quot;,&quot;paid&quot;,true,&quot;time_needed&quot;,null,&quot;xp&quot;,2300,&quot;topic_id&quot;,18,&quot;technology_id&quot;,2,&quot;reduced_outline&quot;,null,&quot;^1H&quot;,null,&quot;lti_only&quot;,false,&quot;instructors&quot;,[[&quot;^ &quot;,&quot;id&quot;,301837,&quot;marketing_biography&quot;,&quot;Data Scientist&quot;,&quot;biography&quot;,&quot;Hugo is a data scientist, educator, writer and podcaster formerly at DataCamp. His main interests are promoting data &amp; AI literacy, helping to spread data skills through organizations and society and doing amateur stand up comedy in NYC. If you want to know what he likes to talk about, definitely check out &lt;a href=\\\\&quot;https://www.datacamp.com/community/podcast\\\\&quot;&gt;DataFramed&lt;/a&gt;, the DataCamp podcast, which he hosted and produced.&quot;,&quot;avatar_url&quot;,&quot;https://assets.datacamp.com/authors/avatars/000/000/006/square/hugoaboutpic.jpg?1705506415&quot;,&quot;full_name&quot;,&quot;Hugo Bowne-Anderson&quot;,&quot;instructor_path&quot;,&quot;/instructors/hugobowne&quot;]],&quot;collaborators&quot;,[[&quot;^ &quot;,&quot;^26&quot;,&quot;https://assets.datacamp.com/authors/avatars/000/000/058/square/francis-photo.jpg?1705506690&quot;,&quot;^27&quot;,&quot;Francisco Castro&quot;]],&quot;datasets&quot;,[[&quot;^ &quot;,&quot;asset_url&quot;,&quot;https://assets.datacamp.com/production/repositories/488/datasets/b422ace2fceada7b569e0ba3e8d833fddc684c4d/latitude.xls&quot;,&quot;name&quot;,&quot;Latitudes (XLS)&quot;],[&quot;^ &quot;,&quot;^2;&quot;,&quot;https://assets.datacamp.com/production/repositories/488/datasets/3ef452f83a91556ea4284624b969392c0506fb33/tweets3.txt&quot;,&quot;^2&lt;&quot;,&quot;Tweets&quot;],[&quot;^ &quot;,&quot;^2;&quot;,&quot;https://assets.datacamp.com/production/repositories/488/datasets/013936d2700e2d00207ec42100d448c23692eb6f/winequality-red.csv&quot;,&quot;^2&lt;&quot;,&quot;Red wine quality&quot;]],&quot;tracks&quot;,[[&quot;^ &quot;,&quot;path&quot;,&quot;/tracks/data-engineer-in-python&quot;,&quot;title_with_subtitle&quot;,&quot;Data Engineer in Python&quot;],[&quot;^ &quot;,&quot;^2&gt;&quot;,&quot;/tracks/data-scientist-in-python&quot;,&quot;^2?&quot;,&quot;Data Scientist in Python&quot;],[&quot;^ &quot;,&quot;^2&gt;&quot;,&quot;/tracks/importing-cleaning-data-with-python&quot;,&quot;^2?&quot;,&quot;Importing &amp; Cleaning Data  in Python&quot;]],&quot;prerequisites&quot;,[[&quot;^ &quot;,&quot;^2&gt;&quot;,&quot;/courses/introduction-to-importing-data-in-python&quot;,&quot;^W&quot;,&quot;Introduction to Importing Data in Python&quot;]],&quot;time_needed_in_hours&quot;,2,&quot;seo_title&quot;,&quot;Intermediate Importing Data in Python&quot;,&quot;seo_description&quot;,&quot;Learn how to import data into Python from sources like the web and by pulling data from APIs, such as the Twitter streaming API to stream real-time tweets.&quot;,&quot;archived_at&quot;,null,&quot;original_image_url&quot;,&quot;https://assets.datacamp.com/production/course_1606/shields/original/shield_image_course_1606_20200310-1-17hkmhz?1583853940&quot;,&quot;external_slug&quot;,&quot;intermediate-importing-data-in-python&quot;,&quot;mobile_enabled&quot;,true,&quot;case_study&quot;,null,&quot;difficulty_level_hardcoded&quot;,null,&quot;long_description&quot;,null,&quot;industry_ids&quot;,[],&quot;audio_recorders&quot;,[],&quot;content_area&quot;,&quot;Data Science and Analytics&quot;,&quot;is_labeled_as_new&quot;,null,&quot;tier&quot;,null,&quot;private&quot;,false,&quot;private_access&quot;,[&quot;^ &quot;],&quot;chapters&quot;,[[&quot;^ &quot;,&quot;id&quot;,4135,&quot;^1;&quot;,null,&quot;^W&quot;,&quot;Importing data from the Internet&quot;,&quot;^X&quot;,&quot;The web is a rich source of data from which you can extract various types of insights and findings. In this chapter, you will learn how to get data from the web, whether it is stored in files or in HTML. You&#39;ll also learn the basics of scraping and parsing web data.&quot;,&quot;^1&lt;&quot;,1,&quot;^1=&quot;,&quot;importing-data-from-the-internet-1&quot;,&quot;^1&gt;&quot;,12,&quot;^1?&quot;,&quot;https://assets.datacamp.com/production/default/badges/missing.png&quot;,&quot;^1@&quot;,&quot;https://assets.datacamp.com/production/default/badges/missing_unc.png&quot;,&quot;^1A&quot;,&quot;26/09/2024&quot;,&quot;^1B&quot;,&quot;https://projector-video-pdf-converter.datacamp.com/1606/chapter1.pdf&quot;,&quot;^1C&quot;,true,&quot;xp&quot;,1050,&quot;^1D&quot;,3,&quot;^F&quot;,[[&quot;^ &quot;,&quot;^B&quot;,&quot;VideoExercise&quot;,&quot;^W&quot;,&quot;Importing flat files from the web&quot;,&quot;^1E&quot;,50,&quot;^1&lt;&quot;,1,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1?ex=1&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^W&quot;,&quot;Importing flat files from the web: your turn!&quot;,&quot;^1E&quot;,100,&quot;^1&lt;&quot;,2,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1?ex=2&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^W&quot;,&quot;Opening and reading flat files from the web&quot;,&quot;^1E&quot;,100,&quot;^1&lt;&quot;,3,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1?ex=3&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^W&quot;,&quot;Importing non-flat files from the web&quot;,&quot;^1E&quot;,100,&quot;^1&lt;&quot;,4,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1?ex=4&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;VideoExercise&quot;,&quot;^W&quot;,&quot;HTTP requests to import files from the web&quot;,&quot;^1E&quot;,50,&quot;^1&lt;&quot;,5,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1?ex=5&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^W&quot;,&quot;Performing HTTP requests in Python using urllib&quot;,&quot;^1E&quot;,100,&quot;^1&lt;&quot;,6,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1?ex=6&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^W&quot;,&quot;Printing HTTP request results in Python using urllib&quot;,&quot;^1E&quot;,100,&quot;^1&lt;&quot;,7,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1?ex=7&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^W&quot;,&quot;Performing HTTP requests in Python using requests&quot;,&quot;^1E&quot;,100,&quot;^1&lt;&quot;,8,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1?ex=8&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;VideoExercise&quot;,&quot;^W&quot;,&quot;Scraping the web in Python&quot;,&quot;^1E&quot;,50,&quot;^1&lt;&quot;,9,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1?ex=9&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^W&quot;,&quot;Parsing HTML with BeautifulSoup&quot;,&quot;^1E&quot;,100,&quot;^1&lt;&quot;,10,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1?ex=10&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^W&quot;,&quot;Turning a webpage into data using BeautifulSoup: getting the text&quot;,&quot;^1E&quot;,100,&quot;^1&lt;&quot;,11,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1?ex=11&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^W&quot;,&quot;Turning a webpage into data using BeautifulSoup: getting the hyperlinks&quot;,&quot;^1E&quot;,100,&quot;^1&lt;&quot;,12,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/importing-data-from-the-internet-1?ex=12&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null]]],[&quot;^ &quot;,&quot;id&quot;,4136,&quot;^1;&quot;,null,&quot;^W&quot;,&quot;Interacting with APIs to import data from the web&quot;,&quot;^X&quot;,&quot;In this chapter, you will gain a deeper understanding of how to import data from the web. You will learn the basics of extracting data from APIs, gain insight on the importance of APIs, and practice extracting data by diving into the OMDB and Library of Congress APIs.&quot;,&quot;^1&lt;&quot;,2,&quot;^1=&quot;,&quot;interacting-with-apis-to-import-data-from-the-web-2&quot;,&quot;^1&gt;&quot;,9,&quot;^1?&quot;,&quot;https://assets.datacamp.com/production/default/badges/missing.png&quot;,&quot;^1@&quot;,&quot;https://assets.datacamp.com/production/default/badges/missing_unc.png&quot;,&quot;^1A&quot;,&quot;26/09/2024&quot;,&quot;^1B&quot;,&quot;https://projector-video-pdf-converter.datacamp.com/1606/chapter2.pdf&quot;,&quot;^1C&quot;,null,&quot;xp&quot;,650,&quot;^1D&quot;,2,&quot;^F&quot;,[[&quot;^ &quot;,&quot;^B&quot;,&quot;VideoExercise&quot;,&quot;^W&quot;,&quot;Introduction to APIs and JSONs&quot;,&quot;^1E&quot;,50,&quot;^1&lt;&quot;,1,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/interacting-with-apis-to-import-data-from-the-web-2?ex=1&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;PureMultipleChoiceExercise&quot;,&quot;^W&quot;,&quot;Pop quiz: What exactly is a JSON?&quot;,&quot;^1E&quot;,50,&quot;^1&lt;&quot;,2,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/interacting-with-apis-to-import-data-from-the-web-2?ex=2&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^W&quot;,&quot;Loading and exploring a JSON&quot;,&quot;^1E&quot;,100,&quot;^1&lt;&quot;,3,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/interacting-with-apis-to-import-data-from-the-web-2?ex=3&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;MultipleChoiceExercise&quot;,&quot;^W&quot;,&quot;Pop quiz: Exploring your JSON&quot;,&quot;^1E&quot;,50,&quot;^1&lt;&quot;,4,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/interacting-with-apis-to-import-data-from-the-web-2?ex=4&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;VideoExercise&quot;,&quot;^W&quot;,&quot;APIs and interacting with the world wide web&quot;,&quot;^1E&quot;,50,&quot;^1&lt;&quot;,5,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/interacting-with-apis-to-import-data-from-the-web-2?ex=5&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;PureMultipleChoiceExercise&quot;,&quot;^W&quot;,&quot;Pop quiz: What&#39;s an API?&quot;,&quot;^1E&quot;,50,&quot;^1&lt;&quot;,6,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/interacting-with-apis-to-import-data-from-the-web-2?ex=6&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^W&quot;,&quot;API requests&quot;,&quot;^1E&quot;,100,&quot;^1&lt;&quot;,7,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/interacting-with-apis-to-import-data-from-the-web-2?ex=7&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^W&quot;,&quot;JSONfrom the web to Python&quot;,&quot;^1E&quot;,100,&quot;^1&lt;&quot;,8,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/interacting-with-apis-to-import-data-from-the-web-2?ex=8&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^W&quot;,&quot;Checking out the Wikipedia API&quot;,&quot;^1E&quot;,100,&quot;^1&lt;&quot;,9,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/interacting-with-apis-to-import-data-from-the-web-2?ex=9&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null]]],[&quot;^ &quot;,&quot;id&quot;,4140,&quot;^1;&quot;,null,&quot;^W&quot;,&quot;Diving  deep into the Twitter API&quot;,&quot;^X&quot;,&quot;In this chapter, you will consolidate your knowledge of interacting with APIs in a deep dive into the Twitter streaming API. You&#39;ll learn how to stream real-time Twitter data, and how to analyze and visualize it.&quot;,&quot;^1&lt;&quot;,3,&quot;^1=&quot;,&quot;diving-deep-into-the-twitter-api&quot;,&quot;^1&gt;&quot;,7,&quot;^1?&quot;,&quot;https://assets.datacamp.com/production/default/badges/missing.png&quot;,&quot;^1@&quot;,&quot;https://assets.datacamp.com/production/default/badges/missing_unc.png&quot;,&quot;^1A&quot;,&quot;26/09/2024&quot;,&quot;^1B&quot;,&quot;https://projector-video-pdf-converter.datacamp.com/1606/chapter3.pdf&quot;,&quot;^1C&quot;,null,&quot;xp&quot;,600,&quot;^1D&quot;,2,&quot;^F&quot;,[[&quot;^ &quot;,&quot;^B&quot;,&quot;VideoExercise&quot;,&quot;^W&quot;,&quot;The Twitter API and Authentication&quot;,&quot;^1E&quot;,50,&quot;^1&lt;&quot;,1,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/diving-deep-into-the-twitter-api?ex=1&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^W&quot;,&quot;Streaming tweets&quot;,&quot;^1E&quot;,100,&quot;^1&lt;&quot;,2,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/diving-deep-into-the-twitter-api?ex=2&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^W&quot;,&quot;Load and explore your Twitter data&quot;,&quot;^1E&quot;,100,&quot;^1&lt;&quot;,3,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/diving-deep-into-the-twitter-api?ex=3&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^W&quot;,&quot;Twitter data to DataFrame&quot;,&quot;^1E&quot;,100,&quot;^1&lt;&quot;,4,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/diving-deep-into-the-twitter-api?ex=4&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^W&quot;,&quot;A little bit of Twitter text analysis&quot;,&quot;^1E&quot;,100,&quot;^1&lt;&quot;,5,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/diving-deep-into-the-twitter-api?ex=5&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^W&quot;,&quot;Plotting your Twitter data&quot;,&quot;^1E&quot;,100,&quot;^1&lt;&quot;,6,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/diving-deep-into-the-twitter-api?ex=6&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null],[&quot;^ &quot;,&quot;^B&quot;,&quot;VideoExercise&quot;,&quot;^W&quot;,&quot;Final Thoughts&quot;,&quot;^1E&quot;,50,&quot;^1&lt;&quot;,7,&quot;url&quot;,&quot;https://campus.datacamp.com/courses/intermediate-importing-data-in-python/diving-deep-into-the-twitter-api?ex=7&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null]]]],&quot;course_resources&quot;,[],&quot;translated_course_id&quot;,1606]]]],&quot;^F&quot;,[&quot;^0&quot;,[&quot;^ &quot;,&quot;n&quot;,&quot;PreFetchedRequestRecord&quot;,&quot;v&quot;,[&quot;^ &quot;,&quot;^2&quot;,&quot;SUCCESS&quot;,&quot;^1:&quot;,[[&quot;^ &quot;,&quot;id&quot;,990668,&quot;^B&quot;,&quot;VideoExercise&quot;,&quot;assignment&quot;,null,&quot;^W&quot;,&quot;Importing flat files from the web&quot;,&quot;sample_code&quot;,&quot;&quot;,&quot;instructions&quot;,null,&quot;^1&lt;&quot;,1,&quot;sct&quot;,&quot;&quot;,&quot;pre_exercise_code&quot;,&quot;&quot;,&quot;solution&quot;,&quot;&quot;,&quot;hint&quot;,null,&quot;attachments&quot;,null,&quot;xp&quot;,50,&quot;possible_answers&quot;,[],&quot;feedbacks&quot;,[],&quot;question&quot;,&quot;&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null,&quot;video_link&quot;,null,&quot;video_hls&quot;,null,&quot;aspect_ratio&quot;,56.25,&quot;projector_key&quot;,&quot;course_1606_59604c018a6e132016cd26144a12fee0&quot;,&quot;key&quot;,&quot;e36457c7ed&quot;,&quot;^U&quot;,&quot;python&quot;,&quot;course_id&quot;,1606,&quot;chapter_id&quot;,4135,&quot;version&quot;,&quot;v0&quot;,&quot;randomNumber&quot;,0.8364573381546423,&quot;externalId&quot;,990668],[&quot;^ &quot;,&quot;id&quot;,42707,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^2U&quot;,&quot;&lt;p&gt;You are about to import your first file from the web! The flat file you will import will be &lt;code&gt;&#39;winequality-red.csv&#39;&lt;/code&gt; from the University of California, Irvine&#39;s &lt;a href=\\\\&quot;https://archive.ics.uci.edu/ml/index.php\\\\&quot;&gt;Machine Learning repository&lt;/a&gt;. The flat file contains tabular data of physiochemical properties of red wine, such as pH, alcohol content and citric acid content, along with wine quality rating.&lt;/p&gt;\\\\n&lt;p&gt;The URL of the file is&lt;/p&gt;\\\\n&lt;pre&gt;&lt;code&gt;&#39;https://assets.datacamp.com/production/course_1606/datasets/winequality-red.csv&#39;\\\\n&lt;/code&gt;&lt;/pre&gt;\\\\n&lt;p&gt;After you import it, you&#39;ll check your working directory to confirm that it is there and then you&#39;ll load it into a &lt;code&gt;pandas&lt;/code&gt; DataFrame.&lt;/p&gt;&quot;,&quot;^W&quot;,&quot;Importing flat files from the web: your turn!&quot;,&quot;^2V&quot;,&quot;# Import package\\\\nfrom ____ import ____\\\\n\\\\n# Import pandas\\\\nimport pandas as pd\\\\n\\\\n# Assign url of file: url\\\\n\\\\n\\\\n# Save file locally\\\\n\\\\n\\\\n# Read file into a DataFrame and print its head\\\\ndf = pd.read_csv(&#39;winequality-red.csv&#39;, sep=&#39;;&#39;)\\\\nprint(df.head())&quot;,&quot;^2W&quot;,&quot;&lt;ul&gt;\\\\n&lt;li&gt;Import the function &lt;code&gt;urlretrieve&lt;/code&gt; from the subpackage &lt;code&gt;urllib.request&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;li&gt;Assign the URL of the file to the variable &lt;code&gt;url&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;li&gt;Use the function &lt;code&gt;urlretrieve()&lt;/code&gt; to save the file locally as &lt;code&gt;&#39;winequality-red.csv&#39;&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;li&gt;Execute the remaining code to load &lt;code&gt;&#39;winequality-red.csv&#39;&lt;/code&gt; in a pandas DataFrame and to print its head to the shell.&lt;/li&gt;\\\\n&lt;/ul&gt;&quot;,&quot;^1&lt;&quot;,2,&quot;sct&quot;,&quot;Ex().has_import(\\\\&quot;urllib.request.urlretrieve\\\\&quot;)\\\\nEx().has_import(\\\\&quot;pandas\\\\&quot;)\\\\nEx().check_object(\\\\&quot;url\\\\&quot;).has_equal_value()\\\\nEx().check_function(\\\\&quot;urllib.request.urlretrieve\\\\&quot;).multi(\\\\n  check_args(0).has_equal_value(),\\\\n  check_args(1).has_equal_value()\\\\n)\\\\nEx().check_correct(\\\\n  check_object(\\\\&quot;df\\\\&quot;).has_equal_value(),\\\\n  check_function(\\\\&quot;pandas.read_csv\\\\&quot;).multi(\\\\n    check_args(0).has_equal_value(),\\\\n    check_args(1).has_equal_value()\\\\n  )\\\\n)\\\\nEx().has_printout(0)\\\\nsuccess_msg(\\\\&quot;Awesome!\\\\&quot;)\\\\n&quot;,&quot;^2X&quot;,&quot;&quot;,&quot;^2Y&quot;,&quot;# Import package\\\\nfrom urllib.request import urlretrieve\\\\n\\\\n# Import pandas\\\\nimport pandas as pd\\\\n\\\\n# Assign url of file: url\\\\nurl = &#39;https://assets.datacamp.com/production/course_1606/datasets/winequality-red.csv&#39;\\\\n\\\\n# Save file locally\\\\nurlretrieve(url, &#39;winequality-red.csv&#39;)\\\\n\\\\n# Read file into a DataFrame and print its head\\\\ndf = pd.read_csv(&#39;winequality-red.csv&#39;, sep=&#39;;&#39;)\\\\nprint(df.head())&quot;,&quot;^2Z&quot;,&quot;&lt;ul&gt;\\\\n&lt;li&gt;To import a function &lt;code&gt;y&lt;/code&gt; from a subpackage &lt;code&gt;x&lt;/code&gt;, execute &lt;code&gt;from x import y&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;li&gt;This one&#39;s a long URL. Make sure you typed it in correctly!&lt;/li&gt;\\\\n&lt;li&gt;Pass the &lt;em&gt;url&lt;/em&gt; to import (in the &lt;code&gt;url&lt;/code&gt; object you defined) as the first argument and the &lt;em&gt;filename&lt;/em&gt; for saving the file locally as the second argument to &lt;code&gt;urlretrieve()&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;li&gt;You don&#39;t have to change the code for loading &lt;code&gt;&#39;winequality-red.csv&#39;&lt;/code&gt; and printing its head.&lt;/li&gt;\\\\n&lt;/ul&gt;&quot;,&quot;^2[&quot;,null,&quot;xp&quot;,100,&quot;^30&quot;,[],&quot;^31&quot;,[],&quot;^32&quot;,&quot;&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null,&quot;^U&quot;,&quot;python&quot;,&quot;^3:&quot;,0.13306885324133644,&quot;^3;&quot;,42707],[&quot;^ &quot;,&quot;id&quot;,42708,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^2U&quot;,&quot;&lt;p&gt;You have just imported a file from the web, saved it locally and loaded it into a DataFrame. If you just wanted to load a file from the web into a DataFrame without first saving it locally, you can do that easily using &lt;code&gt;pandas&lt;/code&gt;. In particular, you can use the function &lt;code&gt;pd.read_csv()&lt;/code&gt; with the URL as the first argument and the separator &lt;code&gt;sep&lt;/code&gt; as the second argument.&lt;/p&gt;\\\\n&lt;p&gt;The URL of the file, once again, is&lt;/p&gt;\\\\n&lt;pre&gt;&lt;code&gt;&#39;https://assets.datacamp.com/production/course_1606/datasets/winequality-red.csv&#39;\\\\n&lt;/code&gt;&lt;/pre&gt;&quot;,&quot;^W&quot;,&quot;Opening and reading flat files from the web&quot;,&quot;^2V&quot;,&quot;# Import packages\\\\nimport matplotlib.pyplot as plt\\\\nimport pandas as pd\\\\n\\\\n# Assign url of file: url\\\\n\\\\n\\\\n# Read file into a DataFrame: df\\\\n\\\\n\\\\n# Print the head of the DataFrame\\\\nprint(____)\\\\n\\\\n# Plot first column of df\\\\ndf.iloc[:, 0].hist()\\\\nplt.xlabel(&#39;fixed acidity (g(tartaric acid)/dm$^3$)&#39;)\\\\nplt.ylabel(&#39;count&#39;)\\\\nplt.show()\\\\n&quot;,&quot;^2W&quot;,&quot;&lt;ul&gt;\\\\n&lt;li&gt;Assign the URL of the file to the variable &lt;code&gt;url&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;li&gt;Read file into a DataFrame &lt;code&gt;df&lt;/code&gt; using &lt;code&gt;pd.read_csv()&lt;/code&gt;, recalling that the separator in the file is &lt;code&gt;&#39;;&#39;&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;li&gt;Print the head of the DataFrame &lt;code&gt;df&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;li&gt;Execute the rest of the code to plot histogram of the first feature in the DataFrame &lt;code&gt;df&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;/ul&gt;&quot;,&quot;^1&lt;&quot;,3,&quot;sct&quot;,&quot;Ex().has_import(\\\\&quot;matplotlib.pyplot\\\\&quot;)\\\\nEx().has_import(\\\\&quot;pandas\\\\&quot;)\\\\nEx().check_object(\\\\&quot;url\\\\&quot;).has_equal_value()\\\\nEx().check_correct(\\\\n  check_object(\\\\&quot;df\\\\&quot;).has_equal_value(),\\\\n  check_function(\\\\&quot;pandas.read_csv\\\\&quot;).multi(\\\\n    check_args(0).has_equal_value(),\\\\n    check_args(1).has_equal_value()\\\\n  )\\\\n)\\\\nEx().has_printout(0)\\\\nEx().has_equal_ast(code=\\\\&quot;df.iloc[:, 0].hist\\\\&quot;, incorrect_msg=\\\\&quot;Please do not change the code to plot the histogram.\\\\&quot;)\\\\nEx().check_function(\\\\&quot;matplotlib.pyplot.show\\\\&quot;)\\\\n\\\\nsuccess_msg(\\\\&quot;Awesome!\\\\&quot;)\\\\n&quot;,&quot;^2X&quot;,&quot;&quot;,&quot;^2Y&quot;,&quot;# Import packages\\\\nimport matplotlib.pyplot as plt\\\\nimport pandas as pd\\\\n\\\\n# Assign url of file: url\\\\nurl = &#39;https://assets.datacamp.com/production/course_1606/datasets/winequality-red.csv&#39;\\\\n\\\\n# Read file into a DataFrame: df\\\\ndf = pd.read_csv(url, sep=&#39;;&#39;)\\\\n\\\\n# Print the head of the DataFrame\\\\nprint(df.head())\\\\n\\\\n# Plot first column of df\\\\ndf.iloc[:, 0].hist()\\\\nplt.xlabel(&#39;fixed acidity (g(tartaric acid)/dm$^3$)&#39;)\\\\nplt.ylabel(&#39;count&#39;)\\\\nplt.show()\\\\n&quot;,&quot;^2Z&quot;,&quot;&lt;ul&gt;\\\\n&lt;li&gt;Make sure you typed the URL correctly!&lt;/li&gt;\\\\n&lt;li&gt;Pass the &lt;em&gt;url&lt;/em&gt; (the &lt;code&gt;url&lt;/code&gt; object you defined) as the first argument and the &lt;em&gt;separator&lt;/em&gt; as the second argument to &lt;code&gt;pd.read_csv()&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;li&gt;The &lt;em&gt;head&lt;/em&gt; of a DataFrame can be accessed by using &lt;code&gt;head()&lt;/code&gt; on the DataFrame.&lt;/li&gt;\\\\n&lt;li&gt;You don&#39;t have to change any of the code for plotting the histograms.&lt;/li&gt;\\\\n&lt;/ul&gt;&quot;,&quot;^2[&quot;,null,&quot;xp&quot;,100,&quot;^30&quot;,[],&quot;^31&quot;,[],&quot;^32&quot;,&quot;&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null,&quot;^U&quot;,&quot;python&quot;,&quot;^3:&quot;,0.7785533906387767,&quot;^3;&quot;,42708],[&quot;^ &quot;,&quot;id&quot;,42709,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^2U&quot;,&quot;&lt;p&gt;Congrats! You&#39;ve just loaded a flat file from the web into a DataFrame without first saving it locally using the &lt;code&gt;pandas&lt;/code&gt; function &lt;code&gt;pd.read_csv()&lt;/code&gt;. This function is super cool because it has close relatives that allow you to load all types of files, not only flat ones. In this interactive exercise, you&#39;ll use &lt;code&gt;pd.read_excel()&lt;/code&gt; to import an Excel spreadsheet.&lt;/p&gt;\\\\n&lt;p&gt;The URL of the spreadsheet is&lt;/p&gt;\\\\n&lt;pre&gt;&lt;code&gt;&#39;https://assets.datacamp.com/course/importing_data_into_r/latitude.xls&#39;\\\\n&lt;/code&gt;&lt;/pre&gt;\\\\n&lt;p&gt;Your job is to use &lt;code&gt;pd.read_excel()&lt;/code&gt; to read in all of its sheets, print the sheet names and then print the head of the first sheet &lt;em&gt;using its name, not its index&lt;/em&gt;.&lt;/p&gt;\\\\n&lt;p&gt;Note that the output of &lt;code&gt;pd.read_excel()&lt;/code&gt; is a Python dictionary with sheet names as keys and corresponding DataFrames as corresponding values.&lt;/p&gt;&quot;,&quot;^W&quot;,&quot;Importing non-flat files from the web&quot;,&quot;^2V&quot;,&quot;# Import package\\\\nimport pandas as pd\\\\n\\\\n# Assign url of file: url\\\\n\\\\n\\\\n# Read in all sheets of Excel file: xls\\\\n\\\\n\\\\n# Print the sheetnames to the shell\\\\n\\\\n\\\\n# Print the head of the first sheet (using its name, NOT its index)\\\\n\\\\n&quot;,&quot;^2W&quot;,&quot;&lt;ul&gt;\\\\n&lt;li&gt;Assign the URL of the file to the variable &lt;code&gt;url&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;li&gt;Read the file in &lt;code&gt;url&lt;/code&gt; into a dictionary &lt;code&gt;xls&lt;/code&gt; using &lt;code&gt;pd.read_excel()&lt;/code&gt; recalling that, in order to import all sheets you need to pass &lt;code&gt;None&lt;/code&gt; to the argument &lt;code&gt;sheet_name&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;li&gt;Print the names of the sheets in the Excel spreadsheet; these will be the keys of the dictionary &lt;code&gt;xls&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;li&gt;Print the head of the first sheet &lt;em&gt;using the sheet name, not the index of the sheet&lt;/em&gt;! The sheet name is &lt;code&gt;&#39;1700&#39;&lt;/code&gt;&lt;/li&gt;\\\\n&lt;/ul&gt;&quot;,&quot;^1&lt;&quot;,4,&quot;sct&quot;,&quot;Ex().has_import(&#39;pandas&#39;)\\\\nEx().check_correct(\\\\n    has_printout(0),\\\\n    multi(\\\\n        check_correct(\\\\n            check_object(&#39;xls&#39;).is_instance(dict),\\\\n            check_correct(\\\\n                check_function(&#39;pandas.read_excel&#39;).multi(\\\\n                    check_args(0).has_equal_value(),\\\\n                    check_args(&#39;sheet_name&#39;).has_equal_value()\\\\n                ),\\\\n                check_object(&#39;url&#39;).has_equal_value()\\\\n            )\\\\n        )\\\\n    )\\\\n)\\\\nEx().has_printout(1)\\\\nsuccess_msg(\\\\&quot;Awesome!\\\\&quot;)&quot;,&quot;^2X&quot;,&quot;&quot;,&quot;^2Y&quot;,&quot;# Import package\\\\nimport pandas as pd\\\\n\\\\n# Assign url of file: url\\\\nurl = &#39;https://assets.datacamp.com/course/importing_data_into_r/latitude.xls&#39;\\\\n\\\\n# Read in all sheets of Excel file: xls\\\\nxls = pd.read_excel(url, sheet_name=None)\\\\n\\\\n# Print the sheetnames to the shell\\\\nprint(xls.keys())\\\\n\\\\n# Print the head of the first sheet (using its name, NOT its index)\\\\nprint(xls[&#39;1700&#39;].head())&quot;,&quot;^2Z&quot;,&quot;&lt;ul&gt;\\\\n&lt;li&gt;Make sure you typed in the URL correctly!&lt;/li&gt;\\\\n&lt;li&gt;Pass the &lt;em&gt;url&lt;/em&gt; (the &lt;code&gt;url&lt;/code&gt; object you defined) as the first argument and &lt;code&gt;sheet_name&lt;/code&gt; with its corresponding value as the second argument to &lt;code&gt;pd.read_excel()&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;li&gt;The &lt;em&gt;keys&lt;/em&gt; of a dictionary can be accessed by using &lt;code&gt;keys()&lt;/code&gt; on the dictionary.&lt;/li&gt;\\\\n&lt;li&gt;You can access a sheet using the format: &lt;em&gt;dictionary&lt;/em&gt;&lt;strong&gt;[&lt;/strong&gt;&lt;em&gt;sheet name or index&lt;/em&gt;&lt;strong&gt;]&lt;/strong&gt;.&lt;/li&gt;\\\\n&lt;/ul&gt;&quot;,&quot;^2[&quot;,null,&quot;xp&quot;,100,&quot;^30&quot;,[],&quot;^31&quot;,[],&quot;^32&quot;,&quot;&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null,&quot;^U&quot;,&quot;python&quot;,&quot;^3:&quot;,0.29677029636305896,&quot;^3;&quot;,42709],[&quot;^ &quot;,&quot;id&quot;,990669,&quot;^B&quot;,&quot;VideoExercise&quot;,&quot;^2U&quot;,null,&quot;^W&quot;,&quot;HTTP requests to import files from the web&quot;,&quot;^2V&quot;,&quot;&quot;,&quot;^2W&quot;,null,&quot;^1&lt;&quot;,5,&quot;sct&quot;,&quot;&quot;,&quot;^2X&quot;,&quot;&quot;,&quot;^2Y&quot;,&quot;&quot;,&quot;^2Z&quot;,null,&quot;^2[&quot;,null,&quot;xp&quot;,50,&quot;^30&quot;,[],&quot;^31&quot;,[],&quot;^32&quot;,&quot;&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null,&quot;^33&quot;,null,&quot;^34&quot;,null,&quot;^35&quot;,56.25,&quot;^36&quot;,&quot;course_1606_9d15ae176be1800b996f7869a82b8087&quot;,&quot;key&quot;,&quot;e480d1fdcf&quot;,&quot;^U&quot;,&quot;python&quot;,&quot;^37&quot;,1606,&quot;^38&quot;,4135,&quot;^39&quot;,&quot;v0&quot;,&quot;^3:&quot;,0.08513839239732768,&quot;^3;&quot;,990669],[&quot;^ &quot;,&quot;id&quot;,42711,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^2U&quot;,&quot;&lt;p&gt;Now that you know the basics behind HTTP GET requests, it&#39;s time to perform some of your own. In this interactive exercise, you will ping our very own DataCamp servers to perform a GET request to extract information from the first coding exercise of this course, &lt;code&gt;\\\\&quot;https://campus.datacamp.com/courses/1606/4135?ex=2\\\\&quot;&lt;/code&gt;.&lt;/p&gt;\\\\n&lt;p&gt;In the next exercise, you&#39;ll extract the HTML itself. Right now, however, you are going to package and send the request and then catch the response.&lt;/p&gt;&quot;,&quot;^W&quot;,&quot;Performing HTTP requests in Python using urllib&quot;,&quot;^2V&quot;,&quot;# Import packages\\\\n\\\\n\\\\n# Specify the url\\\\nurl = \\\\&quot;https://campus.datacamp.com/courses/1606/4135?ex=2\\\\&quot;\\\\n\\\\n# This packages the request: request\\\\n\\\\n\\\\n# Sends the request and catches the response: response\\\\n\\\\n\\\\n# Print the datatype of response\\\\nprint(type(response))\\\\n\\\\n# Be polite and close the response!\\\\nresponse.close()\\\\n&quot;,&quot;^2W&quot;,&quot;&lt;ul&gt;\\\\n&lt;li&gt;Import the functions &lt;code&gt;urlopen&lt;/code&gt; and &lt;code&gt;Request&lt;/code&gt; from the subpackage &lt;code&gt;urllib.request&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;li&gt;Package the request to the url &lt;code&gt;\\\\&quot;https://campus.datacamp.com/courses/1606/4135?ex=2\\\\&quot;&lt;/code&gt; using the function &lt;code&gt;Request()&lt;/code&gt; and assign it to &lt;code&gt;request&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;li&gt;Send the request and catch the response in the variable &lt;code&gt;response&lt;/code&gt; with  the function &lt;code&gt;urlopen()&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;li&gt;Run the rest of the code to see the datatype of &lt;code&gt;response&lt;/code&gt; and to close the connection!&lt;/li&gt;\\\\n&lt;/ul&gt;&quot;,&quot;^1&lt;&quot;,6,&quot;sct&quot;,&quot;\\\\n# Test: import urlopen, Request\\\\nimport_msg = \\\\&quot;Did you correctly import the required packages?\\\\&quot;\\\\nEx().has_import(\\\\n    \\\\&quot;urllib.request.urlopen\\\\&quot;,\\\\n    not_imported_msg=import_msg\\\\n)\\\\nEx().has_import(\\\\n    \\\\&quot;urllib.request.Request\\\\&quot;,\\\\n    not_imported_msg=import_msg\\\\n)\\\\n\\\\n# Test: Predefined code\\\\npredef_msg = \\\\&quot;You don&#39;t have to change any of the predefined code.\\\\&quot;\\\\nEx().check_object(\\\\&quot;url\\\\&quot;, missing_msg=predef_msg).has_equal_value(incorrect_msg = predef_msg)\\\\n\\\\n# Test: call to Request() and &#39;request&#39; variable\\\\nEx().check_function(\\\\&quot;urllib.request.Request\\\\&quot;).check_args(0).has_equal_value()\\\\nEx().check_object(\\\\&quot;request\\\\&quot;)\\\\n  \\\\n# Test: call to urlopen() and &#39;response&#39; variable\\\\nEx().check_function(\\\\&quot;urllib.request.urlopen\\\\&quot;).check_args(0).has_equal_ast()\\\\nEx().check_object(\\\\&quot;response\\\\&quot;),\\\\n\\\\n# Test: Predefined code\\\\nEx().has_printout(0)\\\\nEx().check_function(\\\\&quot;response.close\\\\&quot;)\\\\n\\\\nsuccess_msg(\\\\&quot;Awesome!\\\\&quot;)\\\\n&quot;,&quot;^2X&quot;,&quot;&quot;,&quot;^2Y&quot;,&quot;# Import packages\\\\nfrom urllib.request import urlopen, Request\\\\n\\\\n# Specify the url\\\\nurl = \\\\&quot;https://campus.datacamp.com/courses/1606/4135?ex=2\\\\&quot;\\\\n\\\\n# This packages the request: request\\\\nrequest = Request(url)\\\\n\\\\n# Sends the request and catches the response: response\\\\nresponse = urlopen(request)\\\\n\\\\n# Print the datatype of response\\\\nprint(type(response))\\\\n\\\\n# Be polite and close the response!\\\\nresponse.close()\\\\n&quot;,&quot;^2Z&quot;,&quot;&lt;ul&gt;\\\\n&lt;li&gt;To import two functions in one line, import the first function as usual and add a comma &lt;code&gt;,&lt;/code&gt; followed by the second function.&lt;/li&gt;\\\\n&lt;li&gt;Pass the &lt;em&gt;url&lt;/em&gt; (already in the &lt;code&gt;url&lt;/code&gt; object defined) as an argument to &lt;code&gt;Request()&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;li&gt;Pass &lt;code&gt;request&lt;/code&gt; as an argument to &lt;code&gt;urlopen()&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;li&gt;You don&#39;t have to modify the code for printing the datatype of &lt;code&gt;response&lt;/code&gt; and closing the connection.&lt;/li&gt;\\\\n&lt;/ul&gt;&quot;,&quot;^2[&quot;,null,&quot;xp&quot;,100,&quot;^30&quot;,[],&quot;^31&quot;,[],&quot;^32&quot;,&quot;&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null,&quot;^U&quot;,&quot;python&quot;,&quot;^3:&quot;,0.025167267893165146,&quot;^3;&quot;,42711],[&quot;^ &quot;,&quot;id&quot;,42712,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^2U&quot;,&quot;&lt;p&gt;You have just packaged and sent a GET request to &lt;code&gt;\\\\&quot;https://campus.datacamp.com/courses/1606/4135?ex=2\\\\&quot;&lt;/code&gt; and then caught the response. You saw that such a response is a &lt;code&gt;http.client.HTTPResponse&lt;/code&gt; object. The question remains: what can you do with this response?&lt;/p&gt;\\\\n&lt;p&gt;Well, as it came from an HTML page, you could &lt;em&gt;read&lt;/em&gt; it to extract the HTML and, in fact, such a &lt;code&gt;http.client.HTTPResponse&lt;/code&gt; object has an associated &lt;code&gt;read()&lt;/code&gt; method. In this exercise, you&#39;ll build on your previous great work to extract the response and print the HTML.&lt;/p&gt;&quot;,&quot;^W&quot;,&quot;Printing HTTP request results in Python using urllib&quot;,&quot;^2V&quot;,&quot;# Import packages\\\\nfrom urllib.request import urlopen, Request\\\\n\\\\n# Specify the url\\\\nurl = \\\\&quot;https://campus.datacamp.com/courses/1606/4135?ex=2\\\\&quot;\\\\n\\\\n# This packages the request\\\\nrequest = Request(url)\\\\n\\\\n# Sends the request and catches the response: response\\\\n\\\\n\\\\n# Extract the response: html\\\\n\\\\n\\\\n# Print the html\\\\n\\\\n\\\\n# Be polite and close the response!\\\\nresponse.close()&quot;,&quot;^2W&quot;,&quot;&lt;ul&gt;\\\\n&lt;li&gt;Send the request and catch the response in the variable &lt;code&gt;response&lt;/code&gt; with the function &lt;code&gt;urlopen()&lt;/code&gt;, as in the previous exercise.&lt;/li&gt;\\\\n&lt;li&gt;Extract the response using the &lt;code&gt;read()&lt;/code&gt; method and store the result in the variable &lt;code&gt;html&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;li&gt;Print the string &lt;code&gt;html&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;li&gt;Hit submit to perform all of the above and to close the response: be tidy!&lt;/li&gt;\\\\n&lt;/ul&gt;&quot;,&quot;^1&lt;&quot;,7,&quot;sct&quot;,&quot;\\\\n# Test: Predefined code\\\\npredef_msg = \\\\&quot;You don&#39;t have to change any of the predefined code.\\\\&quot;\\\\nEx().has_import(\\\\n    \\\\&quot;urllib.request.urlopen\\\\&quot;,\\\\n    not_imported_msg=predef_msg\\\\n)\\\\n\\\\nEx().has_import(\\\\n    \\\\&quot;urllib.request.Request\\\\&quot;,\\\\n    not_imported_msg=predef_msg\\\\n)\\\\n\\\\nEx().check_object(\\\\&quot;url\\\\&quot;).has_equal_value()\\\\n\\\\n# Test: call to Request() and &#39;request&#39; variable\\\\nEx().check_function(\\\\&quot;urllib.request.Request\\\\&quot;).check_args(0).has_equal_value()\\\\nEx().check_object(\\\\&quot;request\\\\&quot;)\\\\n\\\\n# Test: call to urlopen() and &#39;response&#39; variable\\\\nEx().check_function(\\\\&quot;urllib.request.urlopen\\\\&quot;).check_args(0).has_equal_ast()\\\\nEx().check_object(\\\\&quot;response\\\\&quot;)\\\\n\\\\n# Test: call to urlopen() and &#39;response&#39; variable\\\\nEx().check_function(\\\\&quot;response.read\\\\&quot;)\\\\nEx().check_object(\\\\&quot;html\\\\&quot;)\\\\n\\\\n# Test: call to print()\\\\nEx().check_function(&#39;print&#39;).check_args(0).has_equal_ast()\\\\n\\\\n# Test: Predefined code\\\\nEx().check_function(\\\\&quot;response.close\\\\&quot;)\\\\n\\\\nsuccess_msg(\\\\&quot;Awesome!\\\\&quot;)\\\\n&quot;,&quot;^2X&quot;,&quot;&quot;,&quot;^2Y&quot;,&quot;# Import packages\\\\nfrom urllib.request import urlopen, Request\\\\n\\\\n# Specify the url\\\\nurl = \\\\&quot;https://campus.datacamp.com/courses/1606/4135?ex=2\\\\&quot;\\\\n\\\\n# This packages the request\\\\nrequest = Request(url)\\\\n\\\\n# Sends the request and catches the response: response\\\\nresponse = urlopen(request)\\\\n\\\\n# Extract the response: html\\\\nhtml = response.read()\\\\n\\\\n# Print the html\\\\nprint(html)\\\\n\\\\n# Be polite and close the response!\\\\nresponse.close()&quot;,&quot;^2Z&quot;,&quot;&lt;ul&gt;\\\\n&lt;li&gt;Pass &lt;code&gt;request&lt;/code&gt; as an argument to &lt;code&gt;urlopen()&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;li&gt;Apply the method &lt;code&gt;read()&lt;/code&gt; to the response object &lt;code&gt;response&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;li&gt;Simply pass &lt;code&gt;html&lt;/code&gt; to the &lt;code&gt;print()&lt;/code&gt; function.&lt;/li&gt;\\\\n&lt;li&gt;You don&#39;t have to modify the code for closing the response.&lt;/li&gt;\\\\n&lt;/ul&gt;&quot;,&quot;^2[&quot;,null,&quot;xp&quot;,100,&quot;^30&quot;,[],&quot;^31&quot;,[],&quot;^32&quot;,&quot;&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null,&quot;^U&quot;,&quot;python&quot;,&quot;^3:&quot;,0.8963620619853123,&quot;^3;&quot;,42712],[&quot;^ &quot;,&quot;id&quot;,42713,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^2U&quot;,&quot;&lt;p&gt;Now that you&#39;ve got your head and hands around making HTTP requests using the urllib package, you&#39;re going to figure out how to do the same using the higher-level requests library. You&#39;ll once again be pinging DataCamp servers for their &lt;code&gt;\\\\&quot;http://www.datacamp.com/teach/documentation\\\\&quot;&lt;/code&gt; page.&lt;/p&gt;\\\\n&lt;p&gt;Note that unlike in the previous exercises using urllib, you don&#39;t have to close the connection when using requests!&lt;/p&gt;&quot;,&quot;^W&quot;,&quot;Performing HTTP requests in Python using requests&quot;,&quot;^2V&quot;,&quot;# Import package\\\\n\\\\n\\\\n# Specify the url: url\\\\n\\\\n\\\\n# Packages the request, send the request and catch the response: r\\\\n\\\\n\\\\n# Extract the response: text\\\\n\\\\n\\\\n# Print the html\\\\nprint(text)&quot;,&quot;^2W&quot;,&quot;&lt;ul&gt;\\\\n&lt;li&gt;Import the package &lt;code&gt;requests&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;li&gt;Assign the URL of interest to the variable &lt;code&gt;url&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;li&gt;Package the request to the URL, send the request and catch the response with a single function &lt;code&gt;requests.get()&lt;/code&gt;, assigning the response to the variable &lt;code&gt;r&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;li&gt;Use the &lt;code&gt;text&lt;/code&gt; attribute of the object &lt;code&gt;r&lt;/code&gt; to return the HTML of the webpage as a string; store the result in a variable &lt;code&gt;text&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;li&gt;Hit submit to print the HTML of the webpage.&lt;/li&gt;\\\\n&lt;/ul&gt;&quot;,&quot;^1&lt;&quot;,8,&quot;sct&quot;,&quot;\\\\n# Test: import requests\\\\nEx().has_import(\\\\&quot;requests\\\\&quot;)\\\\n\\\\n# Test: &#39;url&#39; variable\\\\nEx().check_object(\\\\&quot;url\\\\&quot;).has_equal_value()\\\\n\\\\n# Test: call to requests.get() and &#39;r&#39; variable\\\\nEx().check_function(\\\\&quot;requests.get\\\\&quot;).check_args(0).has_equal_value()\\\\nEx().check_object(\\\\&quot;r\\\\&quot;)\\\\n\\\\n# Test: &#39;text&#39; variable\\\\nEx().has_code(\\\\&quot;r.text\\\\&quot;, pattern = False, not_typed_msg=\\\\&quot;Have you used `r.text` to create `text`?\\\\&quot;)\\\\nEx().check_object(\\\\&quot;text\\\\&quot;)\\\\n\\\\n# Test: Predefined code\\\\nEx().check_function(&#39;print&#39;).check_args(0).has_equal_ast()\\\\n\\\\nsuccess_msg(\\\\&quot;Awesome!\\\\&quot;)\\\\n&quot;,&quot;^2X&quot;,&quot;&quot;,&quot;^2Y&quot;,&quot;# Import package\\\\nimport requests\\\\n\\\\n# Specify the url: url\\\\nurl = \\\\&quot;http://www.datacamp.com/teach/documentation\\\\&quot;\\\\n\\\\n# Packages the request, send the request and catch the response: r\\\\nr = requests.get(url)\\\\n\\\\n# Extract the response: text\\\\ntext = r.text\\\\n\\\\n# Print the html\\\\nprint(text)&quot;,&quot;^2Z&quot;,&quot;&lt;ul&gt;\\\\n&lt;li&gt;To import a package &lt;code&gt;x&lt;/code&gt;, execute &lt;code&gt;import x&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;li&gt;Did you type in the URL correctly?&lt;/li&gt;\\\\n&lt;li&gt;Pass the &lt;em&gt;url&lt;/em&gt; (the &lt;code&gt;url&lt;/code&gt; object you defined) as an argument to &lt;code&gt;requests.get()&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;li&gt;You can access the &lt;code&gt;text&lt;/code&gt; attribute of the object &lt;code&gt;r&lt;/code&gt; by executing &lt;code&gt;r.text&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;li&gt;You don&#39;t have to modify the code for printing the HTML of the webpage.&lt;/li&gt;\\\\n&lt;/ul&gt;&quot;,&quot;^2[&quot;,null,&quot;xp&quot;,100,&quot;^30&quot;,[],&quot;^31&quot;,[],&quot;^32&quot;,&quot;&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null,&quot;^U&quot;,&quot;python&quot;,&quot;^3:&quot;,0.9499234036356423,&quot;^3;&quot;,42713],[&quot;^ &quot;,&quot;id&quot;,990670,&quot;^B&quot;,&quot;VideoExercise&quot;,&quot;^2U&quot;,null,&quot;^W&quot;,&quot;Scraping the web in Python&quot;,&quot;^2V&quot;,&quot;&quot;,&quot;^2W&quot;,null,&quot;^1&lt;&quot;,9,&quot;sct&quot;,&quot;&quot;,&quot;^2X&quot;,&quot;&quot;,&quot;^2Y&quot;,&quot;&quot;,&quot;^2Z&quot;,null,&quot;^2[&quot;,null,&quot;xp&quot;,50,&quot;^30&quot;,[],&quot;^31&quot;,[],&quot;^32&quot;,&quot;&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null,&quot;^33&quot;,null,&quot;^34&quot;,null,&quot;^35&quot;,56.25,&quot;^36&quot;,&quot;course_1606_9d1f8a331d1200c7e1bdbfcaf3a7a491&quot;,&quot;key&quot;,&quot;da43858012&quot;,&quot;^U&quot;,&quot;python&quot;,&quot;^37&quot;,1606,&quot;^38&quot;,4135,&quot;^39&quot;,&quot;v0&quot;,&quot;^3:&quot;,0.6150986604311994,&quot;^3;&quot;,990670],[&quot;^ &quot;,&quot;id&quot;,42715,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^2U&quot;,&quot;&lt;p&gt;In this interactive exercise, you&#39;ll learn how to use the BeautifulSoup package to &lt;em&gt;parse&lt;/em&gt;, &lt;em&gt;prettify&lt;/em&gt; and &lt;em&gt;extract&lt;/em&gt; information from HTML. You&#39;ll scrape the data from the webpage of Guido van Rossum, Python&#39;s very own &lt;a href=\\\\&quot;https://en.wikipedia.org/wiki/Benevolent_dictator_for_life\\\\&quot;&gt;Benevolent Dictator for Life&lt;/a&gt;. In the following exercises, you&#39;ll prettify the HTML and then extract the text and the hyperlinks.&lt;/p&gt;\\\\n&lt;p&gt;The URL of interest is &lt;code&gt;url = &#39;https://www.python.org/~guido/&#39;&lt;/code&gt;.&lt;/p&gt;&quot;,&quot;^W&quot;,&quot;Parsing HTML with BeautifulSoup&quot;,&quot;^2V&quot;,&quot;# Import packages\\\\nimport requests\\\\nfrom ____ import ____\\\\n\\\\n# Specify url: url\\\\n\\\\n\\\\n# Package the request, send the request and catch the response: r\\\\n\\\\n\\\\n# Extracts the response as html: html_doc\\\\n\\\\n\\\\n# Create a BeautifulSoup object from the HTML: soup\\\\n\\\\n\\\\n# Prettify the BeautifulSoup object: pretty_soup\\\\n\\\\n\\\\n# Print the response\\\\nprint(pretty_soup)&quot;,&quot;^2W&quot;,&quot;&lt;ul&gt;\\\\n&lt;li&gt;Import the function &lt;code&gt;BeautifulSoup&lt;/code&gt; from the package &lt;code&gt;bs4&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;li&gt;Assign the URL of interest to the variable &lt;code&gt;url&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;li&gt;Package the request to the URL, send the request and catch the response with a single function &lt;code&gt;requests.get()&lt;/code&gt;, assigning the response to the variable &lt;code&gt;r&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;li&gt;Use the &lt;code&gt;text&lt;/code&gt; attribute of the object &lt;code&gt;r&lt;/code&gt; to return the HTML of the webpage as a string; store the result in a variable &lt;code&gt;html_doc&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;li&gt;Create a BeautifulSoup object &lt;code&gt;soup&lt;/code&gt; from the resulting HTML using the function &lt;code&gt;BeautifulSoup()&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;li&gt;Use the method &lt;code&gt;prettify()&lt;/code&gt; on &lt;code&gt;soup&lt;/code&gt; and assign the result to &lt;code&gt;pretty_soup&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;li&gt;Hit submit to print to prettified HTML to your shell!&lt;/li&gt;\\\\n&lt;/ul&gt;&quot;,&quot;^1&lt;&quot;,10,&quot;sct&quot;,&quot;# Test: Predefined code\\\\npredef_msg = \\\\&quot;You don&#39;t have to change any of the predefined code.\\\\&quot;\\\\nEx().has_import(\\\\n    \\\\&quot;requests\\\\&quot;,\\\\n    not_imported_msg=predef_msg\\\\n)\\\\n\\\\n# Test: import BeautifulSoup\\\\nimport_msg = \\\\&quot;Did you correctly import the required packages?\\\\&quot;\\\\nEx().has_import(\\\\n    \\\\&quot;bs4.BeautifulSoup\\\\&quot;,\\\\n    not_imported_msg=import_msg\\\\n)\\\\n\\\\n# Test: &#39;url&#39; variable\\\\nEx().check_object(\\\\&quot;url\\\\&quot;).has_equal_value()\\\\n\\\\n# Test: call to requests.get() and &#39;r&#39; variable\\\\nEx().check_function(\\\\&quot;requests.get\\\\&quot;).check_args(0).has_equal_value()\\\\nEx().check_object(\\\\&quot;r\\\\&quot;)\\\\n\\\\n\\\\n# Test: &#39;html_doc&#39; variable\\\\nEx().check_correct(\\\\n  check_object(\\\\&quot;html_doc\\\\&quot;).has_equal_value(),\\\\n  has_code(\\\\&quot;r.text\\\\&quot;, pattern = False, not_typed_msg=\\\\&quot;Have you used `r.text` to create `html_doc`?\\\\&quot;)\\\\n)\\\\n\\\\n# Test: call to BeautifulSoup() and &#39;soup&#39; variable\\\\nEx().check_correct(\\\\n  check_object(\\\\&quot;soup\\\\&quot;).has_equal_value(),\\\\n  check_function(\\\\&quot;bs4.BeautifulSoup\\\\&quot;).check_args(0).has_equal_value()\\\\n  )\\\\n\\\\n# Test: call to prettify() and &#39;pretty_soup&#39; variable\\\\nEx().check_correct(\\\\n  check_object(\\\\&quot;pretty_soup\\\\&quot;).has_equal_value(),\\\\n  check_function(\\\\&quot;soup.prettify\\\\&quot;)\\\\n  )\\\\n\\\\n# Test: Predefined code\\\\nEx().has_printout(0)\\\\n\\\\nsuccess_msg(\\\\&quot;Awesome!\\\\&quot;)\\\\n&quot;,&quot;^2X&quot;,&quot;&quot;,&quot;^2Y&quot;,&quot;# Import packages\\\\nimport requests\\\\nfrom bs4 import BeautifulSoup\\\\n\\\\n# Specify url: url\\\\nurl = &#39;https://www.python.org/~guido/&#39;\\\\n\\\\n# Package the request, send the request and catch the response: r\\\\nr = requests.get(url)\\\\n\\\\n# Extracts the response as html: html_doc\\\\nhtml_doc = r.text\\\\n\\\\n# Create a BeautifulSoup object from the HTML: soup\\\\nsoup = BeautifulSoup(html_doc)\\\\n\\\\n# Prettify the BeautifulSoup object: pretty_soup\\\\npretty_soup = soup.prettify()\\\\n\\\\n# Print the response\\\\nprint(pretty_soup)&quot;,&quot;^2Z&quot;,&quot;&lt;ul&gt;\\\\n&lt;li&gt;To import a function &lt;code&gt;y&lt;/code&gt; from a package &lt;code&gt;x&lt;/code&gt;, execute &lt;code&gt;from x import y&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;li&gt;Check the URL to make sure that you typed it in correctly.&lt;/li&gt;\\\\n&lt;li&gt;Pass the &lt;em&gt;url&lt;/em&gt; (the &lt;code&gt;url&lt;/code&gt; object you defined) as an argument to &lt;code&gt;requests.get()&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;li&gt;You can access the &lt;code&gt;text&lt;/code&gt; attribute of the object &lt;code&gt;r&lt;/code&gt; by executing &lt;code&gt;r.text&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;li&gt;Pass the extracted &lt;em&gt;HTML&lt;/em&gt; as an argument to &lt;code&gt;BeautifulSoup()&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;li&gt;To use the &lt;code&gt;prettify()&lt;/code&gt; method on the BeautifulSoup object &lt;code&gt;soup&lt;/code&gt;, execute &lt;code&gt;soup.prettify()&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;li&gt;You don&#39;t have to modify the code to print the prettified HTML.&lt;/li&gt;\\\\n&lt;/ul&gt;&quot;,&quot;^2[&quot;,null,&quot;xp&quot;,100,&quot;^30&quot;,[],&quot;^31&quot;,[],&quot;^32&quot;,&quot;&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null,&quot;^U&quot;,&quot;python&quot;,&quot;^3:&quot;,0.9907962772955521,&quot;^3;&quot;,42715],[&quot;^ &quot;,&quot;id&quot;,42716,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^2U&quot;,&quot;&lt;p&gt;As promised, in the following exercises, you&#39;ll learn the basics of extracting information from HTML soup. In this exercise, you&#39;ll figure out how to extract the text from the BDFL&#39;s webpage, along with printing the webpage&#39;s title.&lt;/p&gt;&quot;,&quot;^W&quot;,&quot;Turning a webpage into data using BeautifulSoup: getting the text&quot;,&quot;^2V&quot;,&quot;# Import packages\\\\nimport requests\\\\nfrom bs4 import BeautifulSoup\\\\n\\\\n# Specify url: url\\\\nurl = &#39;https://www.python.org/~guido/&#39;\\\\n\\\\n# Package the request, send the request and catch the response: r\\\\nr = requests.get(url)\\\\n\\\\n# Extract the response as html: html_doc\\\\nhtml_doc = r.text\\\\n\\\\n# Create a BeautifulSoup object from the HTML: soup\\\\n\\\\n\\\\n# Get the title of Guido&#39;s webpage: guido_title\\\\n\\\\n\\\\n# Print the title of Guido&#39;s webpage to the shell\\\\n\\\\n\\\\n# Get Guido&#39;s text: guido_text\\\\n\\\\n\\\\n# Print Guido&#39;s text to the shell\\\\nprint(guido_text)&quot;,&quot;^2W&quot;,&quot;&lt;ul&gt;\\\\n&lt;li&gt;In the sample code, the HTML response object &lt;code&gt;html_doc&lt;/code&gt; has already been created: your first task is to Soupify it using the function &lt;code&gt;BeautifulSoup()&lt;/code&gt; and to assign the resulting soup to the variable &lt;code&gt;soup&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;li&gt;Extract the title from the HTML soup &lt;code&gt;soup&lt;/code&gt; using the attribute &lt;code&gt;title&lt;/code&gt; and assign the result to &lt;code&gt;guido_title&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;li&gt;Print the title of Guido&#39;s webpage to the shell using the &lt;code&gt;print()&lt;/code&gt; function.&lt;/li&gt;\\\\n&lt;li&gt;Extract the text from the HTML soup &lt;code&gt;soup&lt;/code&gt; using the method &lt;code&gt;get_text()&lt;/code&gt; and assign to &lt;code&gt;guido_text&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;li&gt;Hit submit to print the text from Guido&#39;s webpage to the shell.&lt;/li&gt;\\\\n&lt;/ul&gt;&quot;,&quot;^1&lt;&quot;,11,&quot;sct&quot;,&quot;# Test: Predefined code\\\\npredef_msg = \\\\&quot;You don&#39;t have to change any of the predefined code.\\\\&quot;\\\\nEx().has_import(\\\\n    \\\\&quot;requests\\\\&quot;,\\\\n    not_imported_msg=predef_msg\\\\n)\\\\n\\\\n# Test: import BeautifulSoup\\\\nEx().has_import(\\\\n    \\\\&quot;bs4.BeautifulSoup\\\\&quot;,\\\\n    not_imported_msg=predef_msg\\\\n)\\\\n\\\\n# Test: &#39;url&#39; variable\\\\nEx().check_object(\\\\&quot;url\\\\&quot;).has_equal_value()\\\\n\\\\n# Test: call to requests.get() and &#39;r&#39; variable\\\\nEx().check_function(\\\\&quot;requests.get\\\\&quot;).check_args(0).has_equal_value()\\\\nEx().check_object(\\\\&quot;r\\\\&quot;)\\\\n\\\\n\\\\n# Test: &#39;html_doc&#39; variable\\\\nEx().check_correct(\\\\n  check_object(\\\\&quot;html_doc\\\\&quot;).has_equal_value(),\\\\n  has_code(\\\\&quot;r.text\\\\&quot;, pattern = False, not_typed_msg=\\\\&quot;Have you used `r.text` to create `html_doc`?\\\\&quot;)\\\\n)\\\\n\\\\n# Test: call to BeautifulSoup() and &#39;soup&#39; variable\\\\nEx().check_correct(\\\\n  check_object(\\\\&quot;soup\\\\&quot;).has_equal_value(),\\\\n  check_function(\\\\&quot;bs4.BeautifulSoup\\\\&quot;).check_args(0).has_equal_value()\\\\n  )\\\\n\\\\n# Test: &#39;guido_title&#39; variable\\\\nEx().check_correct(\\\\n  check_object(\\\\&quot;guido_title\\\\&quot;).has_equal_value(),\\\\n  has_code(\\\\&quot;soup.title\\\\&quot;, pattern = False, not_typed_msg=\\\\&quot;Have you used `soup.title` to create `guido_title`?\\\\&quot;)\\\\n)\\\\n\\\\n# Test: call to print()\\\\nEx().has_printout(0)\\\\n\\\\n# Test: call to soup.get_text() and &#39;guido_text&#39; variable\\\\nEx().check_correct(\\\\n  check_object(\\\\&quot;guido_text\\\\&quot;).has_equal_value(),\\\\n  check_function(\\\\&quot;soup.get_text\\\\&quot;)\\\\n  )\\\\n\\\\n# Test: Predefined code\\\\nEx().has_printout(1)\\\\n\\\\nsuccess_msg(\\\\&quot;Awesome!\\\\&quot;)\\\\n&quot;,&quot;^2X&quot;,&quot;&quot;,&quot;^2Y&quot;,&quot;# Import packages\\\\nimport requests\\\\nfrom bs4 import BeautifulSoup\\\\n\\\\n# Specify url: url\\\\nurl = &#39;https://www.python.org/~guido/&#39;\\\\n\\\\n# Package the request, send the request and catch the response: r\\\\nr = requests.get(url)\\\\n\\\\n# Extract the response as html: html_doc\\\\nhtml_doc = r.text\\\\n\\\\n# Create a BeautifulSoup object from the HTML: soup\\\\nsoup = BeautifulSoup(html_doc)\\\\n\\\\n# Get the title of Guido&#39;s webpage: guido_title\\\\nguido_title = soup.title\\\\n\\\\n# Print the title of Guido&#39;s webpage to the shell\\\\nprint(guido_title)\\\\n\\\\n# Get Guido&#39;s text: guido_text\\\\nguido_text = soup.get_text()\\\\n\\\\n# Print Guido&#39;s text to the shell\\\\nprint(guido_text)&quot;,&quot;^2Z&quot;,&quot;&lt;ul&gt;\\\\n&lt;li&gt;Pass the &lt;em&gt;HTML response object&lt;/em&gt; as an argument to &lt;code&gt;BeautifulSoup()&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;li&gt;You can access the &lt;code&gt;title&lt;/code&gt; attribute of the object &lt;code&gt;soup&lt;/code&gt; by executing &lt;code&gt;soup.title&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;li&gt;The object that contains the title of Guido&#39;s webpage is &lt;code&gt;guido_title&lt;/code&gt;; pass this as an argument to &lt;code&gt;print()&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;li&gt;Use the method &lt;code&gt;get_text()&lt;/code&gt; on the HTML soup &lt;code&gt;soup&lt;/code&gt; by executing &lt;code&gt;soup.get_text()&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;li&gt;You don&#39;t have to modify the code to print the text from Guido&#39;s webpage.&lt;/li&gt;\\\\n&lt;/ul&gt;&quot;,&quot;^2[&quot;,null,&quot;xp&quot;,100,&quot;^30&quot;,[],&quot;^31&quot;,[],&quot;^32&quot;,&quot;&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null,&quot;^U&quot;,&quot;python&quot;,&quot;^3:&quot;,0.9359883737326375,&quot;^3;&quot;,42716],[&quot;^ &quot;,&quot;id&quot;,42717,&quot;^B&quot;,&quot;NormalExercise&quot;,&quot;^2U&quot;,&quot;&lt;p&gt;In this exercise, you&#39;ll figure out how to extract the URLs of the hyperlinks from the BDFL&#39;s webpage. In the process, you&#39;ll become close friends with the soup method &lt;code&gt;find_all()&lt;/code&gt;.&lt;/p&gt;&quot;,&quot;^W&quot;,&quot;Turning a webpage into data using BeautifulSoup: getting the hyperlinks&quot;,&quot;^2V&quot;,&quot;# Import packages\\\\nimport requests\\\\nfrom bs4 import BeautifulSoup\\\\n\\\\n# Specify url\\\\nurl = &#39;https://www.python.org/~guido/&#39;\\\\n\\\\n# Package the request, send the request and catch the response: r\\\\nr = requests.get(url)\\\\n\\\\n# Extracts the response as html: html_doc\\\\nhtml_doc = r.text\\\\n\\\\n# create a BeautifulSoup object from the HTML: soup\\\\nsoup = BeautifulSoup(html_doc)\\\\n\\\\n# Print the title of Guido&#39;s webpage\\\\nprint(soup.title)\\\\n\\\\n# Find all &#39;a&#39; tags (which define hyperlinks): a_tags\\\\n\\\\n\\\\n# Print the URLs to the shell\\\\nfor ____ in ____:\\\\n    ____&quot;,&quot;^2W&quot;,&quot;&lt;ul&gt;\\\\n&lt;li&gt;Use the method &lt;code&gt;find_all()&lt;/code&gt; to find all hyperlinks in &lt;code&gt;soup&lt;/code&gt;, remembering that hyperlinks are defined by the HTML tag &lt;code&gt;&amp;lt;a&amp;gt;&lt;/code&gt; but passed to &lt;code&gt;find_all()&lt;/code&gt; without angle brackets; store the result in the variable &lt;code&gt;a_tags&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;li&gt;The variable &lt;code&gt;a_tags&lt;/code&gt; is a results set: your job now is to enumerate over it, using a &lt;code&gt;for&lt;/code&gt; loop and to print the actual URLs of the hyperlinks; to do this, for every element &lt;code&gt;link&lt;/code&gt; in &lt;code&gt;a_tags&lt;/code&gt;, you want to &lt;code&gt;print()&lt;/code&gt; &lt;code&gt;link.get(&#39;href&#39;)&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;/ul&gt;&quot;,&quot;^1&lt;&quot;,12,&quot;sct&quot;,&quot;predef_msg = \\\\&quot;You don&#39;t have to change any of the predefined code.\\\\&quot;\\\\nEx().has_import(\\\\&quot;requests\\\\&quot;)\\\\nEx().has_import(\\\\&quot;bs4.BeautifulSoup\\\\&quot;)\\\\nEx().check_object(\\\\&quot;url\\\\&quot;).has_equal_value(incorrect_msg = predef_msg)\\\\nEx().check_function(\\\\&quot;requests.get\\\\&quot;).check_args(0).has_equal_ast()\\\\nEx().check_object(\\\\&quot;html_doc\\\\&quot;).has_equal_value(incorrect_msg = predef_msg)\\\\nEx().check_object(\\\\&quot;soup\\\\&quot;).has_equal_value(incorrect_msg = predef_msg)\\\\nEx().has_printout(0)\\\\n\\\\nEx().check_correct(\\\\n    check_object(\\\\&quot;a_tags\\\\&quot;),\\\\n    check_function(\\\\&quot;soup.find_all\\\\&quot;).check_args(0).has_equal_value()\\\\n)\\\\nEx().check_for_loop().multi(\\\\n        check_iter().has_equal_value(incorrect_msg = \\\\&quot;You have to iterate over `a_tags`\\\\&quot;),\\\\n        check_body().set_context(&#39;&lt;a href=\\\\&quot;pics.html\\\\&quot;&gt;&lt;img border=\\\\&quot;0\\\\&quot; src=\\\\&quot;images/IMG_2192.jpg\\\\&quot;/&gt;&lt;/a&gt;&#39;).check_function(\\\\&quot;print\\\\&quot;).check_args(0).check_function(\\\\&quot;link.get\\\\&quot;).check_args(0).has_equal_value()\\\\n    )\\\\n\\\\nsuccess_msg(\\\\&quot;Awesome!\\\\&quot;)&quot;,&quot;^2X&quot;,&quot;&quot;,&quot;^2Y&quot;,&quot;# Import packages\\\\nimport requests\\\\nfrom bs4 import BeautifulSoup\\\\n\\\\n# Specify url\\\\nurl = &#39;https://www.python.org/~guido/&#39;\\\\n\\\\n# Package the request, send the request and catch the response: r\\\\nr = requests.get(url)\\\\n\\\\n# Extracts the response as html: html_doc\\\\nhtml_doc = r.text\\\\n\\\\n# create a BeautifulSoup object from the HTML: soup\\\\nsoup = BeautifulSoup(html_doc)\\\\n\\\\n# Print the title of Guido&#39;s webpage\\\\nprint(soup.title)\\\\n\\\\n# Find all &#39;a&#39; tags (which define hyperlinks): a_tags\\\\na_tags = soup.find_all(&#39;a&#39;)\\\\n\\\\n# Print the URLs to the shell\\\\nfor link in a_tags:\\\\n    print(link.get(&#39;href&#39;))&quot;,&quot;^2Z&quot;,&quot;&lt;ul&gt;\\\\n&lt;li&gt;Pass the &lt;em&gt;HTML tag&lt;/em&gt; to find (without the angle brackets &lt;code&gt;&amp;lt;&amp;gt;&lt;/code&gt;) as a string argument to &lt;code&gt;find_all()&lt;/code&gt;.&lt;/li&gt;\\\\n&lt;li&gt;Recall that the &lt;code&gt;for&lt;/code&gt; loop recipe is: &lt;code&gt;for&lt;/code&gt; &lt;em&gt;loop variable&lt;/em&gt; &lt;code&gt;in&lt;/code&gt; &lt;em&gt;results set&lt;/em&gt;&lt;code&gt;:&lt;/code&gt;. Don&#39;t forget to pass &lt;code&gt;link.get(&#39;href&#39;)&lt;/code&gt; as an argument to &lt;code&gt;print()&lt;/code&gt; inside the &lt;code&gt;for&lt;/code&gt; loop body.&lt;/li&gt;\\\\n&lt;/ul&gt;&quot;,&quot;^2[&quot;,null,&quot;xp&quot;,100,&quot;^30&quot;,[],&quot;^31&quot;,[],&quot;^32&quot;,&quot;&quot;,&quot;^1F&quot;,null,&quot;^1G&quot;,null,&quot;^1H&quot;,null,&quot;^U&quot;,&quot;python&quot;,&quot;^3:&quot;,0.5560594333253173,&quot;^3;&quot;,42717]]]]],&quot;^H&quot;,[&quot;^0&quot;,[&quot;^ &quot;,&quot;n&quot;,&quot;PreFetchedRequestRecord&quot;,&quot;v&quot;,[&quot;^ &quot;,&quot;^2&quot;,&quot;NOT_FETCHED&quot;,&quot;^1:&quot;,null]]],&quot;sharedImage&quot;,[&quot;^0&quot;,[&quot;^ &quot;,&quot;n&quot;,&quot;PreFetchedRequestRecord&quot;,&quot;v&quot;,[&quot;^ &quot;,&quot;^2&quot;,&quot;NOT_FETCHED&quot;,&quot;^1:&quot;,null]]],&quot;^Q&quot;,[&quot;^0&quot;,[&quot;^ &quot;,&quot;n&quot;,&quot;PreFetchedRequestRecord&quot;,&quot;v&quot;,[&quot;^ &quot;,&quot;^2&quot;,&quot;SUCCESS&quot;,&quot;^1:&quot;,[&quot;^ &quot;,&quot;^R&quot;,&quot;template&quot;,&quot;id&quot;,3046,&quot;^S&quot;,&quot;2022-12-01T15:10:45.124Z&quot;,&quot;^T&quot;,&quot;2022-12-05T06:31:46.338Z&quot;,&quot;key&quot;,&quot;course-dataset-intermediate-importing-data-in-python&quot;,&quot;^U&quot;,&quot;Python&quot;,&quot;^V&quot;,null,&quot;^W&quot;,&quot;Intermediate Importing Data in Python&quot;,&quot;^X&quot;,&quot;Explore the datasets from the course, Intermediate Importing Data in Python.&quot;,&quot;^Y&quot;,false,&quot;^Z&quot;,&quot;d9783ad9a9e677a4f583a5bd9ed5b9d5987a2859&quot;,&quot;^[&quot;,null,&quot;^10&quot;,null,&quot;^11&quot;,null,&quot;^12&quot;,&quot;ade0176d-8e1d-436c-b7c1-44c3f4f1df8f&quot;,&quot;^13&quot;,[&quot;course-dataset&quot;],&quot;^14&quot;,1606,&quot;^15&quot;,[],&quot;^16&quot;,null]]]],&quot;courseImages&quot;,[&quot;^0&quot;,[&quot;^ &quot;,&quot;n&quot;,&quot;PreFetchedRequestRecord&quot;,&quot;v&quot;,[&quot;^ &quot;,&quot;^2&quot;,&quot;SUCCESS&quot;,&quot;^1:&quot;,[&quot;^ &quot;,&quot;imageTag&quot;,&quot;course-1606-master:cb59605c00ed73a970165be3564ff450-20240926095400969&quot;,&quot;^B&quot;,&quot;singleImage&quot;]]]],&quot;categoryPages&quot;,[&quot;^0&quot;,[&quot;^ &quot;,&quot;n&quot;,&quot;PreFetchedRequestRecord&quot;,&quot;v&quot;,[&quot;^ &quot;,&quot;^2&quot;,&quot;SUCCESS&quot;,&quot;^1:&quot;,[[&quot;^ &quot;,&quot;^1=&quot;,&quot;power-bi&quot;,&quot;facet&quot;,[&quot;^ &quot;,&quot;technology_array&quot;,[&quot;Power BI&quot;]]],[&quot;^ &quot;,&quot;^1=&quot;,&quot;r&quot;,&quot;^3@&quot;,[&quot;^ &quot;,&quot;^3A&quot;,[&quot;R&quot;]]],[&quot;^ &quot;,&quot;^1=&quot;,&quot;sql&quot;,&quot;^3@&quot;,[&quot;^ &quot;,&quot;^3A&quot;,[&quot;SQL&quot;]]],[&quot;^ &quot;,&quot;^1=&quot;,&quot;tableau&quot;,&quot;^3@&quot;,[&quot;^ &quot;,&quot;^3A&quot;,[&quot;Tableau&quot;]]],[&quot;^ &quot;,&quot;^1=&quot;,&quot;azure&quot;,&quot;^3@&quot;,[&quot;^ &quot;,&quot;^3A&quot;,[&quot;Azure&quot;]]],[&quot;^ &quot;,&quot;^1=&quot;,&quot;probability-and-statistics&quot;,&quot;^3@&quot;,[&quot;^ &quot;,&quot;topic_array&quot;,[&quot;Probability &amp; Statistics&quot;]]],[&quot;^ &quot;,&quot;^1=&quot;,&quot;artificial-intelligence&quot;,&quot;^3@&quot;,[&quot;^ &quot;,&quot;^3B&quot;,[&quot;Artificial Intelligence&quot;]]],[&quot;^ &quot;,&quot;^1=&quot;,&quot;machine-learning&quot;,&quot;^3@&quot;,[&quot;^ &quot;,&quot;^3B&quot;,[&quot;Machine Learning&quot;]]],[&quot;^ &quot;,&quot;^1=&quot;,&quot;data-engineering&quot;,&quot;^3@&quot;,[&quot;^ &quot;,&quot;^3B&quot;,[&quot;Data Engineering&quot;]]],[&quot;^ &quot;,&quot;^1=&quot;,&quot;data-visualization&quot;,&quot;^3@&quot;,[&quot;^ &quot;,&quot;^3B&quot;,[&quot;Data Visualization&quot;]]],[&quot;^ &quot;,&quot;^1=&quot;,&quot;data-analysis&quot;,&quot;^3@&quot;,[&quot;^ &quot;,&quot;^3B&quot;,[&quot;Reporting&quot;,&quot;Data Manipulation&quot;,&quot;Data Preparation&quot;,&quot;Exploratory Data Analysis&quot;,&quot;Data Visualization&quot;]]],[&quot;^ &quot;,&quot;^1=&quot;,&quot;python&quot;,&quot;^3@&quot;,[&quot;^ &quot;,&quot;^3A&quot;,[&quot;Python&quot;]]]]]]],&quot;translatedCourses&quot;,[&quot;^0&quot;,[&quot;^ &quot;,&quot;n&quot;,&quot;PreFetchedRequestRecord&quot;,&quot;v&quot;,[&quot;^ &quot;,&quot;^2&quot;,&quot;SUCCESS&quot;,&quot;^1:&quot;,[&quot;^ &quot;,&quot;58&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;672&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;735&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;799&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;1477&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;1531&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;1532&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;1606&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;1607&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;1796&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;1975&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;2072&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;2906&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;3423&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;3629&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;4205&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;4267&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;4452&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;4914&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;5065&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;6079&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;6199&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;6280&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;6576&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;6612&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;6919&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;7355&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;13023&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;13185&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;13203&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;13274&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;13367&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;13369&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;13371&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;13690&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;13698&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;13706&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;14519&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;14739&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;14989&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;15108&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;15192&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;15424&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;15876&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;16459&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;16470&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;16921&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;16937&quot;,[&quot;es&quot;],&quot;17118&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;17602&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;19197&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;19854&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;19930&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;20692&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;20822&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;20891&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;21394&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;21544&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;22066&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;22639&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;22723&quot;,[&quot;pt&quot;,&quot;es&quot;,&quot;de&quot;],&quot;22812&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;23080&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;23983&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;24098&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;24252&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;24364&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;24372&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;],&quot;24388&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;],&quot;24558&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;24852&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;24865&quot;,[&quot;pt&quot;],&quot;24878&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;24896&quot;,[&quot;de&quot;,&quot;pt&quot;],&quot;24907&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;25412&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;25472&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;25473&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;25475&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;25711&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;25814&quot;,[&quot;pt&quot;,&quot;es&quot;,&quot;de&quot;],&quot;25923&quot;,[&quot;de&quot;],&quot;25942&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;26827&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;27336&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;27391&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;28169&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;28173&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;28303&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;28314&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;28318&quot;,[&quot;es&quot;,&quot;de&quot;,&quot;pt&quot;],&quot;28765&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;28767&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;28826&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;28921&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;28944&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;28946&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;29081&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;29092&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;29094&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;29140&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;29143&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;29157&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;29302&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;29303&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;29304&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;29355&quot;,[&quot;es&quot;,&quot;de&quot;,&quot;pt&quot;],&quot;29453&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;29478&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;],&quot;29490&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;29533&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;29573&quot;,[&quot;es&quot;,&quot;de&quot;,&quot;pt&quot;],&quot;29712&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;29744&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;29830&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;29835&quot;,[&quot;es&quot;],&quot;29847&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;29902&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;29943&quot;,[&quot;pt&quot;,&quot;de&quot;,&quot;es&quot;],&quot;29968&quot;,[&quot;pt&quot;,&quot;es&quot;],&quot;30523&quot;,[&quot;pt&quot;,&quot;es&quot;],&quot;30563&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;],&quot;30656&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;30891&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;31224&quot;,[&quot;pt&quot;,&quot;es&quot;],&quot;31361&quot;,[&quot;pt&quot;,&quot;es&quot;],&quot;31794&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;31939&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;31950&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;32086&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;32245&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;32271&quot;,[&quot;pt&quot;,&quot;es&quot;],&quot;32326&quot;,[&quot;pt&quot;,&quot;es&quot;],&quot;32428&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;32439&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;32476&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;32509&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;32613&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;32623&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;32740&quot;,[&quot;es&quot;,&quot;de&quot;,&quot;pt&quot;,&quot;fr&quot;],&quot;32932&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;33286&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;33409&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;33412&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;,&quot;fr&quot;],&quot;33509&quot;,[&quot;es&quot;],&quot;33554&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;33674&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;33727&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;33848&quot;,[&quot;pt&quot;,&quot;es&quot;],&quot;33893&quot;,[&quot;pt&quot;,&quot;es&quot;],&quot;33937&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;34425&quot;,[&quot;pt&quot;,&quot;es&quot;],&quot;34598&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;34614&quot;,[&quot;es&quot;,&quot;pt&quot;,&quot;de&quot;],&quot;34777&quot;,[&quot;pt&quot;,&quot;es&quot;],&quot;34857&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;34919&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;34961&quot;,[&quot;pt&quot;,&quot;es&quot;],&quot;35064&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;35486&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;35597&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;35684&quot;,[&quot;pt&quot;,&quot;es&quot;,&quot;de&quot;],&quot;35704&quot;,[&quot;de&quot;],&quot;35927&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;35934&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;36079&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;36157&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;36160&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;36164&quot;,[&quot;pt&quot;,&quot;es&quot;],&quot;36398&quot;,[&quot;pt&quot;,&quot;es&quot;,&quot;de&quot;],&quot;36399&quot;,[&quot;es&quot;,&quot;pt&quot;],&quot;37483&quot;,[&quot;pt&quot;,&quot;es&quot;,&quot;de&quot;]]]]]]]],&quot;settings&quot;,[&quot;^?&quot;,[&quot;uiTheme&quot;,&quot;DARK&quot;,&quot;feedbackRatingStatus&quot;,&quot;NONE&quot;,&quot;mobileView&quot;,&quot;CONTEXT&quot;]],&quot;streakInfo&quot;,[&quot;^ &quot;,&quot;^B&quot;,&quot;StreakUnknown&quot;],&quot;systemStatus&quot;,[&quot;^?&quot;,[&quot;indicator&quot;,&quot;none&quot;,&quot;description&quot;,&quot;No status has been fetched from the Status Page.&quot;]],&quot;user&quot;,[&quot;^?&quot;,[&quot;status&quot;,&quot;not_initiate&quot;,&quot;settings&quot;,[&quot;^?&quot;,[&quot;aiFlags&quot;,[&quot;^?&quot;,[&quot;aiSolutionExplanationEnabled&quot;,false,&quot;aiErrorExplanationEnabled&quot;,false]]]]]],&quot;images&quot;,[&quot;^ &quot;,&quot;^3&gt;&quot;,&quot;course-1606-master:cb59605c00ed73a970165be3564ff450-20240926095400969&quot;,&quot;^B&quot;,&quot;singleImage&quot;]]]]\";</script><script>window.PRELOADED_LANGUAGE = \"en\";</script><div id=\"root\"><div class=\"theme progress-indicator--visible\"><style data-emotion=\"css 19enzrs\">.css-19enzrs{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;background-color:#F7F7FC;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;height:50px;padding-left:10px;padding-right:10px;position:relative;z-index:15;}</style><header data-cy=\"alpa-navbar\" class=\"css-19enzrs\"><style data-emotion=\"css vpr568\">.css-vpr568{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex:1;-ms-flex:1;flex:1;-webkit-box-pack:start;-ms-flex-pack:start;-webkit-justify-content:flex-start;justify-content:flex-start;}</style><div class=\"css-vpr568\"><style data-emotion=\"css 19lbh5u\">.css-19lbh5u{padding-left:6px;padding-right:6px;}</style><style data-emotion=\"css 12o4242\">.css-12o4242{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;border-color:transparent;border-radius:4px;border-style:solid;border-width:2px;cursor:pointer;display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;font-family:Studio-Feixen-Sans,Arial,sans-serif;font-weight:800;-webkit-box-pack:center;-ms-flex-pack:center;-webkit-justify-content:center;justify-content:center;line-height:1;margin:0;outline:0;padding:0;position:relative;-webkit-text-decoration:none;text-decoration:none;-webkit-transition:background-color 125ms ease-out;transition:background-color 125ms ease-out;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;vertical-align:middle;background-color:transparent;color:var(--wf-text--link, #0065D1);font-size:var(--wf-button--medium, 14px);height:36px;min-width:36px;width:auto;padding-left:16px;padding-right:16px;padding-left:6px;padding-right:6px;}.css-12o4242::before{border-radius:2px;content:\"\";display:block;height:100%;inset:0;position:absolute;width:100%;z-index:0;}.css-12o4242:active{background-color:transparent;}.css-12o4242:disabled{cursor:default;opacity:0.4;pointer-events:none;}.css-12o4242:hover{border-color:var(--wf-bg--hover, rgba(48, 57, 105, 0.06));}.css-12o4242:hover::before{background-color:var(--wf-bg--hover, rgba(48, 57, 105, 0.06));}.css-12o4242 >*{z-index:1;}</style><a class=\"alpa-navbar-logo css-12o4242\" data-cy=\"header-logo\" data-testid=\"alpa-navbar-logo\" data-trackid=\"alpa-navbar-logo\" href=\"https://www.datacamp.com\" aria-label=\"landing\"><style data-emotion=\"css 61bni1\">.css-61bni1{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;height:100%;gap:8px;}</style><span class=\"css-61bni1\"><svg viewbox=\"0 0 27 35\" xml:space=\"preserve\" xmlns=\"http://www.w3.org/2000/svg\" height=\"28\" class=\"css-0\"><path clip-rule=\"evenodd\" d=\"M11.699 8.514v8.333L2.858 21.89V3.44l8.841 5.074zm2.861 17.507v-7.51l11.84-6.757-2.88-1.65-8.96 5.112V7.68a1.442 1.442 0 0 0-.718-1.242L3.056.256C3.027.238 2.998.224 2.97.21A2.064 2.064 0 0 0 0 2.07v21.184a2.067 2.067 0 0 0 2.971 1.865l.082-.042 8.64-4.933v6.72c.002.513.277.987.722 1.243L23.502 34.4l2.88-1.651-11.822-6.728z\" fill=\"var(--wf-brand--text, #05192D)\" fill-rule=\"evenodd\"/></svg></span></a><nav aria-label=\"Breadcrumb\" data-testid=\"alpa-navbar-breadcrumbs\"><style data-emotion=\"css 1goqhco\">.css-1goqhco{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;padding:0;}.css-1goqhco div[aria-hidden='true']{color:#5D6A77;display:none;padding:0 4px;}.css-1goqhco div[aria-hidden='true']:first-of-type{display:inline-block;}@media screen and (min-width: 820px){.css-1goqhco div[aria-hidden='true']{display:inline-block;}}.css-1goqhco li{display:none;-webkit-box-flex:1;-webkit-flex-grow:1;-ms-flex-positive:1;flex-grow:1;-webkit-flex-shrink:1;-ms-flex-negative:1;flex-shrink:1;list-style:none;}@media screen and (min-width: 820px){.css-1goqhco li{display:inline-block;}}.css-1goqhco li:first-of-type{display:inline-block;}.css-1goqhco li:last-of-type{display:inline-block;}.css-1goqhco li a{color:#05192D;font-weight:normal;height:30px;line-height:21px;min-height:unset;padding:2px;}.css-1goqhco li a span{display:inline-block;max-width:20vw;overflow:hidden;text-overflow:ellipsis;white-space:nowrap;}.css-1goqhco li:last-of-type a{font-weight:bold;}</style><ol itemscope itemtype=\"http://schema.org/BreadcrumbList\" class=\"css-1goqhco\"><li itemprop=\"itemListElement\" itemscope itemtype=\"https://schema.org/ListItem\"><style data-emotion=\"css qwtpyn\">.css-qwtpyn{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;border-color:transparent;border-radius:4px;border-style:solid;border-width:2px;cursor:pointer;display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;font-family:Studio-Feixen-Sans,Arial,sans-serif;font-weight:800;-webkit-box-pack:center;-ms-flex-pack:center;-webkit-justify-content:center;justify-content:center;line-height:1;margin:0;outline:0;padding:0;position:relative;-webkit-text-decoration:none;text-decoration:none;-webkit-transition:background-color 125ms ease-out;transition:background-color 125ms ease-out;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;vertical-align:middle;background-color:transparent;color:var(--wf-text--link, #0065D1);font-size:var(--wf-button--medium, 14px);height:36px;min-width:36px;width:auto;padding-left:16px;padding-right:16px;}.css-qwtpyn::before{border-radius:2px;content:\"\";display:block;height:100%;inset:0;position:absolute;width:100%;z-index:0;}.css-qwtpyn:active{background-color:transparent;}.css-qwtpyn:disabled{cursor:default;opacity:0.4;pointer-events:none;}.css-qwtpyn:hover{border-color:var(--wf-bg--hover, rgba(48, 57, 105, 0.06));}.css-qwtpyn:hover::before{background-color:var(--wf-bg--hover, rgba(48, 57, 105, 0.06));}.css-qwtpyn >*{z-index:1;}</style><a data-trackid=\"alpa-navbar-breadcrumb-learn\" href=\"https://www.datacamp.com\" itemprop=\"item\" aria-label=\"Learn\" class=\"css-qwtpyn\"><span class=\"css-61bni1\"><span itemprop=\"name\">Learn</span></span></a><meta content=\"0\" itemprop=\"position\"></li><div aria-hidden=\"true\">/</div><li itemprop=\"itemListElement\" itemscope itemtype=\"https://schema.org/ListItem\"><a data-trackid=\"alpa-navbar-breadcrumb-courses\" href=\"https://www.datacamp.com/category/python\" itemprop=\"item\" aria-label=\"Courses\" class=\"css-qwtpyn\"><span class=\"css-61bni1\"><span itemprop=\"name\">Courses</span></span></a><meta content=\"1\" itemprop=\"position\"></li><div aria-hidden=\"true\">/</div><li itemprop=\"itemListElement\" itemscope itemtype=\"https://schema.org/ListItem\"><a data-trackid=\"alpa-navbar-breadcrumb-course\" href=\"https://www.datacamp.com/courses/intermediate-importing-data-in-python\" itemprop=\"item\" aria-label=\"Intermediate Importing Data in Python\" class=\"css-qwtpyn\"><span class=\"css-61bni1\"><span itemprop=\"name\">Intermediate Importing Data in Python</span></span></a><meta content=\"2\" itemprop=\"position\"></li></ol></nav></div><style data-emotion=\"css 1jov1vc\">.css-1jov1vc{-webkit-box-pack:initial;-ms-flex-pack:initial;-webkit-justify-content:initial;justify-content:initial;}</style><div class=\"css-1jov1vc\"></div><style data-emotion=\"css r4fpqc\">.css-r4fpqc{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex:1;-ms-flex:1;flex:1;-webkit-box-pack:end;-ms-flex-pack:end;-webkit-justify-content:flex-end;justify-content:flex-end;}</style><nav class=\"css-r4fpqc\"><style data-emotion=\"css 79elbk\">.css-79elbk{position:relative;}</style><div class=\"css-79elbk\"><style data-emotion=\"css 10ganm4\">.css-10ganm4{border:none;}</style><style data-emotion=\"css 178iibo\">.css-178iibo{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;border-color:transparent;border-radius:4px;border-style:solid;border-width:2px;cursor:pointer;display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;font-family:Studio-Feixen-Sans,Arial,sans-serif;font-weight:800;-webkit-box-pack:center;-ms-flex-pack:center;-webkit-justify-content:center;justify-content:center;line-height:1;margin:0;outline:0;padding:0;position:relative;-webkit-text-decoration:none;text-decoration:none;-webkit-transition:background-color 125ms ease-out;transition:background-color 125ms ease-out;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;vertical-align:middle;background-color:transparent;color:var(--wf-text--main, #05192D);font-size:var(--wf-button--medium, 14px);height:36px;min-width:36px;width:auto;padding-left:16px;padding-right:16px;border-color:var(--wf-border-color--interactive, rgba(48, 57, 105, 0.6));border:none;}.css-178iibo::before{border-radius:2px;content:\"\";display:block;height:100%;inset:0;position:absolute;width:100%;z-index:0;}.css-178iibo::before{border-radius:2px;margin:0;}.css-178iibo:active{background-color:transparent;}.css-178iibo:disabled{cursor:default;opacity:0.4;pointer-events:none;}.css-178iibo:hover::before{background-color:var(--wf-bg--hover, rgba(48, 57, 105, 0.06));}.css-178iibo >*{z-index:1;}</style><button class=\"css-178iibo\" aria-label=\"course-menu\" type=\"button\"><span class=\"css-61bni1\"><svg aria-hidden=\"true\" height=\"16\" width=\"16\" viewbox=\"0 0 18 18\"><path fill=\"currentColor\" d=\"M2 11a2 2 0 1 1 0-4 2 2 0 0 1 0 4Zm7 0a2 2 0 1 1 0-4 2 2 0 0 1 0 4Zm7 0a2 2 0 1 1 0-4 2 2 0 0 1 0 4Z\"/></svg></span></button><style data-emotion=\"css h7pn2b\">.css-h7pn2b{position:absolute;top:32px;right:0;padding:8px;padding-left:0;padding-right:0;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;max-width:90dvw;z-index:5000;width:0;height:0;overflow:hidden;}.css-h7pn2b button span{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:start;-ms-flex-pack:start;-webkit-justify-content:flex-start;justify-content:flex-start;font-weight:400;width:100%;}</style><style data-emotion=\"css 1ydqvfl\">.css-1ydqvfl{background-color:var(--wf-bg--contrast, #FFFFFF);border-color:var(--wf-border-color--main, rgba(48, 57, 105, 0.15));border-radius:4px;border-style:solid;border-width:1px;display:block;outline:0;padding:16px;position:relative;-webkit-text-decoration:none;text-decoration:none;-webkit-transition:box-shadow 600ms cubic-bezier(0.1, 0.8, 0.2, 1),-webkit-transform 600ms cubic-bezier(0.1, 0.8, 0.2, 1);transition:box-shadow 600ms cubic-bezier(0.1, 0.8, 0.2, 1),transform 600ms cubic-bezier(0.1, 0.8, 0.2, 1);position:absolute;top:32px;right:0;padding:8px;padding-left:0;padding-right:0;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;max-width:90dvw;z-index:5000;width:0;height:0;overflow:hidden;}.css-1ydqvfl:where(a, button){cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;}.css-1ydqvfl button span{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:start;-ms-flex-pack:start;-webkit-justify-content:flex-start;justify-content:flex-start;font-weight:400;width:100%;}</style><section aria-hidden=\"true\" class=\"css-1ydqvfl\"><nav><style data-emotion=\"css 15c08fe\">.css-15c08fe{color:#05192D;border:none;width:100%;}@media screen and (min-width: 820px){.css-15c08fe{border-radius:0;}.css-15c08fe:after{border-radius:0;}}</style><style data-emotion=\"css btjij\">.css-btjij{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;border-color:transparent;border-radius:4px;border-style:solid;border-width:2px;cursor:pointer;display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;font-family:Studio-Feixen-Sans,Arial,sans-serif;font-weight:800;-webkit-box-pack:center;-ms-flex-pack:center;-webkit-justify-content:center;justify-content:center;line-height:1;margin:0;outline:0;padding:0;position:relative;-webkit-text-decoration:none;text-decoration:none;-webkit-transition:background-color 125ms ease-out;transition:background-color 125ms ease-out;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;vertical-align:middle;background-color:transparent;color:var(--wf-text--main, #05192D);font-size:var(--wf-button--medium, 14px);height:36px;min-width:36px;width:auto;padding-left:16px;padding-right:16px;border-color:var(--wf-border-color--interactive, rgba(48, 57, 105, 0.6));color:#05192D;border:none;width:100%;}.css-btjij::before{border-radius:2px;content:\"\";display:block;height:100%;inset:0;position:absolute;width:100%;z-index:0;}.css-btjij::before{border-radius:2px;margin:0;}.css-btjij:active{background-color:transparent;}.css-btjij:disabled{cursor:default;opacity:0.4;pointer-events:none;}.css-btjij:hover::before{background-color:var(--wf-bg--hover, rgba(48, 57, 105, 0.06));}.css-btjij >*{z-index:1;}@media screen and (min-width: 820px){.css-btjij{border-radius:0;}.css-btjij:after{border-radius:0;}}</style><button data-cy=\"header-outline\" class=\"css-btjij\" type=\"button\"><span class=\"css-61bni1\"><svg aria-hidden=\"true\" height=\"16\" width=\"16\" viewbox=\"0 0 18 18\" style=\"flex-shrink:0\"><path fill=\"currentColor\" d=\"M4 6a1 1 0 1 1 0-2h10a1 1 0 0 1 0 2H4Zm0 4a1 1 0 1 1 0-2h10a1 1 0 0 1 0 2H4Zm0 4a1 1 0 0 1 0-2h10a1 1 0 0 1 0 2H4Z\"/></svg>Course Outline</span></button><style data-emotion=\"css ntp9k4\">.css-ntp9k4{height:0;overflow:hidden;position:absolute;top:-9000px;left:-9000px;}</style><div aria-hidden=\"true\" class=\"css-ntp9k4\"><ul data-cy=\"outline-container\"><style data-emotion=\"css p1ihnf\">.css-p1ihnf{border:1px solid rgba(48, 57, 105, 0.15);border-radius:4px;margin-bottom:16px;overflow:hidden;}</style><li data-cy=\"outline-chapter\" class=\"css-p1ihnf\"><style data-emotion=\"css 15hicbc\">.css-15hicbc{padding:16px;padding-bottom:0;}</style><div class=\"css-15hicbc\"><style data-emotion=\"css k008qs\">.css-k008qs{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}</style><header class=\"css-k008qs\"><style data-emotion=\"css mwfol9\">.css-mwfol9{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-flex:1;-webkit-flex-grow:1;-ms-flex-positive:1;flex-grow:1;gap:8px;}</style><div class=\"css-mwfol9\"><style data-emotion=\"css ty7r4z\">.css-ty7r4z{font-weight:800;}</style><style data-emotion=\"css kdtjtf\">.css-kdtjtf{-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;font-family:Studio-Feixen-Sans,Arial,sans-serif;overflow:hidden;background:var(--wf-navy--main, #05192D);border-radius:24px;color:var(--wf-navy--text-on-color, #FFFFFF);font-size:12px;height:24px;line-height:24px;width:24px;font-weight:800;}</style><div class=\"css-kdtjtf\"><style data-emotion=\"css 3xjkdl\">.css-3xjkdl{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;font-variant-numeric:tabular-nums;height:100%;-webkit-box-pack:center;-ms-flex-pack:center;-webkit-justify-content:center;justify-content:center;width:100%;}.css-3xjkdl>*{margin:auto 0;}.css-3xjkdl>:not(svg){min-width:100%;}.css-3xjkdl>*{min-height:14px;}.css-3xjkdl>svg{width:14px;}</style><div class=\"css-3xjkdl\">1</div></div><style data-emotion=\"css 1uk1gs8\">.css-1uk1gs8{margin:0;}</style><style data-emotion=\"css 1g5cl9a\">.css-1g5cl9a{font-weight:800;line-height:1.25;margin-bottom:8px;font-size:16px;margin:0;}</style><style data-emotion=\"css fbt0po\">.css-fbt0po{color:var(--wf-text--main, #05192D);font-family:Studio-Feixen-Sans,Arial,sans-serif;font-weight:400;line-height:1.5;margin:0;padding:0;font-size:14px;font-weight:800;line-height:1.25;margin-bottom:8px;font-size:16px;margin:0;}</style><h3 class=\"css-fbt0po\">Importing data from the Internet</h3><style data-emotion=\"css 17lebkx\">.css-17lebkx{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;font-family:Studio-Feixen-Sans,Arial,sans-serif;font-weight:800;-webkit-box-pack:center;-ms-flex-pack:center;-webkit-justify-content:center;justify-content:center;letter-spacing:0.5px;line-height:1;padding:0 4px;text-transform:uppercase;border-radius:4px;background-color:var(--wf-yellow--main, #FCCE0D);color:var(--wf-yellow--main, #FCCE0D);font-size:12px;height:18px;}.css-17lebkx span{color:var(--wf-yellow--text-on-color, #05192D);}</style><style data-emotion=\"css 1gjxyd4\">.css-1gjxyd4{color:var(--wf-text--main, #05192D);font-family:Studio-Feixen-Sans,Arial,sans-serif;font-weight:400;line-height:1.5;margin:0;padding:0;font-size:14px;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;font-family:Studio-Feixen-Sans,Arial,sans-serif;font-weight:800;-webkit-box-pack:center;-ms-flex-pack:center;-webkit-justify-content:center;justify-content:center;letter-spacing:0.5px;line-height:1;padding:0 4px;text-transform:uppercase;border-radius:4px;background-color:var(--wf-yellow--main, #FCCE0D);color:var(--wf-yellow--main, #FCCE0D);font-size:12px;height:18px;}.css-1gjxyd4 span{color:var(--wf-yellow--text-on-color, #05192D);}</style><span class=\"css-1gjxyd4\"><style data-emotion=\"css 19ist84\">.css-19ist84{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;color:inherit;display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;gap:4px;max-width:164px;}</style><span class=\"css-19ist84\"><style data-emotion=\"css 8uhtka\">.css-8uhtka{overflow:hidden;text-overflow:ellipsis;white-space:nowrap;}</style><span class=\"css-8uhtka\">Free</span></span></span></div><style data-emotion=\"css 1krpqay\">.css-1krpqay{padding-left:16px;width:200px;}</style><div class=\"css-1krpqay\"><style data-emotion=\"css 18oyfde\">.css-18oyfde{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;color:var(--wf-text--subtle, #5D6A77);display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;font-family:Studio-Feixen-Sans,Arial,sans-serif;gap:8px;line-height:1;width:100%;font-size:12px;}</style><div data-testid=\"progress-wrapper\" class=\"css-18oyfde\"><style data-emotion=\"css k1hg5o\">.css-k1hg5o{display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;-webkit-flex:1;-ms-flex:1;flex:1;position:relative;width:100%;}</style><div class=\"css-k1hg5o\"><style data-emotion=\"css 11s5m7q\">.css-11s5m7q{-webkit-appearance:none;-moz-appearance:none;-ms-appearance:none;appearance:none;background-color:var(--wf-transparent-grey--lighter, rgba(48, 57, 105, 0.15));border:none;width:100%;border-radius:4px;-webkit-clip-path:url(#progress-null-clip);clip-path:url(#progress-null-clip);height:8px;}.css-11s5m7q::-webkit-progress-bar{background-color:inherit;}.css-11s5m7q::-moz-progress-bar{-webkit-transition:width 1s ease-in-out;transition:width 1s ease-in-out;background-color:var(--wf-brand--main, #03EF62);border-radius:4px;}.css-11s5m7q::-webkit-progress-bar{border-radius:4px;}.css-11s5m7q::-webkit-progress-value{-webkit-transition:width 1s ease-in-out;transition:width 1s ease-in-out;background-color:var(--wf-brand--main, #03EF62);border-radius:4px;}</style><progress aria-label=\"Progress\" aria-valuemax=\"100\" aria-valuemin=\"0\" aria-valuenow=\"0\" id=\"progress-null\" max=\"100\" value=\"0\" class=\"css-11s5m7q\"></progress></div><label for=\"progress-null\"><span aria-hidden=\"true\">0%</span></label></div></div></header><style data-emotion=\"css y1tonc\">.css-y1tonc{font-size:14px;font-family:Studio-Feixen-Sans,Arial,sans-serif;line-height:1.5;}</style><div class=\"css-y1tonc\"><p class>The web is a rich source of data from which you can extract various types of insights and findings. In this chapter, you will learn how to get data from the web, whether it is stored in files or in HTML. You&apos;ll also learn the basics of scraping and parsing web data.</p></div></div><style data-emotion=\"css 1lkdjmn\">.css-1lkdjmn{background-color:#F7F7FC;padding:8px;}</style><div class=\"css-1lkdjmn\"><style data-emotion=\"css p9ltrc\">.css-p9ltrc{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;border-color:transparent;border-radius:4px;border-style:solid;border-width:2px;cursor:pointer;display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;font-family:Studio-Feixen-Sans,Arial,sans-serif;font-weight:800;-webkit-box-pack:center;-ms-flex-pack:center;-webkit-justify-content:center;justify-content:center;line-height:1;margin:0;outline:0;padding:0;position:relative;-webkit-text-decoration:none;text-decoration:none;-webkit-transition:background-color 125ms ease-out;transition:background-color 125ms ease-out;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;vertical-align:middle;background-color:transparent;color:var(--wf-text--link, #0065D1);font-size:12px;height:28px;min-width:28px;width:auto;padding-left:8px;padding-right:8px;}.css-p9ltrc::before{border-radius:2px;content:\"\";display:block;height:100%;inset:0;position:absolute;width:100%;z-index:0;}.css-p9ltrc:active{background-color:transparent;}.css-p9ltrc:disabled{cursor:default;opacity:0.4;pointer-events:none;}.css-p9ltrc:hover{border-color:var(--wf-bg--hover, rgba(48, 57, 105, 0.06));}.css-p9ltrc:hover::before{background-color:var(--wf-bg--hover, rgba(48, 57, 105, 0.06));}.css-p9ltrc >*{z-index:1;}</style><button tabindex=\"-1\" data-cy=\"outline-expand-chapter\" type=\"button\" class=\"css-p9ltrc\"><style data-emotion=\"css xejdhu\">.css-xejdhu{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;height:100%;gap:4px;}</style><span class=\"css-xejdhu\">View Chapter Details<svg aria-hidden=\"true\" height=\"14\" width=\"14\" viewbox=\"0 0 18 18\" style=\"flex-shrink:0\"><path fill=\"currentColor\" d=\"m8.244 12.155-4.95-4.947a1 1 0 1 1 1.415-1.415l4.294 4.291 4.293-4.279a.998.998 0 0 1 1.413.003c.39.392.388 1.025-.003 1.415l-5.002 4.986a.998.998 0 0 1-1.46-.054Z\"/></svg></span></button></div></li><li data-cy=\"outline-chapter\" class=\"css-p1ihnf\"><div class=\"css-15hicbc\"><header class=\"css-k008qs\"><div class=\"css-mwfol9\"><div class=\"css-kdtjtf\"><div class=\"css-3xjkdl\">2</div></div><h3 class=\"css-fbt0po\">Interacting with APIs to import data from the web</h3></div><div class=\"css-1krpqay\"><div data-testid=\"progress-wrapper\" class=\"css-18oyfde\"><div class=\"css-k1hg5o\"><progress aria-label=\"Progress\" aria-valuemax=\"100\" aria-valuemin=\"0\" aria-valuenow=\"0\" id=\"progress-null\" max=\"100\" value=\"0\" class=\"css-11s5m7q\"></progress></div><label for=\"progress-null\"><span aria-hidden=\"true\">0%</span></label></div></div></header><div class=\"css-y1tonc\"><p class>In this chapter, you will gain a deeper understanding of how to import data from the web. You will learn the basics of extracting data from APIs, gain insight on the importance of APIs, and practice extracting data by diving into the OMDB and Library of Congress APIs.</p></div></div><div class=\"css-1lkdjmn\"><button tabindex=\"-1\" data-cy=\"outline-expand-chapter\" type=\"button\" class=\"css-p9ltrc\"><span class=\"css-xejdhu\">View Chapter Details<svg aria-hidden=\"true\" height=\"14\" width=\"14\" viewbox=\"0 0 18 18\" style=\"flex-shrink:0\"><path fill=\"currentColor\" d=\"m8.244 12.155-4.95-4.947a1 1 0 1 1 1.415-1.415l4.294 4.291 4.293-4.279a.998.998 0 0 1 1.413.003c.39.392.388 1.025-.003 1.415l-5.002 4.986a.998.998 0 0 1-1.46-.054Z\"/></svg></span></button></div></li><li data-cy=\"outline-chapter\" class=\"css-p1ihnf\"><div class=\"css-15hicbc\"><header class=\"css-k008qs\"><div class=\"css-mwfol9\"><div class=\"css-kdtjtf\"><div class=\"css-3xjkdl\">3</div></div><h3 class=\"css-fbt0po\">Diving  deep into the Twitter API</h3></div><div class=\"css-1krpqay\"><div data-testid=\"progress-wrapper\" class=\"css-18oyfde\"><div class=\"css-k1hg5o\"><progress aria-label=\"Progress\" aria-valuemax=\"100\" aria-valuemin=\"0\" aria-valuenow=\"0\" id=\"progress-null\" max=\"100\" value=\"0\" class=\"css-11s5m7q\"></progress></div><label for=\"progress-null\"><span aria-hidden=\"true\">0%</span></label></div></div></header><div class=\"css-y1tonc\"><p class>In this chapter, you will consolidate your knowledge of interacting with APIs in a deep dive into the Twitter streaming API. You&apos;ll learn how to stream real-time Twitter data, and how to analyze and visualize it.</p></div></div><div class=\"css-1lkdjmn\"><button tabindex=\"-1\" data-cy=\"outline-expand-chapter\" type=\"button\" class=\"css-p9ltrc\"><span class=\"css-xejdhu\">View Chapter Details<svg aria-hidden=\"true\" height=\"14\" width=\"14\" viewbox=\"0 0 18 18\" style=\"flex-shrink:0\"><path fill=\"currentColor\" d=\"m8.244 12.155-4.95-4.947a1 1 0 1 1 1.415-1.415l4.294 4.291 4.293-4.279a.998.998 0 0 1 1.413.003c.39.392.388 1.025-.003 1.415l-5.002 4.986a.998.998 0 0 1-1.46-.054Z\"/></svg></span></button></div></li></ul></div></nav><style data-emotion=\"css 16cuyl0\">.css-16cuyl0{color:#05192D;}</style><style data-emotion=\"css r7pabm\">.css-r7pabm{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;border-color:transparent;border-radius:4px;border-style:solid;border-width:2px;cursor:pointer;display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;font-family:Studio-Feixen-Sans,Arial,sans-serif;font-weight:800;-webkit-box-pack:center;-ms-flex-pack:center;-webkit-justify-content:center;justify-content:center;line-height:1;margin:0;outline:0;padding:0;position:relative;-webkit-text-decoration:none;text-decoration:none;-webkit-transition:background-color 125ms ease-out;transition:background-color 125ms ease-out;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;vertical-align:middle;background-color:transparent;color:var(--wf-text--link, #0065D1);font-size:var(--wf-button--medium, 14px);height:36px;min-width:36px;width:auto;padding-left:16px;padding-right:16px;color:#05192D;}.css-r7pabm::before{border-radius:2px;content:\"\";display:block;height:100%;inset:0;position:absolute;width:100%;z-index:0;}.css-r7pabm:active{background-color:transparent;}.css-r7pabm:disabled{cursor:default;opacity:0.4;pointer-events:none;}.css-r7pabm:hover{border-color:var(--wf-bg--hover, rgba(48, 57, 105, 0.06));}.css-r7pabm:hover::before{background-color:var(--wf-bg--hover, rgba(48, 57, 105, 0.06));}.css-r7pabm >*{z-index:1;}</style><button data-cy=\"header-slides\" class=\"css-r7pabm\" type=\"button\"><span class=\"css-61bni1\"><svg aria-hidden=\"true\" height=\"14\" width=\"14\" viewbox=\"0 0 18 18\"><path fill=\"currentColor\" d=\"M14 9.004H9.996a2 2 0 0 1-2-2V2H4v14h10V9.004Zm1.828-2.815A1.938 1.938 0 0 1 16 7v9a2 2 0 0 1-2 2H4a2 2 0 0 1-2-2V2a2 2 0 0 1 2-2h5.003a2 2 0 0 1 1.415.586l4.997 5a2 2 0 0 1 .413.603Zm-1.832.815-4-4v4h4Z\"/></svg>Show Slides</span></button><button data-cy=\"header-video\" class=\"css-r7pabm\" aria-label=\"Show video\" type=\"button\"><span class=\"css-61bni1\"><svg aria-hidden=\"true\" height=\"14\" width=\"14\" viewbox=\"0 0 18 18\"><path fill=\"currentColor\" d=\"m13 6.3 3.331-2.998A1 1 0 0 1 18 4.045v9.91a1 1 0 0 1-1.669.743L13 11.7V14c0 .552-.485 1-1.083 1H1.083C.485 15 0 14.552 0 14V4c0-.552.485-1 1.083-1h10.834C12.515 3 13 3.448 13 4v2.3Zm0 2.69v.02l3 2.7V6.29l-3 2.7ZM2 5v8h9V5H2Z\"/></svg>Show Video</span></button><button data-cy=\"header-notes\" class=\"css-r7pabm\" type=\"button\"><span class=\"css-61bni1\"><svg aria-hidden=\"true\" height=\"14\" width=\"14\" viewbox=\"0 0 18 18\"><path fill=\"currentColor\" fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M12.528.293a.999.999 0 0 1 1.414 0l3.765 3.765a.999.999 0 0 1 0 1.414L5.472 17.707a1 1 0 0 1-.707.293H1a1 1 0 0 1-1-1v-3.765c0-.265.105-.52.293-.707L12.528.293zM2 13.65V16h2.35l8.412-8.412-2.35-2.35L2 13.65zm9.826-9.826 2.351 2.351 1.409-1.409-2.351-2.35-1.409 1.408zM16.529 18h-8a1 1 0 0 1 0-2h8a1 1 0 0 1 0 2z\"/></svg>Take Notes</span></button><button data-cy=\"header-mobile\" class=\"css-r7pabm\" type=\"button\"><span class=\"css-61bni1\"><svg aria-hidden=\"true\" height=\"14\" width=\"14\" viewbox=\"0 0 18 18\"><path fill=\"currentColor\" d=\"M5.5 2v14h7V2h-7Zm-1-2h9a1 1 0 0 1 1 1v16a1 1 0 0 1-1 1h-9a1 1 0 0 1-1-1V1a1 1 0 0 1 1-1Zm4 13h1a1 1 0 0 1 0 2h-1a1 1 0 0 1 0-2Z\"/></svg>Continue Learning on Mobile</span></button><button data-cy=\"header-issue\" data-test-id=\"header-report-issue-button\" class=\"css-r7pabm\" type=\"button\"><span class=\"css-61bni1\"><svg aria-hidden=\"true\" height=\"14\" width=\"14\" viewbox=\"0 0 18 18\"><path fill=\"currentColor\" fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M17.744 14.31 10.869 1.647a2.119 2.119 0 0 0-3.72 0L.268 14.31a2.116 2.116 0 0 0 1.862 3.148h13.75A2.122 2.122 0 0 0 18 15.383a2.12 2.12 0 0 0-.256-1.052v-.021zm-2.054.419L9.448 3.24a.5.5 0 0 0-.879 0L2.322 14.73a.5.5 0 0 0 .439.739H15.25a.502.502 0 0 0 .44-.74zM8.02 7.017a.994.994 0 1 1 1.99 0v2.57a.994.994 0 1 1-1.99 0v-2.57zm1.021 6.961a1.144 1.144 0 0 1-1.054-.704 1.143 1.143 0 0 1 .247-1.243 1.14 1.14 0 0 1 1.947.807 1.14 1.14 0 0 1-1.14 1.14z\"/></svg>Provide Feedback</span></button><style data-emotion=\"css xqh66l\">.css-xqh66l{margin:8px;color:#05192D;opacity:0.15;border-bottom:none;}</style><hr class=\"css-xqh66l\"><style data-emotion=\"css yv011k\">.css-yv011k{padding:8px;padding-left:16px;padding-right:16px;}</style><div class=\"css-yv011k\"><div data-cy=\"header-session\" css=\"[object Object]\"><style data-emotion=\"css 8zmdb0\">.css-8zmdb0{color:#03EF62;}</style><svg aria-hidden=\"true\" height=\"16\" width=\"16\" viewbox=\"0 0 18 18\" aria-label=\"Session Ready\" class=\"css-8zmdb0\"><path fill=\"currentColor\" d=\"M9 18A9 9 0 1 1 9 0a9 9 0 0 1 0 18Z\"/></svg><style data-emotion=\"css 1isemmb\">.css-1isemmb{margin-left:8px;}</style><span class=\"css-1isemmb\">Initializing</span></div></div></section></div></nav></header><style data-emotion=\"css iqa0tj\">.css-iqa0tj{position:absolute;top:100px;bottom:32px;right:12px;left:12px;overflow:hidden;}</style><main class=\"css-iqa0tj\"><div data-cy=\"server-side-loader-placeholder\"><aside class=\"exercise--sidebar\" style=\"width:40%\"><div class=\"exercise--sidebar-content\"><div class=\"listview__outer\"><div class=\"listview__inner\"><div class=\"listview__section\"><div><div role=\"button\" class=\"listview__header\"><style data-emotion=\"css r7m65a\">.css-r7m65a{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;height:100%;padding-right:16px;}</style><div class=\"css-r7m65a\"><style data-emotion=\"css 171fln0\">.css-171fln0{font-size:16px;margin:0;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;gap:8px;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;padding-left:16px;}</style><style data-emotion=\"css 10nfsoz\">.css-10nfsoz{font-weight:800;line-height:1.25;margin-bottom:8px;font-size:18px;font-size:16px;margin:0;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;gap:8px;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;padding-left:16px;}</style><style data-emotion=\"css 1tah88q\">.css-1tah88q{color:var(--wf-text--main, #05192D);font-family:Studio-Feixen-Sans,Arial,sans-serif;font-weight:400;line-height:1.5;margin:0;padding:0;font-size:14px;font-weight:800;line-height:1.25;margin-bottom:8px;font-size:18px;font-size:16px;margin:0;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;gap:8px;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;padding-left:16px;}</style><h2 class=\"css-1tah88q\"><svg aria-hidden=\"true\" height=\"14\" width=\"14\" viewbox=\"0 0 18 18\"><path fill=\"currentColor\" d=\"M4 2a1 1 0 0 0-1 1v12a1 1 0 0 0 1 1h10a1 1 0 0 0 1-1V3a1 1 0 0 0-1-1H4Zm0-2h10a3 3 0 0 1 3 3v12a3 3 0 0 1-3 3H4a3 3 0 0 1-3-3V3a3 3 0 0 1 3-3Zm2 6h6a1 1 0 0 1 0 2H6a1 1 0 1 1 0-2Zm0 4h6a1 1 0 0 1 0 2H6a1 1 0 0 1 0-2Z\"/></svg>Exercise</h2></div></div></div><div class=\"listview__content\"><style data-emotion=\"css ikv0qb\">.css-ikv0qb{position:relative;padding:16px;}</style><div class=\"css-ikv0qb\"><style data-emotion=\"css 1c1rk5o\">.css-1c1rk5o{font-weight:800;line-height:1.25;margin-bottom:8px;font-size:20px;}</style><style data-emotion=\"css fsa3o0\">.css-fsa3o0{color:var(--wf-text--main, #05192D);font-family:Studio-Feixen-Sans,Arial,sans-serif;font-weight:400;line-height:1.5;margin:0;padding:0;font-size:14px;font-weight:800;line-height:1.25;margin-bottom:8px;font-size:20px;}</style><h1 class=\"css-fsa3o0\">Importing flat files from the web: your turn!</h1><style data-emotion=\"css 8czf7d\">.css-8czf7d{line-height:1.5;}.css-8czf7d code{font-family:JetBrainsMonoNL,Menlo,Monaco,'Courier New',monospace;margin:0 2px;padding:2px 4px;line-height:1.25;background-color:#EFEFF5;border-radius:4px;font-size:86%;mix-blend-mode:multiply;}.css-8czf7d pre{background-color:#EFEFF5;padding:8px;margin:0;border-radius:4px;tab-size:4;white-space:pre;line-height:1.25;mix-blend-mode:multiply;}.css-8czf7d pre>code{margin:0;padding:0;background-color:transparent;}.css-8czf7d ul,.css-8czf7d ol{padding-left:16px;}.css-8czf7d ul:first-of-type,.css-8czf7d ol:first-of-type{margin-top:0;}.css-8czf7d p:first-of-type{margin-top:0;}.css-8czf7d li{margin-bottom:8px;}.css-8czf7d a{color:#0065D1;-webkit-text-decoration:none;text-decoration:none;font-weight:800;border-radius:4px;outline:0;}.css-8czf7d a:hover{color:#0065D1;-webkit-text-decoration:underline;text-decoration:underline;}.css-8czf7d a:focus-visible{box-shadow:0 0 0 2px #257DFE;}.css-8czf7d a code{color:#0065D1;}.css-8czf7d hr{background-color:rgba(48, 57, 105, 0.15);border:0;height:1px;margin:16px 0;}</style><style data-emotion=\"css alxior\">.css-alxior{color:var(--wf-text--main, #05192D);font-family:Studio-Feixen-Sans,Arial,sans-serif;font-weight:400;line-height:1.5;margin:0;padding:0;font-size:14px;line-height:1.5;}.css-alxior code{font-family:JetBrainsMonoNL,Menlo,Monaco,'Courier New',monospace;margin:0 2px;padding:2px 4px;line-height:1.25;background-color:#EFEFF5;border-radius:4px;font-size:86%;mix-blend-mode:multiply;}.css-alxior pre{background-color:#EFEFF5;padding:8px;margin:0;border-radius:4px;tab-size:4;white-space:pre;line-height:1.25;mix-blend-mode:multiply;}.css-alxior pre>code{margin:0;padding:0;background-color:transparent;}.css-alxior ul,.css-alxior ol{padding-left:16px;}.css-alxior ul:first-of-type,.css-alxior ol:first-of-type{margin-top:0;}.css-alxior p:first-of-type{margin-top:0;}.css-alxior li{margin-bottom:8px;}.css-alxior a{color:#0065D1;-webkit-text-decoration:none;text-decoration:none;font-weight:800;border-radius:4px;outline:0;}.css-alxior a:hover{color:#0065D1;-webkit-text-decoration:underline;text-decoration:underline;}.css-alxior a:focus-visible{box-shadow:0 0 0 2px #257DFE;}.css-alxior a code{color:#0065D1;}.css-alxior hr{background-color:rgba(48, 57, 105, 0.15);border:0;height:1px;margin:16px 0;}</style><div class=\"css-alxior\"><div class><p>You are about to import your first file from the web! The flat file you will import will be <code>&apos;winequality-red.csv&apos;</code> from the University of California, Irvine&apos;s <a href=\"https://archive.ics.uci.edu/ml/index.php\">Machine Learning repository</a>. The flat file contains tabular data of physiochemical properties of red wine, such as pH, alcohol content and citric acid content, along with wine quality rating.</p>\n",
            "<p>The URL of the file is</p>\n",
            "<pre><code>&apos;https://assets.datacamp.com/production/course_1606/datasets/winequality-red.csv&apos;\n",
            "</code></pre>\n",
            "<p>After you import it, you&apos;ll check your working directory to confirm that it is there and then you&apos;ll load it into a <code>pandas</code> DataFrame.</p></div></div></div></div></div><div class=\"listview__section\" style=\"min-height:calc(50% - 33px)\"><div><div role=\"button\" class=\"listview__header\"><div class=\"css-r7m65a\"><style data-emotion=\"css 1ubtfgv\">.css-1ubtfgv{font-size:16px;margin:0;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;gap:8px;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;padding-left:16px;width:100%;-webkit-box-flex:1;-webkit-flex-grow:1;-ms-flex-positive:1;flex-grow:1;}</style><style data-emotion=\"css ycumlt\">.css-ycumlt{font-weight:800;line-height:1.25;margin-bottom:8px;font-size:18px;font-size:16px;margin:0;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;gap:8px;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;padding-left:16px;width:100%;-webkit-box-flex:1;-webkit-flex-grow:1;-ms-flex-positive:1;flex-grow:1;}</style><style data-emotion=\"css 1kphf8n\">.css-1kphf8n{color:var(--wf-text--main, #05192D);font-family:Studio-Feixen-Sans,Arial,sans-serif;font-weight:400;line-height:1.5;margin:0;padding:0;font-size:14px;font-weight:800;line-height:1.25;margin-bottom:8px;font-size:18px;font-size:16px;margin:0;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;gap:8px;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;padding-left:16px;width:100%;-webkit-box-flex:1;-webkit-flex-grow:1;-ms-flex-positive:1;flex-grow:1;}</style><h2 class=\"css-1kphf8n\"><svg aria-hidden=\"true\" height=\"14\" width=\"14\" viewbox=\"0 0 18 18\"><path fill=\"currentColor\" d=\"M9 16A7 7 0 1 0 9 2a7 7 0 0 0 0 14Zm0 2A9 9 0 1 1 9 0a9 9 0 0 1 0 18Zm2.326-11.96a1 1 0 0 1 1.555 1.258L8.773 12.37a1 1 0 0 1-1.534.024l-2.124-2.46a1 1 0 0 1 1.514-1.307l1.342 1.556 3.355-4.144Z\"/></svg>Instructions</h2><style data-emotion=\"css 17lebkx\">.css-17lebkx{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;font-family:Studio-Feixen-Sans,Arial,sans-serif;font-weight:800;-webkit-box-pack:center;-ms-flex-pack:center;-webkit-justify-content:center;justify-content:center;letter-spacing:0.5px;line-height:1;padding:0 4px;text-transform:uppercase;border-radius:4px;background-color:var(--wf-yellow--main, #FCCE0D);color:var(--wf-yellow--main, #FCCE0D);font-size:12px;height:18px;}.css-17lebkx span{color:var(--wf-yellow--text-on-color, #05192D);}</style><style data-emotion=\"css 1gjxyd4\">.css-1gjxyd4{color:var(--wf-text--main, #05192D);font-family:Studio-Feixen-Sans,Arial,sans-serif;font-weight:400;line-height:1.5;margin:0;padding:0;font-size:14px;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;font-family:Studio-Feixen-Sans,Arial,sans-serif;font-weight:800;-webkit-box-pack:center;-ms-flex-pack:center;-webkit-justify-content:center;justify-content:center;letter-spacing:0.5px;line-height:1;padding:0 4px;text-transform:uppercase;border-radius:4px;background-color:var(--wf-yellow--main, #FCCE0D);color:var(--wf-yellow--main, #FCCE0D);font-size:12px;height:18px;}.css-1gjxyd4 span{color:var(--wf-yellow--text-on-color, #05192D);}</style><span class=\"css-1gjxyd4\"><style data-emotion=\"css 19ist84\">.css-19ist84{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;color:inherit;display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;gap:4px;max-width:164px;}</style><span class=\"css-19ist84\"><style data-emotion=\"css 8uhtka\">.css-8uhtka{overflow:hidden;text-overflow:ellipsis;white-space:nowrap;}</style><span class=\"css-8uhtka\">100 XP</span></span></span></div></div></div><div class=\"listview__content\"><div><style data-emotion=\"css 186pnwx\">.css-186pnwx{-webkit-flex:1;-ms-flex:1;flex:1;position:relative;padding:16px;}</style><div class=\"css-186pnwx\"><div class=\"css-alxior\"><div class=\"exercise--instructions__content\"><ul>\n",
            "<li>Import the function <code>urlretrieve</code> from the subpackage <code>urllib.request</code>.</li>\n",
            "<li>Assign the URL of the file to the variable <code>url</code>.</li>\n",
            "<li>Use the function <code>urlretrieve()</code> to save the file locally as <code>&apos;winequality-red.csv&apos;</code>.</li>\n",
            "<li>Execute the remaining code to load <code>&apos;winequality-red.csv&apos;</code> in a pandas DataFrame and to print its head to the shell.</li>\n",
            "</ul></div></div><style data-emotion=\"css kbabwt\">.css-kbabwt{margin:16px -16px 0;}</style><div class=\"css-kbabwt\"><section class=\"dc-sct-feedback\" tabindex=\"-1\"><div></div><nav class=\"dc-sct-feedback__nav\"><style data-emotion=\"css n085mf\">.css-n085mf{padding-left:16px;}</style><div class=\"css-n085mf\"><style data-emotion=\"css 12j1yck\">.css-12j1yck{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;border:0;border-radius:4px;border-style:solid;border-width:2px;cursor:pointer;display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;-webkit-box-pack:center;-ms-flex-pack:center;-webkit-justify-content:center;justify-content:center;position:relative;-webkit-text-decoration:none;text-decoration:none;text-transform:capitalize;-webkit-transition:0.15s;transition:0.15s;vertical-align:baseline;white-space:nowrap;background-color:transparent;border-color:#05192D;color:#05192D;padding:0 15px;}.css-12j1yck:active{-webkit-transform:perspective(1px) scale(0.975);-moz-transform:perspective(1px) scale(0.975);-ms-transform:perspective(1px) scale(0.975);transform:perspective(1px) scale(0.975);}.css-12j1yck:disabled,.css-12j1yck:hover:disabled,.css-12j1yck:active:disabled{-webkit-transform:none;-moz-transform:none;-ms-transform:none;transform:none;}.css-12j1yck:focus{outline:0;}.css-12j1yck:hover{background-color:rgba(5, 25, 45, 0.15);border-color:#05192D;color:#05192D;}</style><button class=\"dc-sct-feedback__nav--hint-solution css-12j1yck\" type=\"button\" data-cy=\"exercise-show-hint\"><svg viewbox=\"0 0 18 18\" aria-hidden=\"true\" height=\"16\" role=\"img\" width=\"16\"><path fill=\"currentColor\" d=\"M9 0a7 7 0 014.95 11.95l-.001-.001c-.794.795-.949 1.1-.949 2.051a1 1 0 01-2 0c0-1.548.396-2.325 1.535-3.467l.04-.037a5 5 0 10-7.11.037C6.605 11.675 7 12.453 7 14a1 1 0 01-2 0c0-.951-.155-1.256-.949-2.051A7 7 0 019 0zm0 7a1 1 0 011 1v6a1 1 0 01-2 0V8a1 1 0 011-1zm0 11c-1.657 0-3-.895-3-2h6c0 1.105-1.343 2-3 2z\" fill-rule=\"evenodd\"/></svg><style data-emotion=\"css aib9ji\">.css-aib9ji{font-size:14px;line-height:32px;color:#05192D;font-weight:bold;margin-left:8px;}</style><style data-emotion=\"css vvk465\">.css-vvk465{-webkit-font-smoothing:antialiased;color:#05192D;font-family:Studio-Feixen-Sans,Arial,sans-serif;font-style:normal;font-size:14px;font-weight:400;font-size:14px;line-height:32px;color:#05192D;font-weight:bold;margin-left:8px;}</style><span class=\"css-vvk465\">Take Hint (-30 XP)</span></button></div></nav></section></div></div></div></div></div></div></div></div></aside><section class=\"exercise--content\" style=\"width:60%\"><div class=\"exercise-waiting\"><style data-emotion=\"css 1gnr744\">.css-1gnr744{position:absolute;top:50%;left:50%;-webkit-transform:translate(-50%, -50%);-moz-transform:translate(-50%, -50%);-ms-transform:translate(-50%, -50%);transform:translate(-50%, -50%);display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-ms-flex-pack:center;-webkit-justify-content:center;justify-content:center;}</style><div class=\"css-1gnr744\"><style data-emotion=\"css 1rm9ybb animation-1pv1bkr\">.css-1rm9ybb{-webkit-animation:animation-1pv1bkr cubic-bezier(0.65, 0, 0.55, 1) 2s infinite alternate;animation:animation-1pv1bkr cubic-bezier(0.65, 0, 0.55, 1) 2s infinite alternate;will-change:clip-path;--wf-loader--color:var(--wf-text--main, #05192D);width:50;}@-webkit-keyframes animation-1pv1bkr{0%,6%{-webkit-clip-path:polygon(0% -12%, 0% -12%, 169% 63%, 169% 63%);clip-path:polygon(0% -12%, 0% -12%, 169% 63%, 169% 63%);}100%{-webkit-clip-path:polygon(0% -12%, 0% 308%, 169% 383%, 169% 63%);clip-path:polygon(0% -12%, 0% 308%, 169% 383%, 169% 63%);}}@keyframes animation-1pv1bkr{0%,6%{-webkit-clip-path:polygon(0% -12%, 0% -12%, 169% 63%, 169% 63%);clip-path:polygon(0% -12%, 0% -12%, 169% 63%, 169% 63%);}100%{-webkit-clip-path:polygon(0% -12%, 0% 308%, 169% 383%, 169% 63%);clip-path:polygon(0% -12%, 0% 308%, 169% 383%, 169% 63%);}}</style><div aria-label=\"Loading\" data-testid=\"loader-wrapper\" role=\"alert\" class=\"css-1rm9ybb\"><style data-emotion=\"css 1j8nxo animation-1h2cwi2\">.css-1j8nxo{-webkit-animation:animation-1h2cwi2 cubic-bezier(0, 0, 0.85, 1) 2s infinite alternate;animation:animation-1h2cwi2 cubic-bezier(0, 0, 0.85, 1) 2s infinite alternate;will-change:clip-path;}@-webkit-keyframes animation-1h2cwi2{0%,71%{-webkit-clip-path:polygon(0% 0%, 0% 78.5%, 100% 34.5%, 100% -44%);clip-path:polygon(0% 0%, 0% 78.5%, 100% 34.5%, 100% -44%);}96%,100%{-webkit-clip-path:polygon(0% 0%, 0% 140%, 100% 96%, 100% -44%);clip-path:polygon(0% 0%, 0% 140%, 100% 96%, 100% -44%);}}@keyframes animation-1h2cwi2{0%,71%{-webkit-clip-path:polygon(0% 0%, 0% 78.5%, 100% 34.5%, 100% -44%);clip-path:polygon(0% 0%, 0% 78.5%, 100% 34.5%, 100% -44%);}96%,100%{-webkit-clip-path:polygon(0% 0%, 0% 140%, 100% 96%, 100% -44%);clip-path:polygon(0% 0%, 0% 140%, 100% 96%, 100% -44%);}}</style><div class=\"css-1j8nxo\"><style data-emotion=\"css zsjzbc\">.css-zsjzbc{-webkit-clip-path:polygon(-0.1% -10%, 169% 65%, -0.1% 139%);clip-path:polygon(-0.1% -10%, 169% 65%, -0.1% 139%);}</style><div class=\"css-zsjzbc\"><style data-emotion=\"css cihpzr\">.css-cihpzr{display:block;overflow:visible;stroke:var(--wf-loader--color, var(--wf-text--main, #05192D));}</style><svg viewbox=\"0 0 2640 3444\" width=\"50\" class=\"css-cihpzr\"><style data-emotion=\"css jy99qt animation-co7x2c\">.css-jy99qt{-webkit-animation:animation-co7x2c cubic-bezier(0.65, 0, 0.55, 1) 2s infinite alternate;animation:animation-co7x2c cubic-bezier(0.65, 0, 0.55, 1) 2s infinite alternate;stroke-dasharray:9800;stroke-dashoffset:9800;will-change:stroke-dashoffset;}@-webkit-keyframes animation-co7x2c{100%{stroke-dashoffset:0;}}@keyframes animation-co7x2c{100%{stroke-dashoffset:0;}}</style><path d=\"M0 0 M2569 1056L143 2447V149l1175 673v1867l1248 715\" fill=\"none\" stroke-linejoin=\"round\" stroke-width=\"300\" class=\"css-jy99qt\"/></svg></div></div></div></div><noscript></noscript></div></section></div></main><div class=\"exercise-footer\"><style data-emotion=\"css 8uttuf\">.css-8uttuf{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-ms-flex-pack:center;-webkit-justify-content:center;justify-content:center;width:100%;max-width:600px;list-style:none;margin:0;padding:0;gap:8px;}</style><ul data-cy=\"progress-container\" class=\"css-8uttuf\"><style data-emotion=\"css 149stfi\">.css-149stfi{-webkit-box-flex:1;-webkit-flex-grow:1;-ms-flex-positive:1;flex-grow:1;max-width:100px;}</style><li class=\"css-149stfi\"><style data-emotion=\"css 46tute\">.css-46tute{display:block;height:8px;border-radius:4px;background-color:rgba(48, 57, 105, 0.15);border-bottom:0;outline:0;}.css-46tute:focus-visible{box-shadow:0 0 0 2px #257DFE;}</style><a href=\"javascript:void(0)\" data-testid=\"progress-indicator-item\" class=\"css-46tute\"><style data-emotion=\"css 1pw8nbl\">.css-1pw8nbl{-webkit-transition:width 250ms linear;transition:width 250ms linear;height:8px;border-radius:4px;background-color:#5EB1FF;}</style><div style=\"width:0%\" class=\"css-1pw8nbl\"></div></a></li><li class=\"css-149stfi\"><a href=\"javascript:void(0)\" data-testid=\"progress-indicator-item\" class=\"css-46tute\"><div style=\"width:0%\" class=\"css-1pw8nbl\"></div></a></li><li class=\"css-149stfi\"><a href=\"javascript:void(0)\" data-testid=\"progress-indicator-item\" class=\"css-46tute\"><div style=\"width:0%\" class=\"css-1pw8nbl\"></div></a></li></ul></div></div></div><script>window.MathJax={options:{ignoreHtmlClass:\"tex2jax_ignore\",processHtmlClass:\"tex2jax_process\"},tex:{autoload:{color:[],colorV2:[\"color\"]},packages:{\"[+]\":[\"noerrors\"]}},loader:{load:[\"[tex]/noerrors\"]}}</script><script src=\"/campus/mathjax@3/es5/tex-chtml.js\" id=\"MathJax-script\" async></script><script>!function(e){function o(o){for(var d,n,r=o[0],s=o[1],m=o[2],t=0,v=[];t<r.length;t++)n=r[t],Object.prototype.hasOwnProperty.call(a,n)&&a[n]&&v.push(a[n][0]),a[n]=0;for(d in s)Object.prototype.hasOwnProperty.call(s,d)&&(e[d]=s[d]);for(b&&b(o);v.length;)v.shift()();return f.push.apply(f,m||[]),c()}function c(){for(var e,o=0;o<f.length;o++){for(var c=f[o],d=!0,n=1;n<c.length;n++){var s=c[n];0!==a[s]&&(d=!1)}d&&(f.splice(o--,1),e=r(r.s=c[0]))}return e}var d={},n={97:0},a={97:0},f=[];function r(o){if(d[o])return d[o].exports;var c=d[o]={i:o,l:!1,exports:{}};return e[o].call(c.exports,c,c.exports,r),c.l=!0,c.exports}r.e=function(e){var o=[];n[e]?o.push(n[e]):0!==n[e]&&{0:1,5:1,11:1,15:1,16:1,17:1,18:1,22:1,24:1,27:1,29:1,32:1,33:1,35:1,41:1,45:1,48:1,51:1,52:1,53:1,54:1,55:1,59:1,61:1,62:1,63:1,66:1,68:1,71:1,72:1,87:1,93:1,94:1,96:1,136:1,138:1,139:1}[e]&&o.push(n[e]=new Promise((function(o,c){for(var d=\"static/css/\"+({0:\"vendors~ce~dnde~ee~ge~idee~pmce~rde~se~ve~vise~a4f7b5e1\",1:\"vendors~ce~dnde~ee~ge~idee~pmce~rde~splitio~ve~vise~253ae210\",2:\"vendors~ce~dnde~ee~ge~idee~pmce~rde~splitio~ve~vise~c7ce39a9\",3:\"vendors~ce~dnde~ee~ge~idee~pmce~rde~splitio~ve~vise~d49b3b41\",4:\"vendors~ce~dnde~ee~ge~idee~pmce~rde~ve~vise~253ae210\",5:\"vendors~dnde~ee~ge~idee~pmce~vise~253ae210\",6:\"vendors~ce~rde~253ae210\",7:\"vendors~ce~rde~7274e1de\",8:\"vendors~ce~rde~b5a0571e\",9:\"vendors~console-monaco~monaco~235b8c57\",10:\"vendors~console-monaco~monaco~253ae210\",11:\"vendors~console-monaco~monaco~36912834\",12:\"vendors~console-monaco~monaco~49d8ad03\",13:\"vendors~console-monaco~monaco~4d911f2e\",14:\"vendors~console-monaco~monaco~5584ff6c\",15:\"vendors~console-monaco~monaco~57c220dc\",16:\"vendors~console-monaco~monaco~589039fc\",17:\"vendors~console-monaco~monaco~5e1bc0de\",18:\"vendors~console-monaco~monaco~6ddf31e8\",19:\"vendors~console-monaco~monaco~80993005\",20:\"vendors~console-monaco~monaco~85a20469\",21:\"vendors~console-monaco~monaco~86ffeb1a\",22:\"vendors~console-monaco~monaco~900aca88\",23:\"vendors~console-monaco~monaco~9c5b28f6\",24:\"vendors~console-monaco~monaco~a03ee73f\",25:\"vendors~console-monaco~monaco~ba2d52b5\",26:\"vendors~console-monaco~monaco~c01cf258\",27:\"vendors~console-monaco~monaco~c682183c\",28:\"vendors~console-monaco~monaco~c73e0090\",29:\"vendors~console-monaco~monaco~d7ac9e7b\",30:\"vendors~console-monaco~monaco~dac6e39f\",31:\"vendors~console-monaco~monaco~e66ff6d3\",32:\"vendors~console-monaco~monaco~e69ef85d\",33:\"vendors~console-monaco~monaco~f7d19227\",35:\"ce~253ae210\",36:\"ce~40b10d04\",37:\"ce~62c53bf1\",38:\"ce~748942c6\",39:\"ce~a4f7b5e1\",40:\"console-monaco~31ecd969\",41:\"dnde~253ae210\",42:\"dnde~9c5b28f6\",43:\"dnde~c8f69aa9\",44:\"ee~253ae210\",45:\"ee~a4f7b5e1\",46:\"ge~06694820\",47:\"ge~235b8c57\",48:\"ge~36912834\",49:\"ge~4d911f2e\",50:\"ge~5584ff6c\",51:\"ge~57c220dc\",52:\"ge~589039fc\",53:\"ge~5e1bc0de\",54:\"ge~6ddf31e8\",55:\"ge~7f323393\",56:\"ge~80993005\",57:\"ge~85a20469\",58:\"ge~86ffeb1a\",59:\"ge~900aca88\",60:\"ge~9c5b28f6\",61:\"ge~a03ee73f\",62:\"ge~a4f7b5e1\",63:\"ge~b6351802\",64:\"ge~ba2d52b5\",65:\"ge~c01cf258\",66:\"ge~c682183c\",67:\"ge~c73e0090\",68:\"ge~d7ac9e7b\",69:\"ge~dac6e39f\",70:\"ge~e66ff6d3\",71:\"ge~f7d19227\",72:\"idee~0f485567\",73:\"idee~253ae210\",80:\"markdown-renderer~2353b14b\",81:\"modal-views~31ecd969\",82:\"monaco~31ecd969\",83:\"pmce~0df6afb5\",84:\"pmce~253ae210\",85:\"pmce~56e1be11\",86:\"pmce~9c5b28f6\",87:\"pmce~a4f7b5e1\",88:\"pmce~d80adb5f\",89:\"pmce~e65503b9\",90:\"pmce~ece0910c\",91:\"rde~1f059a71\",92:\"rde~253ae210\",93:\"rde~3dd5b2e0\",94:\"rde~3ffedb8b\",95:\"rde~5f1bbfc7\",96:\"rde~748942c6\",135:\"vendors~se~253ae210\",136:\"vendors~se~a4f7b5e1\",137:\"vendors~se~d0fcca00\",138:\"vendors~ve~cfba5e8d\",139:\"vendors~xterm~0d30e071\",140:\"vise~b26d07d5\",141:\"vise~da250ca5\",142:\"vise~e65503b9\",143:\"xterm~d021be4b\"}[e]||e)+\".\"+{0:\"f479e7a2\",1:\"31d6cfe0\",2:\"31d6cfe0\",3:\"31d6cfe0\",4:\"31d6cfe0\",5:\"a8d4fad6\",6:\"31d6cfe0\",7:\"31d6cfe0\",8:\"31d6cfe0\",9:\"31d6cfe0\",10:\"31d6cfe0\",11:\"1ad26591\",12:\"31d6cfe0\",13:\"31d6cfe0\",14:\"31d6cfe0\",15:\"ea109276\",16:\"59e05191\",17:\"9bf089b3\",18:\"d2c4604b\",19:\"31d6cfe0\",20:\"31d6cfe0\",21:\"31d6cfe0\",22:\"7a6ad70e\",23:\"31d6cfe0\",24:\"98d862d2\",25:\"31d6cfe0\",26:\"31d6cfe0\",27:\"03248981\",28:\"31d6cfe0\",29:\"9f101993\",30:\"31d6cfe0\",31:\"31d6cfe0\",32:\"3f1ff7c1\",33:\"2281ed76\",34:\"31d6cfe0\",35:\"7986f49c\",36:\"31d6cfe0\",37:\"31d6cfe0\",38:\"31d6cfe0\",39:\"31d6cfe0\",40:\"31d6cfe0\",41:\"f63aa94e\",42:\"31d6cfe0\",43:\"31d6cfe0\",44:\"31d6cfe0\",45:\"318451f9\",46:\"31d6cfe0\",47:\"31d6cfe0\",48:\"1ad26591\",49:\"31d6cfe0\",50:\"31d6cfe0\",51:\"ea109276\",52:\"59e05191\",53:\"9bf089b3\",54:\"d2c4604b\",55:\"96a878eb\",56:\"31d6cfe0\",57:\"31d6cfe0\",58:\"31d6cfe0\",59:\"7a6ad70e\",60:\"31d6cfe0\",61:\"98d862d2\",62:\"d498bfb3\",63:\"28103d70\",64:\"31d6cfe0\",65:\"31d6cfe0\",66:\"03248981\",67:\"31d6cfe0\",68:\"9f101993\",69:\"31d6cfe0\",70:\"31d6cfe0\",71:\"2281ed76\",72:\"c86e1775\",73:\"31d6cfe0\",80:\"31d6cfe0\",81:\"31d6cfe0\",82:\"31d6cfe0\",83:\"31d6cfe0\",84:\"31d6cfe0\",85:\"31d6cfe0\",86:\"31d6cfe0\",87:\"5f802060\",88:\"31d6cfe0\",89:\"31d6cfe0\",90:\"31d6cfe0\",91:\"31d6cfe0\",92:\"31d6cfe0\",93:\"05896465\",94:\"0cc5eb29\",95:\"31d6cfe0\",96:\"53e0c1db\",135:\"31d6cfe0\",136:\"74da6240\",137:\"31d6cfe0\",138:\"37797958\",139:\"9e71d144\",140:\"31d6cfe0\",141:\"31d6cfe0\",142:\"31d6cfe0\",143:\"31d6cfe0\",144:\"31d6cfe0\",145:\"31d6cfe0\",146:\"31d6cfe0\",147:\"31d6cfe0\",148:\"31d6cfe0\",149:\"31d6cfe0\",150:\"31d6cfe0\",151:\"31d6cfe0\",152:\"31d6cfe0\",153:\"31d6cfe0\"}[e]+\".chunk.css\",a=r.p+d,f=document.getElementsByTagName(\"link\"),s=0;s<f.length;s++){var m=(b=f[s]).getAttribute(\"data-href\")||b.getAttribute(\"href\");if(\"stylesheet\"===b.rel&&(m===d||m===a))return o()}var t=document.getElementsByTagName(\"style\");for(s=0;s<t.length;s++){var b;if((m=(b=t[s]).getAttribute(\"data-href\"))===d||m===a)return o()}var v=document.createElement(\"link\");v.rel=\"stylesheet\",v.type=\"text/css\",v.onload=o,v.onerror=function(o){var d=o&&o.target&&o.target.src||a,f=new Error(\"Loading CSS chunk \"+e+\" failed.\\n(\"+d+\")\");f.code=\"CSS_CHUNK_LOAD_FAILED\",f.request=d,delete n[e],v.parentNode.removeChild(v),c(f)},v.href=a,document.getElementsByTagName(\"head\")[0].appendChild(v)})).then((function(){n[e]=0})));var c=a[e];if(0!==c)if(c)o.push(c[2]);else{var d=new Promise((function(o,d){c=a[e]=[o,d]}));o.push(c[2]=d);var f,s=document.createElement(\"script\");s.charset=\"utf-8\",s.timeout=120,r.nc&&s.setAttribute(\"nonce\",r.nc),s.src=function(e){return r.p+\"static/js/\"+({0:\"vendors~ce~dnde~ee~ge~idee~pmce~rde~se~ve~vise~a4f7b5e1\",1:\"vendors~ce~dnde~ee~ge~idee~pmce~rde~splitio~ve~vise~253ae210\",2:\"vendors~ce~dnde~ee~ge~idee~pmce~rde~splitio~ve~vise~c7ce39a9\",3:\"vendors~ce~dnde~ee~ge~idee~pmce~rde~splitio~ve~vise~d49b3b41\",4:\"vendors~ce~dnde~ee~ge~idee~pmce~rde~ve~vise~253ae210\",5:\"vendors~dnde~ee~ge~idee~pmce~vise~253ae210\",6:\"vendors~ce~rde~253ae210\",7:\"vendors~ce~rde~7274e1de\",8:\"vendors~ce~rde~b5a0571e\",9:\"vendors~console-monaco~monaco~235b8c57\",10:\"vendors~console-monaco~monaco~253ae210\",11:\"vendors~console-monaco~monaco~36912834\",12:\"vendors~console-monaco~monaco~49d8ad03\",13:\"vendors~console-monaco~monaco~4d911f2e\",14:\"vendors~console-monaco~monaco~5584ff6c\",15:\"vendors~console-monaco~monaco~57c220dc\",16:\"vendors~console-monaco~monaco~589039fc\",17:\"vendors~console-monaco~monaco~5e1bc0de\",18:\"vendors~console-monaco~monaco~6ddf31e8\",19:\"vendors~console-monaco~monaco~80993005\",20:\"vendors~console-monaco~monaco~85a20469\",21:\"vendors~console-monaco~monaco~86ffeb1a\",22:\"vendors~console-monaco~monaco~900aca88\",23:\"vendors~console-monaco~monaco~9c5b28f6\",24:\"vendors~console-monaco~monaco~a03ee73f\",25:\"vendors~console-monaco~monaco~ba2d52b5\",26:\"vendors~console-monaco~monaco~c01cf258\",27:\"vendors~console-monaco~monaco~c682183c\",28:\"vendors~console-monaco~monaco~c73e0090\",29:\"vendors~console-monaco~monaco~d7ac9e7b\",30:\"vendors~console-monaco~monaco~dac6e39f\",31:\"vendors~console-monaco~monaco~e66ff6d3\",32:\"vendors~console-monaco~monaco~e69ef85d\",33:\"vendors~console-monaco~monaco~f7d19227\",35:\"ce~253ae210\",36:\"ce~40b10d04\",37:\"ce~62c53bf1\",38:\"ce~748942c6\",39:\"ce~a4f7b5e1\",40:\"console-monaco~31ecd969\",41:\"dnde~253ae210\",42:\"dnde~9c5b28f6\",43:\"dnde~c8f69aa9\",44:\"ee~253ae210\",45:\"ee~a4f7b5e1\",46:\"ge~06694820\",47:\"ge~235b8c57\",48:\"ge~36912834\",49:\"ge~4d911f2e\",50:\"ge~5584ff6c\",51:\"ge~57c220dc\",52:\"ge~589039fc\",53:\"ge~5e1bc0de\",54:\"ge~6ddf31e8\",55:\"ge~7f323393\",56:\"ge~80993005\",57:\"ge~85a20469\",58:\"ge~86ffeb1a\",59:\"ge~900aca88\",60:\"ge~9c5b28f6\",61:\"ge~a03ee73f\",62:\"ge~a4f7b5e1\",63:\"ge~b6351802\",64:\"ge~ba2d52b5\",65:\"ge~c01cf258\",66:\"ge~c682183c\",67:\"ge~c73e0090\",68:\"ge~d7ac9e7b\",69:\"ge~dac6e39f\",70:\"ge~e66ff6d3\",71:\"ge~f7d19227\",72:\"idee~0f485567\",73:\"idee~253ae210\",80:\"markdown-renderer~2353b14b\",81:\"modal-views~31ecd969\",82:\"monaco~31ecd969\",83:\"pmce~0df6afb5\",84:\"pmce~253ae210\",85:\"pmce~56e1be11\",86:\"pmce~9c5b28f6\",87:\"pmce~a4f7b5e1\",88:\"pmce~d80adb5f\",89:\"pmce~e65503b9\",90:\"pmce~ece0910c\",91:\"rde~1f059a71\",92:\"rde~253ae210\",93:\"rde~3dd5b2e0\",94:\"rde~3ffedb8b\",95:\"rde~5f1bbfc7\",96:\"rde~748942c6\",135:\"vendors~se~253ae210\",136:\"vendors~se~a4f7b5e1\",137:\"vendors~se~d0fcca00\",138:\"vendors~ve~cfba5e8d\",139:\"vendors~xterm~0d30e071\",140:\"vise~b26d07d5\",141:\"vise~da250ca5\",142:\"vise~e65503b9\",143:\"xterm~d021be4b\"}[e]||e)+\".\"+{0:\"1d82e8a6\",1:\"49e109bd\",2:\"12db2881\",3:\"1647a0ff\",4:\"2705d6e6\",5:\"d2c8e124\",6:\"91be1254\",7:\"dc75903c\",8:\"344c3320\",9:\"34551be5\",10:\"312dc061\",11:\"f36228cf\",12:\"2faff24d\",13:\"1dfe5846\",14:\"b5d496c9\",15:\"9549b59d\",16:\"7b88f286\",17:\"583f9755\",18:\"c2d7c43a\",19:\"228ba56e\",20:\"39bed9b8\",21:\"4b7b5385\",22:\"ab6a4a63\",23:\"c67012bc\",24:\"3c5f6279\",25:\"afc56e20\",26:\"847c4771\",27:\"93ab0953\",28:\"244b3464\",29:\"2336e3c0\",30:\"b4ee706f\",31:\"ea970b75\",32:\"c6980440\",33:\"a2e94c09\",34:\"0ba116dc\",35:\"026785e0\",36:\"27bef178\",37:\"a25ea595\",38:\"c8b72a52\",39:\"12a7eefd\",40:\"2b265f1a\",41:\"40ac37b1\",42:\"819dad87\",43:\"3a885e0f\",44:\"a5217467\",45:\"6ea1cd17\",46:\"0e9723e4\",47:\"25735538\",48:\"fe7822b4\",49:\"935834d5\",50:\"5d3f006b\",51:\"f6aefef4\",52:\"484a730a\",53:\"dc6a3bde\",54:\"5ff44360\",55:\"9eaf98ee\",56:\"ada80d8b\",57:\"5e806715\",58:\"d732d9b7\",59:\"d85f6dd6\",60:\"e56d0c62\",61:\"de798489\",62:\"eee506a2\",63:\"e897e396\",64:\"a8ed2264\",65:\"203f0126\",66:\"113d0bea\",67:\"b2ec5b96\",68:\"73dd834a\",69:\"d439387b\",70:\"4bbd3371\",71:\"3e79f0f0\",72:\"5aa2c855\",73:\"2fdc94b1\",80:\"ba19212e\",81:\"6972e36a\",82:\"2a2a9899\",83:\"1c346ca6\",84:\"0c7d1196\",85:\"c81882a6\",86:\"0e95ac27\",87:\"de5d003b\",88:\"5e520d6f\",89:\"6526a9a6\",90:\"dd814856\",91:\"35ea6200\",92:\"f5f95f63\",93:\"b094ff69\",94:\"d025bc87\",95:\"e6cd7cc2\",96:\"ec2f67e7\",135:\"991604b3\",136:\"77548a1c\",137:\"187724fb\",138:\"f5526ffc\",139:\"5d751f87\",140:\"2cf3a967\",141:\"2623c691\",142:\"bf526353\",143:\"53e58be6\",144:\"d96374fc\",145:\"ddab4f00\",146:\"aaa861d2\",147:\"87909d9f\",148:\"62ce2ff3\",149:\"f4ec06fb\",150:\"08e5edc8\",151:\"20a1e5f0\",152:\"428db6be\",153:\"39b8d262\"}[e]+\".chunk.js\"}(e);var m=new Error;f=function(o){s.onerror=s.onload=null,clearTimeout(t);var c=a[e];if(0!==c){if(c){var d=o&&(\"load\"===o.type?\"missing\":o.type),n=o&&o.target&&o.target.src;m.message=\"Loading chunk \"+e+\" failed.\\n(\"+d+\": \"+n+\")\",m.name=\"ChunkLoadError\",m.type=d,m.request=n,c[1](m)}a[e]=void 0}};var t=setTimeout((function(){f({type:\"timeout\",target:s})}),12e4);s.onerror=s.onload=f,document.head.appendChild(s)}return Promise.all(o)},r.m=e,r.c=d,r.d=function(e,o,c){r.o(e,o)||Object.defineProperty(e,o,{enumerable:!0,get:c})},r.r=function(e){\"undefined\"!=typeof Symbol&&Symbol.toStringTag&&Object.defineProperty(e,Symbol.toStringTag,{value:\"Module\"}),Object.defineProperty(e,\"__esModule\",{value:!0})},r.t=function(e,o){if(1&o&&(e=r(e)),8&o)return e;if(4&o&&\"object\"==typeof e&&e&&e.__esModule)return e;var c=Object.create(null);if(r.r(c),Object.defineProperty(c,\"default\",{enumerable:!0,value:e}),2&o&&\"string\"!=typeof e)for(var d in e)r.d(c,d,function(o){return e[o]}.bind(null,d));return c},r.n=function(e){var o=e&&e.__esModule?function(){return e.default}:function(){return e};return r.d(o,\"a\",o),o},r.o=function(e,o){return Object.prototype.hasOwnProperty.call(e,o)},r.p=\"/campus/\",r.oe=function(e){throw console.error(e),e};var s=this[\"webpackJsonpcampus-app-v2\"]=this[\"webpackJsonpcampus-app-v2\"]||[],m=s.push.bind(s);s.push=o,s=s.slice();for(var t=0;t<s.length;t++)o(s[t]);var b=m;c()}([])</script><script src=\"/campus/static/js/vendors~main~253ae210.523d3d82.chunk.js\"></script><script src=\"/campus/static/js/vendors~main~0f485567.c868fd6b.chunk.js\"></script><script src=\"/campus/static/js/vendors~main~06694820.44d1436c.chunk.js\"></script><script src=\"/campus/static/js/vendors~main~977b87ed.9d55bb4c.chunk.js\"></script><script src=\"/campus/static/js/vendors~main~ea2ee6ce.7a02ffb4.chunk.js\"></script><script src=\"/campus/static/js/vendors~main~7af1ae76.52983e6d.chunk.js\"></script><script src=\"/campus/static/js/vendors~main~b24a28be.8ab2c38f.chunk.js\"></script><script src=\"/campus/static/js/vendors~main~2374ce8c.6848e79a.chunk.js\"></script><script src=\"/campus/static/js/vendors~main~975751f9.6b6210bf.chunk.js\"></script><script src=\"/campus/static/js/vendors~main~f6d28abc.af7ef5d8.chunk.js\"></script><script src=\"/campus/static/js/vendors~main~89b1000f.d5acdd11.chunk.js\"></script><script src=\"/campus/static/js/vendors~main~a122113c.276d3185.chunk.js\"></script><script src=\"/campus/static/js/vendors~main~ccbc3fde.4aa547a1.chunk.js\"></script><script src=\"/campus/static/js/vendors~main~13f6a649.cf4bb401.chunk.js\"></script><script src=\"/campus/static/js/vendors~main~7274e1de.903d7af6.chunk.js\"></script><script src=\"/campus/static/js/vendors~main~b5906859.004bf36c.chunk.js\"></script><script src=\"/campus/static/js/vendors~main~db300d2f.943f3c0a.chunk.js\"></script><script src=\"/campus/static/js/vendors~main~1f20a385.1f952117.chunk.js\"></script><script src=\"/campus/static/js/vendors~main~7d359b94.9400c848.chunk.js\"></script><script src=\"/campus/static/js/vendors~main~4d01349d.8d40e459.chunk.js\"></script><script src=\"/campus/static/js/vendors~main~d4b3742f.dacf4391.chunk.js\"></script><script src=\"/campus/static/js/vendors~main~690b702c.a5b9fe98.chunk.js\"></script><script src=\"/campus/static/js/vendors~main~2930ad93.aa4320fa.chunk.js\"></script><script src=\"/campus/static/js/vendors~main~bc6b49b0.1f691103.chunk.js\"></script><script src=\"/campus/static/js/vendors~main~9c5b28f6.c2f7398a.chunk.js\"></script><script src=\"/campus/static/js/vendors~main~678f84af.06c24110.chunk.js\"></script><script src=\"/campus/static/js/vendors~main~3f764be9.22d9c230.chunk.js\"></script><script src=\"/campus/static/js/vendors~main~3c941b24.662a3151.chunk.js\"></script><script src=\"/campus/static/js/vendors~main~98431bb7.a234f9ec.chunk.js\"></script><script src=\"/campus/static/js/vendors~main~d51fa4e6.f55bd344.chunk.js\"></script><script src=\"/campus/static/js/vendors~main~f53fef7e.eeddaa80.chunk.js\"></script><script src=\"/campus/static/js/vendors~main~d84fb1a9.6880f18f.chunk.js\"></script><script src=\"/campus/static/js/vendors~main~8e7b4e02.ea628f19.chunk.js\"></script><script src=\"/campus/static/js/vendors~main~33237170.076bc7ed.chunk.js\"></script><script src=\"/campus/static/js/vendors~main~ec8c427e.37e149cf.chunk.js\"></script><script src=\"/campus/static/js/vendors~main~1c3a2c3f.7969310b.chunk.js\"></script><script src=\"/campus/static/js/vendors~main~2900d54e.7cff0633.chunk.js\"></script><script src=\"/campus/static/js/main~748942c6.50d6f7e3.chunk.js\"></script><script src=\"/campus/static/js/main~21833f8f.deeede83.chunk.js\"></script><script src=\"/campus/static/js/main~b553cb79.a5cca2f1.chunk.js\"></script><script src=\"/campus/static/js/main~970f9218.a97caaee.chunk.js\"></script><script src=\"/campus/static/js/main~c714bc7b.f4b170d8.chunk.js\"></script><script src=\"/campus/static/js/main~cc2efef2.e8891ed5.chunk.js\"></script><script>(function(){function c(){var b=a.contentDocument||a.contentWindow.document;if(b){var d=b.createElement('script');d.innerHTML=\"window.__CF$cv$params={r:'8d1aedbf9e150bcc',t:'MTcyODc3NjM2MC4wMDAwMDA='};var a=document.createElement('script');a.nonce='';a.src='/cdn-cgi/challenge-platform/scripts/jsd/main.js';document.getElementsByTagName('head')[0].appendChild(a);\";b.getElementsByTagName('head')[0].appendChild(d)}}if(document.body){var a=document.createElement('iframe');a.height=1;a.width=1;a.style.position='absolute';a.style.top=0;a.style.left=0;a.style.border='none';a.style.visibility='hidden';document.body.appendChild(a);if('loading'!==document.readyState)c();else if(window.addEventListener)document.addEventListener('DOMContentLoaded',c);else{var e=document.onreadystatechange||function(){};document.onreadystatechange=function(b){e(b);'loading'!==document.readyState&&(document.onreadystatechange=e,c())}}}})();</script></body></html>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# HTML Parsing with BeautifulSoup\n",
        "\n",
        "# Import packages\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# Specify url: url\n",
        "url = 'https://www.python.org/~guido/'\n",
        "\n",
        "# Package the request, send the request and catch the response: r\n",
        "r = requests.get(url)\n",
        "\n",
        "# Extracts the response as html: html_doc\n",
        "html_doc = r.text\n",
        "\n",
        "# Create a BeautifulSoup object from the HTML: soup\n",
        "soup = BeautifulSoup(html_doc)\n",
        "\n",
        "# Prettify the BeautifulSoup object: pretty_soup\n",
        "pretty_soup = soup.prettify()\n",
        "\n",
        "# Print the response\n",
        "print(pretty_soup)\n",
        "\n",
        "# Get the title of Guido's webpage: guido_title\n",
        "guido_title = soup.title\n",
        "\n",
        "# Print the title of Guido's webpage to the shell\n",
        "print(guido_title)\n",
        "\n",
        "# Get Guido's text: guido_text\n",
        "guido_text = soup.get_text()\n",
        "\n",
        "# Print Guido's text to the shell\n",
        "print(guido_text)\n",
        "\n",
        "# Find all 'a' tags (which define hyperlinks): a_tags\n",
        "a_tags = soup.find_all('a')\n",
        "\n",
        "# Print the URLs to the shell\n",
        "for link in soup.find_all('a'):\n",
        "    print(link.get('href'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "niylSCrzHj7E",
        "outputId": "97345562-84c2-4ce5-98b6-9362fc080c2d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<html>\n",
            " <head>\n",
            "  <title>\n",
            "   Guido's Personal Home Page\n",
            "  </title>\n",
            " </head>\n",
            " <body bgcolor=\"#FFFFFF\" text=\"#000000\">\n",
            "  <!-- Built from main -->\n",
            "  <h1>\n",
            "   <a href=\"pics.html\">\n",
            "    <img border=\"0\" src=\"images/IMG_2192.jpg\"/>\n",
            "   </a>\n",
            "   Guido van Rossum - Personal Home Page\n",
            "   <a href=\"pics.html\">\n",
            "    <img border=\"0\" height=\"216\" src=\"images/guido-headshot-2019.jpg\" width=\"270\"/>\n",
            "   </a>\n",
            "  </h1>\n",
            "  <p>\n",
            "   <a href=\"http://www.washingtonpost.com/wp-srv/business/longterm/microsoft/stories/1998/raymond120398.htm\">\n",
            "    <i>\n",
            "     \"Gawky and proud of it.\"\n",
            "    </i>\n",
            "   </a>\n",
            "  </p>\n",
            "  <h3>\n",
            "   <a href=\"images/df20000406.jpg\">\n",
            "    Who I Am\n",
            "   </a>\n",
            "  </h3>\n",
            "  <p>\n",
            "   Read\n",
            "my\n",
            "   <a href=\"http://neopythonic.blogspot.com/2016/04/kings-day-speech.html\">\n",
            "    \"King's\n",
            "Day Speech\"\n",
            "   </a>\n",
            "   for some inspiration.\n",
            "  </p>\n",
            "  <p>\n",
            "   I am the author of the\n",
            "   <a href=\"http://www.python.org\">\n",
            "    Python\n",
            "   </a>\n",
            "   programming language.  See also my\n",
            "   <a href=\"Resume.html\">\n",
            "    resume\n",
            "   </a>\n",
            "   and my\n",
            "   <a href=\"Publications.html\">\n",
            "    publications list\n",
            "   </a>\n",
            "   , a\n",
            "   <a href=\"bio.html\">\n",
            "    brief bio\n",
            "   </a>\n",
            "   , assorted\n",
            "   <a href=\"http://legacy.python.org/doc/essays/\">\n",
            "    writings\n",
            "   </a>\n",
            "   ,\n",
            "   <a href=\"http://legacy.python.org/doc/essays/ppt/\">\n",
            "    presentations\n",
            "   </a>\n",
            "   and\n",
            "   <a href=\"interviews.html\">\n",
            "    interviews\n",
            "   </a>\n",
            "   (all about Python), some\n",
            "   <a href=\"pics.html\">\n",
            "    pictures of me\n",
            "   </a>\n",
            "   ,\n",
            "   <a href=\"http://neopythonic.blogspot.com\">\n",
            "    my new blog\n",
            "   </a>\n",
            "   , and\n",
            "my\n",
            "   <a href=\"http://www.artima.com/weblogs/index.jsp?blogger=12088\">\n",
            "    old\n",
            "blog\n",
            "   </a>\n",
            "   on Artima.com.  I am\n",
            "   <a href=\"https://twitter.com/gvanrossum\">\n",
            "    @gvanrossum\n",
            "   </a>\n",
            "   on Twitter.\n",
            "  </p>\n",
            "  <p>\n",
            "   I am currently a Distinguished Engineer at Microsoft.\n",
            "I have worked for Dropbox, Google, Elemental Security, Zope\n",
            "Corporation, BeOpen.com, CNRI, CWI, and SARA.  (See\n",
            "my\n",
            "   <a href=\"Resume.html\">\n",
            "    resume\n",
            "   </a>\n",
            "   .)  I created Python while at CWI.\n",
            "  </p>\n",
            "  <h3>\n",
            "   How to Reach Me\n",
            "  </h3>\n",
            "  <p>\n",
            "   You can send email for me to guido (at) python.org.\n",
            "I read everything sent there, but I receive too much email to respond\n",
            "to everything.\n",
            "  </p>\n",
            "  <p>\n",
            "   Please understand that I do not give talks or keynotes any more,\n",
            "nor do I participate in podcasts or give interviews, etc.\n",
            "I am sorry, but I just receive too many such requests to decline\n",
            "them individually.\n",
            "Offering payment or trips to exotic locales just makes things worse, sorry.\n",
            "  </p>\n",
            "  <p>\n",
            "   I also prefer not to receive questions about how to use Python\n",
            "(please read the\n",
            "   <a href=\"https://docs.python.org\">\n",
            "    documentation\n",
            "   </a>\n",
            "   or search the internet for Python answers forums),\n",
            "bug reports (use the\n",
            "   <a href=\"https://github.com/python/cpython/issues\">\n",
            "    GitHub issue tracker\n",
            "   </a>\n",
            "   ),\n",
            "proposals for changes to the language (use\n",
            "   <a href=\"https://discuss.python.org\">\n",
            "    Discourse\n",
            "   </a>\n",
            "   ),\n",
            "job offers (I'm happy where I am),\n",
            "or requests to join you in some far-fetched scheme to save humanity (though sometimes I like me a good rant :-).\n",
            "  </p>\n",
            "  <h3>\n",
            "   My Name\n",
            "  </h3>\n",
            "  <p>\n",
            "   My name often poses difficulties for Americans.\n",
            "  </p>\n",
            "  <p>\n",
            "   <b>\n",
            "    Pronunciation:\n",
            "   </b>\n",
            "   in Dutch, the \"G\" in Guido is a hard G,\n",
            "pronounced roughly like the \"ch\" in Scottish \"loch\".  (Listen to the\n",
            "   <a href=\"guido.au\">\n",
            "    sound clip\n",
            "   </a>\n",
            "   .)  However, if you're\n",
            "American, you may also pronounce it as the Italian \"Guido\".  I'm not\n",
            "too worried about the associations with mob assassins that some people\n",
            "have. :-)\n",
            "  </p>\n",
            "  <p>\n",
            "   <b>\n",
            "    Spelling:\n",
            "   </b>\n",
            "   my last name is two words, and I'd like to keep it\n",
            "that way, the spelling on some of my credit cards notwithstanding.\n",
            "Dutch spelling rules dictate that when used in combination with my\n",
            "first name, \"van\" is not capitalized: \"Guido van Rossum\".  But when my\n",
            "last name is used alone to refer to me, it is capitalized, for\n",
            "example: \"As usual, Van Rossum was right.\"\n",
            "  </p>\n",
            "  <p>\n",
            "   <b>\n",
            "    Alphabetization:\n",
            "   </b>\n",
            "   in America, I show up in the alphabet under\n",
            "\"V\".  But in Europe, I show up under \"R\".  And some of my friends put\n",
            "me under \"G\" in their address book...\n",
            "  </p>\n",
            "  <h3>\n",
            "   More Hyperlinks\n",
            "  </h3>\n",
            "  <ul>\n",
            "   <li>\n",
            "    Here's a collection of\n",
            "    <a href=\"http://legacy.python.org/doc/essays/\">\n",
            "     essays\n",
            "    </a>\n",
            "    relating to Python\n",
            "that I've written, including the foreword I wrote for Mark Lutz' book\n",
            "\"Programming Python\".\n",
            "    <p>\n",
            "    </p>\n",
            "   </li>\n",
            "   <li>\n",
            "    I own the official\n",
            "    <a href=\"images/license.jpg\">\n",
            "     <img align=\"center\" border=\"0\" height=\"75\" src=\"images/license_thumb.jpg\" width=\"100\"/>\n",
            "     Python license.\n",
            "    </a>\n",
            "    <p>\n",
            "    </p>\n",
            "   </li>\n",
            "  </ul>\n",
            "  <h3>\n",
            "   The Audio File Formats FAQ\n",
            "  </h3>\n",
            "  <p>\n",
            "   I was the original creator and maintainer of the Audio File Formats\n",
            "FAQ.  It was later maintained by Chris Bagwell, but seems to have been\n",
            "lost.  You can still find it on\n",
            "   <a href=\"https://web.archive.org/\">\n",
            "    archive.org\n",
            "   </a>\n",
            "   by searching for\n",
            "   <a href=\"https://web.archive.org/web/20230627131911/http://www.cnpbagwell.com/audio-faq\">\n",
            "    http://www.cnpbagwell.com/audio-faq\n",
            "   </a>\n",
            "   .  And here is a link to\n",
            "   <a href=\"http://sox.sourceforge.net/\">\n",
            "    SOX\n",
            "   </a>\n",
            "   , to which I contributed\n",
            "some early code.\n",
            "  </p>\n",
            "  <hr/>\n",
            "  <a href=\"images/internetdog.gif\">\n",
            "   \"On the Internet, nobody knows you're\n",
            "a dog.\"\n",
            "  </a>\n",
            "  <hr/>\n",
            " </body>\n",
            "</html>\n",
            "\n",
            "<title>Guido's Personal Home Page</title>\n",
            "\n",
            "\n",
            "Guido's Personal Home Page\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Guido van Rossum - Personal Home Page\n",
            "\n",
            "\n",
            "\"Gawky and proud of it.\"\n",
            "Who I Am\n",
            "Read\n",
            "my \"King's\n",
            "Day Speech\" for some inspiration.\n",
            "\n",
            "I am the author of the Python\n",
            "programming language.  See also my resume\n",
            "and my publications list, a brief bio, assorted writings, presentations and interviews (all about Python), some\n",
            "pictures of me,\n",
            "my new blog, and\n",
            "my old\n",
            "blog on Artima.com.  I am\n",
            "@gvanrossum on Twitter.\n",
            "\n",
            "I am currently a Distinguished Engineer at Microsoft.\n",
            "I have worked for Dropbox, Google, Elemental Security, Zope\n",
            "Corporation, BeOpen.com, CNRI, CWI, and SARA.  (See\n",
            "my resume.)  I created Python while at CWI.\n",
            "\n",
            "How to Reach Me\n",
            "You can send email for me to guido (at) python.org.\n",
            "I read everything sent there, but I receive too much email to respond\n",
            "to everything.\n",
            "\n",
            "Please understand that I do not give talks or keynotes any more,\n",
            "nor do I participate in podcasts or give interviews, etc.\n",
            "I am sorry, but I just receive too many such requests to decline\n",
            "them individually.\n",
            "Offering payment or trips to exotic locales just makes things worse, sorry.\n",
            "\n",
            "I also prefer not to receive questions about how to use Python\n",
            "(please read the documentation or search the internet for Python answers forums),\n",
            "bug reports (use the GitHub issue tracker),\n",
            "proposals for changes to the language (use Discourse),\n",
            "job offers (I'm happy where I am),\n",
            "or requests to join you in some far-fetched scheme to save humanity (though sometimes I like me a good rant :-).\n",
            "\n",
            "My Name\n",
            "My name often poses difficulties for Americans.\n",
            "\n",
            "Pronunciation: in Dutch, the \"G\" in Guido is a hard G,\n",
            "pronounced roughly like the \"ch\" in Scottish \"loch\".  (Listen to the\n",
            "sound clip.)  However, if you're\n",
            "American, you may also pronounce it as the Italian \"Guido\".  I'm not\n",
            "too worried about the associations with mob assassins that some people\n",
            "have. :-)\n",
            "\n",
            "Spelling: my last name is two words, and I'd like to keep it\n",
            "that way, the spelling on some of my credit cards notwithstanding.\n",
            "Dutch spelling rules dictate that when used in combination with my\n",
            "first name, \"van\" is not capitalized: \"Guido van Rossum\".  But when my\n",
            "last name is used alone to refer to me, it is capitalized, for\n",
            "example: \"As usual, Van Rossum was right.\"\n",
            "\n",
            "Alphabetization: in America, I show up in the alphabet under\n",
            "\"V\".  But in Europe, I show up under \"R\".  And some of my friends put\n",
            "me under \"G\" in their address book...\n",
            "\n",
            "\n",
            "More Hyperlinks\n",
            "\n",
            "Here's a collection of essays relating to Python\n",
            "that I've written, including the foreword I wrote for Mark Lutz' book\n",
            "\"Programming Python\".\n",
            "I own the official \n",
            "Python license.\n",
            "\n",
            "The Audio File Formats FAQ\n",
            "I was the original creator and maintainer of the Audio File Formats\n",
            "FAQ.  It was later maintained by Chris Bagwell, but seems to have been\n",
            "lost.  You can still find it on\n",
            "archive.org by searching for\n",
            "http://www.cnpbagwell.com/audio-faq.  And here is a link to\n",
            "SOX, to which I contributed\n",
            "some early code.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\"On the Internet, nobody knows you're\n",
            "a dog.\"\n",
            "\n",
            "\n",
            "\n",
            "pics.html\n",
            "pics.html\n",
            "http://www.washingtonpost.com/wp-srv/business/longterm/microsoft/stories/1998/raymond120398.htm\n",
            "images/df20000406.jpg\n",
            "http://neopythonic.blogspot.com/2016/04/kings-day-speech.html\n",
            "http://www.python.org\n",
            "Resume.html\n",
            "Publications.html\n",
            "bio.html\n",
            "http://legacy.python.org/doc/essays/\n",
            "http://legacy.python.org/doc/essays/ppt/\n",
            "interviews.html\n",
            "pics.html\n",
            "http://neopythonic.blogspot.com\n",
            "http://www.artima.com/weblogs/index.jsp?blogger=12088\n",
            "https://twitter.com/gvanrossum\n",
            "Resume.html\n",
            "https://docs.python.org\n",
            "https://github.com/python/cpython/issues\n",
            "https://discuss.python.org\n",
            "guido.au\n",
            "http://legacy.python.org/doc/essays/\n",
            "images/license.jpg\n",
            "https://web.archive.org/\n",
            "https://web.archive.org/web/20230627131911/http://www.cnpbagwell.com/audio-faq\n",
            "http://sox.sourceforge.net/\n",
            "images/internetdog.gif\n"
          ]
        }
      ]
    }
  ]
}